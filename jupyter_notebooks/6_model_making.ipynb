{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Razvoj modela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Matej\\anaconda3\\envs\\uzop_projekt\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras import layers, models as tf_models, callbacks\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U훾itavanje podataka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21 entries, 0 to 20\n",
      "Data columns (total 19 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   n                             21 non-null     int64  \n",
      " 1   m                             21 non-null     int64  \n",
      " 2   k_avg                         21 non-null     float64\n",
      " 3   edge_length_total             21 non-null     float64\n",
      " 4   edge_length_avg               21 non-null     float64\n",
      " 5   streets_per_node_avg          21 non-null     float64\n",
      " 6   streets_per_node_counts       21 non-null     object \n",
      " 7   streets_per_node_proportions  21 non-null     object \n",
      " 8   intersection_count            21 non-null     int64  \n",
      " 9   street_length_total           21 non-null     float64\n",
      " 10  street_segment_count          21 non-null     int64  \n",
      " 11  street_length_avg             21 non-null     float64\n",
      " 12  circuity_avg                  21 non-null     float64\n",
      " 13  self_loop_proportion          21 non-null     float64\n",
      " 14  node_density_km               21 non-null     float64\n",
      " 15  intersection_density_km       21 non-null     float64\n",
      " 16  edge_density_km               21 non-null     float64\n",
      " 17  street_density_km             21 non-null     float64\n",
      " 18  city_code                     21 non-null     object \n",
      "dtypes: float64(12), int64(4), object(3)\n",
      "memory usage: 3.2+ KB\n"
     ]
    }
   ],
   "source": [
    "cities_df = pd.read_json('dataset/city_basic_stats.json')\n",
    "cities_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35159 entries, 0 to 35158\n",
      "Data columns (total 27 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Unnamed: 0.1                 35159 non-null  int64  \n",
      " 1   Unnamed: 0                   35159 non-null  int64  \n",
      " 2   ID                           35159 non-null  object \n",
      " 3   Delivery_person_ID           35159 non-null  object \n",
      " 4   Delivery_person_Age          35159 non-null  int64  \n",
      " 5   Delivery_person_Ratings      35159 non-null  float64\n",
      " 6   Restaurant_latitude          35159 non-null  float64\n",
      " 7   Restaurant_longitude         35159 non-null  float64\n",
      " 8   Delivery_location_latitude   35159 non-null  float64\n",
      " 9   Delivery_location_longitude  35159 non-null  float64\n",
      " 10  Weatherconditions            35159 non-null  object \n",
      " 11  Road_traffic_density         35159 non-null  object \n",
      " 12  Vehicle_condition            35159 non-null  int64  \n",
      " 13  Type_of_order                35159 non-null  object \n",
      " 14  Type_of_vehicle              35159 non-null  object \n",
      " 15  multiple_deliveries          35159 non-null  int64  \n",
      " 16  Festival                     35159 non-null  int64  \n",
      " 17  City                         35159 non-null  object \n",
      " 18  Time_taken(min)              35159 non-null  int64  \n",
      " 19  Datetime_Ordered             35159 non-null  object \n",
      " 20  Datetime_Picked              35159 non-null  object \n",
      " 21  distance(km)                 35159 non-null  float64\n",
      " 22  city_code                    35159 non-null  object \n",
      " 23  Restaurant_node_id           35159 non-null  int64  \n",
      " 24  Delivery_node_id             35159 non-null  int64  \n",
      " 25  shortest_path                34830 non-null  object \n",
      " 26  shortest_path_length         35159 non-null  float64\n",
      "dtypes: float64(7), int64(9), object(11)\n",
      "memory usage: 7.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/deliverytime_with_route_lengths.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priprema podataka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spajanje podatkovnog skupa dostava s podatkovnim skupom statistika gradova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'ID', 'Delivery_person_ID',\n",
       "       'Delivery_person_Age', 'Delivery_person_Ratings', 'Restaurant_latitude',\n",
       "       'Restaurant_longitude', 'Delivery_location_latitude',\n",
       "       'Delivery_location_longitude', 'Weatherconditions',\n",
       "       'Road_traffic_density', 'Vehicle_condition', 'Type_of_order',\n",
       "       'Type_of_vehicle', 'multiple_deliveries', 'Festival', 'City',\n",
       "       'Time_taken(min)', 'Datetime_Ordered', 'Datetime_Picked',\n",
       "       'distance(km)', 'city_code', 'Restaurant_node_id', 'Delivery_node_id',\n",
       "       'shortest_path', 'shortest_path_length', 'n', 'm', 'k_avg',\n",
       "       'edge_length_total', 'edge_length_avg', 'streets_per_node_avg',\n",
       "       'streets_per_node_counts', 'streets_per_node_proportions',\n",
       "       'intersection_count', 'street_length_total', 'street_segment_count',\n",
       "       'street_length_avg', 'circuity_avg', 'self_loop_proportion',\n",
       "       'node_density_km', 'intersection_density_km', 'edge_density_km',\n",
       "       'street_density_km'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(df, cities_df, on='city_code')\n",
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristi훾ko mijenjanje kategori훾kih vrijednosti numeri훾kima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['snack' 'drinks' 'meal' 'buffet']\n",
      "['motorcycle' 'scooter' 'electric_scooter']\n",
      "['Sunny' 'Cloudy' 'Sandstorms' 'Fog' 'Stormy' 'Windy']\n",
      "['High ' 'Low ' 'Medium ' 'Jam ']\n",
      "['Urban ' 'Metropolitian ' 'Semi-Urban ']\n"
     ]
    }
   ],
   "source": [
    "print(merged_df['Type_of_order'].unique())\n",
    "print(merged_df['Type_of_vehicle'].unique())\n",
    "print(merged_df['Weatherconditions'].unique())\n",
    "print(merged_df['Road_traffic_density'].unique())\n",
    "print(merged_df['City'].unique())\n",
    "\n",
    "merged_df['Type_of_order'].replace(\n",
    "    ['snack', 'drinks', 'meal', 'buffet'],\n",
    "    [1, 1, 5, 5], \n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "merged_df['Type_of_vehicle'].replace(\n",
    "    ['motorcycle', 'scooter', 'electric_scooter', 'bicycle'],\n",
    "    [5, 5, 3, 0.5], \n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "merged_df['Weatherconditions'].replace(\n",
    "    ['Sunny', 'Stormy', 'Sandstorms', 'Cloudy', 'Fog', 'Windy'],\n",
    "    [0.5, 2, 2, 3, 3, 2], \n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "\n",
    "merged_df['Road_traffic_density'].replace(\n",
    "    ['High ', 'Jam ', 'Low ', 'Medium '],\n",
    "    [2, 3, 0.5, 1], \n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "merged_df['City'].replace(\n",
    "    ['Urban ', 'Metropolitian ', 'Semi-Urban '],\n",
    "    [2, 3, 1], \n",
    "    inplace=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Datetime_Ordered'] = pd.to_datetime(merged_df['Datetime_Ordered'])\n",
    "merged_df['Datetime_Picked'] = pd.to_datetime(merged_df['Datetime_Picked'])\n",
    "\n",
    "merged_df[\"Order_month\"] = merged_df['Datetime_Ordered'].dt.month\n",
    "merged_df[\"Order_hour\"] = merged_df['Datetime_Ordered'].dt.hour\n",
    "merged_df[\"Picked_month\"] = merged_df['Datetime_Picked'].dt.month\n",
    "merged_df[\"Picked_hour\"] = merged_df['Datetime_Picked'].dt.hour\n",
    "merged_df[\"Day_of_week\"] = merged_df['Datetime_Ordered'].dt.day_of_week + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'ID', 'Delivery_person_ID',\n",
       "       'Delivery_person_Age', 'Delivery_person_Ratings', 'Restaurant_latitude',\n",
       "       'Restaurant_longitude', 'Delivery_location_latitude',\n",
       "       'Delivery_location_longitude', 'Weatherconditions',\n",
       "       'Road_traffic_density', 'Vehicle_condition', 'Type_of_order',\n",
       "       'Type_of_vehicle', 'multiple_deliveries', 'Festival', 'City',\n",
       "       'Time_taken(min)', 'Datetime_Ordered', 'Datetime_Picked',\n",
       "       'distance(km)', 'city_code', 'Restaurant_node_id', 'Delivery_node_id',\n",
       "       'shortest_path', 'shortest_path_length', 'n', 'm', 'k_avg',\n",
       "       'edge_length_total', 'edge_length_avg', 'streets_per_node_avg',\n",
       "       'streets_per_node_counts', 'streets_per_node_proportions',\n",
       "       'intersection_count', 'street_length_total', 'street_segment_count',\n",
       "       'street_length_avg', 'circuity_avg', 'self_loop_proportion',\n",
       "       'node_density_km', 'intersection_density_km', 'edge_density_km',\n",
       "       'street_density_km', 'Order_month', 'Order_hour', 'Picked_month',\n",
       "       'Picked_hour', 'Day_of_week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Izabir numeri훾kih vrijednosti iz podatkovnog skupa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Delivery_person_Age', 'Delivery_person_Ratings', 'Restaurant_latitude',\n",
       "       'Restaurant_longitude', 'Delivery_location_latitude',\n",
       "       'Delivery_location_longitude', 'Weatherconditions',\n",
       "       'Road_traffic_density', 'Vehicle_condition', 'Type_of_order',\n",
       "       'Type_of_vehicle', 'multiple_deliveries', 'Festival', 'City',\n",
       "       'distance(km)', 'Restaurant_node_id', 'Delivery_node_id',\n",
       "       'shortest_path_length', 'n', 'm', 'k_avg', 'edge_length_total',\n",
       "       'edge_length_avg', 'streets_per_node_avg', 'intersection_count',\n",
       "       'street_length_total', 'street_segment_count', 'street_length_avg',\n",
       "       'circuity_avg', 'self_loop_proportion', 'node_density_km',\n",
       "       'intersection_density_km', 'edge_density_km', 'street_density_km',\n",
       "       'Order_month', 'Order_hour', 'Picked_month', 'Picked_hour',\n",
       "       'Day_of_week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_numeric = merged_df.select_dtypes(include='number')\n",
    "X_numeric = X_numeric.drop(['Time_taken(min)', 'Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "X_numeric.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Train-validation-test' podjela, polinomijalna transformacija i standardizacija"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'Time_taken(min)'\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_numeric, \n",
    "    merged_df[target_column], \n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 2\n",
    "\n",
    "selected_attributes = [\n",
    "    'Delivery_person_Age', 'Delivery_person_Ratings', 'Weatherconditions',\n",
    "    'Road_traffic_density', 'Vehicle_condition', 'multiple_deliveries', \n",
    "    'Festival', 'City', 'shortest_path_length', 'intersection_density_km', \n",
    "    'self_loop_proportion', 'circuity_avg', 'Order_hour', 'Picked_hour'\n",
    "]\n",
    "\n",
    "poly = PolynomialFeatures(degree=degree)\n",
    "X_train_poly = pd.DataFrame(poly.fit_transform(X_train[selected_attributes]), columns=poly.get_feature_names_out(X_train[selected_attributes].columns))\n",
    "X_val_poly = pd.DataFrame(poly.fit_transform(X_val[selected_attributes]), columns=poly.get_feature_names_out(X_val[selected_attributes].columns))\n",
    "X_test_poly = pd.DataFrame(poly.fit_transform(X_test[selected_attributes]), columns=poly.get_feature_names_out(X_test[selected_attributes].columns))\n",
    "\n",
    "extended_df = pd.concat([X_train, X_train_poly, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_poly = scaler.fit_transform(X_train_poly)\n",
    "X_val_scaled_poly = scaler.transform(X_val_poly)\n",
    "X_test_scaled_poly = scaler.transform(X_test_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bazna struktura neuronske mre탑e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neural_network(input_shape, hidden_layer_sizes=[], act_funs=[], output_size=1):\n",
    "    \"\"\"Creates untrained linear regresion model with specified sizes of hidden layers \n",
    "    and specified activation functions between layers.\n",
    "    \"\"\"\n",
    "    nn = tf_models.Sequential()\n",
    "\n",
    "    nn.add(layers.InputLayer(input_shape=input_shape))\n",
    "\n",
    "    for i in range(len(hidden_layer_sizes)):\n",
    "        units = hidden_layer_sizes[i]\n",
    "        activation_fun = act_funs[i]\n",
    "        nn.add(layers.Dense(units, activation=activation_fun))\n",
    "\n",
    "    nn.add(layers.Dense(output_size, activation='linear'))  # Adjust activation function as needed\n",
    "\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jednostavna linearna regresija (bez skrivenih slojeva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Matej\\anaconda3\\envs\\uzop_projekt\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1)                 40        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40 (160.00 Byte)\n",
      "Trainable params: 40 (160.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = X_train_scaled.shape[1]\n",
    "\n",
    "input_shape = (input_size,)\n",
    "neural_network = create_neural_network(input_shape, [], [])\n",
    "\n",
    "neural_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "WARNING:tensorflow:From c:\\Users\\Matej\\anaconda3\\envs\\uzop_projekt\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "22/22 [==============================] - 1s 9ms/step - loss: 782.8168 - val_loss: 761.1772 - lr: 0.0100\n",
      "Epoch 2/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 759.7762 - val_loss: 740.7491 - lr: 0.0100\n",
      "Epoch 3/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 740.2266 - val_loss: 722.8514 - lr: 0.0100\n",
      "Epoch 4/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 723.1229 - val_loss: 706.6508 - lr: 0.0100\n",
      "Epoch 5/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 707.4722 - val_loss: 691.8558 - lr: 0.0100\n",
      "Epoch 6/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 693.0145 - val_loss: 678.0744 - lr: 0.0100\n",
      "Epoch 7/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 679.3837 - val_loss: 665.0207 - lr: 0.0100\n",
      "Epoch 8/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 666.6180 - val_loss: 652.4501 - lr: 0.0100\n",
      "Epoch 9/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 654.1888 - val_loss: 640.5347 - lr: 0.0100\n",
      "Epoch 10/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 642.4537 - val_loss: 629.1050 - lr: 0.0100\n",
      "Epoch 11/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 631.0005 - val_loss: 617.9236 - lr: 0.0100\n",
      "Epoch 12/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 620.0224 - val_loss: 607.1625 - lr: 0.0100\n",
      "Epoch 13/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 609.3329 - val_loss: 596.7399 - lr: 0.0100\n",
      "Epoch 14/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 598.8995 - val_loss: 586.4717 - lr: 0.0100\n",
      "Epoch 15/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 588.6700 - val_loss: 576.5219 - lr: 0.0100\n",
      "Epoch 16/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 578.7322 - val_loss: 566.7651 - lr: 0.0100\n",
      "Epoch 17/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 568.9175 - val_loss: 557.1174 - lr: 0.0100\n",
      "Epoch 18/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 559.3177 - val_loss: 547.6450 - lr: 0.0100\n",
      "Epoch 19/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 549.9707 - val_loss: 538.3445 - lr: 0.0100\n",
      "Epoch 20/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 540.6803 - val_loss: 529.2264 - lr: 0.0100\n",
      "Epoch 21/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 531.4755 - val_loss: 520.2231 - lr: 0.0100\n",
      "Epoch 22/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 522.4576 - val_loss: 511.3794 - lr: 0.0100\n",
      "Epoch 23/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 513.6063 - val_loss: 502.6267 - lr: 0.0100\n",
      "Epoch 24/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 504.8759 - val_loss: 494.0198 - lr: 0.0100\n",
      "Epoch 25/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 496.2213 - val_loss: 485.5198 - lr: 0.0100\n",
      "Epoch 26/300\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 487.7380 - val_loss: 477.0978 - lr: 0.0100\n",
      "Epoch 27/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 479.3466 - val_loss: 468.8327 - lr: 0.0100\n",
      "Epoch 28/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 471.0660 - val_loss: 460.7535 - lr: 0.0100\n",
      "Epoch 29/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 462.9607 - val_loss: 452.6643 - lr: 0.0100\n",
      "Epoch 30/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 454.9202 - val_loss: 444.7401 - lr: 0.0100\n",
      "Epoch 31/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 447.0130 - val_loss: 436.9813 - lr: 0.0100\n",
      "Epoch 32/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 439.1915 - val_loss: 429.2673 - lr: 0.0100\n",
      "Epoch 33/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 431.5180 - val_loss: 421.6771 - lr: 0.0100\n",
      "Epoch 34/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 423.8781 - val_loss: 414.2057 - lr: 0.0100\n",
      "Epoch 35/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 416.3930 - val_loss: 406.8208 - lr: 0.0100\n",
      "Epoch 36/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 409.0284 - val_loss: 399.5580 - lr: 0.0100\n",
      "Epoch 37/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 401.7628 - val_loss: 392.3961 - lr: 0.0100\n",
      "Epoch 38/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 394.5995 - val_loss: 385.3627 - lr: 0.0100\n",
      "Epoch 39/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 387.5669 - val_loss: 378.3779 - lr: 0.0100\n",
      "Epoch 40/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 380.5767 - val_loss: 371.5302 - lr: 0.0100\n",
      "Epoch 41/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 373.7255 - val_loss: 364.7873 - lr: 0.0100\n",
      "Epoch 42/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 366.9866 - val_loss: 358.1232 - lr: 0.0100\n",
      "Epoch 43/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 360.3126 - val_loss: 351.5374 - lr: 0.0100\n",
      "Epoch 44/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 353.7719 - val_loss: 345.1241 - lr: 0.0100\n",
      "Epoch 45/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 347.2710 - val_loss: 338.7419 - lr: 0.0100\n",
      "Epoch 46/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 340.9349 - val_loss: 332.4930 - lr: 0.0100\n",
      "Epoch 47/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 334.6658 - val_loss: 326.2969 - lr: 0.0100\n",
      "Epoch 48/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 328.4675 - val_loss: 320.2284 - lr: 0.0100\n",
      "Epoch 49/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 322.3764 - val_loss: 314.2134 - lr: 0.0100\n",
      "Epoch 50/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 316.3805 - val_loss: 308.3342 - lr: 0.0100\n",
      "Epoch 51/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 310.5195 - val_loss: 302.5495 - lr: 0.0100\n",
      "Epoch 52/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 304.6864 - val_loss: 296.8397 - lr: 0.0100\n",
      "Epoch 53/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 298.9632 - val_loss: 291.1833 - lr: 0.0100\n",
      "Epoch 54/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 293.3295 - val_loss: 285.6811 - lr: 0.0100\n",
      "Epoch 55/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 287.8123 - val_loss: 280.2051 - lr: 0.0100\n",
      "Epoch 56/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 282.3242 - val_loss: 274.8189 - lr: 0.0100\n",
      "Epoch 57/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 276.9782 - val_loss: 269.5542 - lr: 0.0100\n",
      "Epoch 58/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 271.6592 - val_loss: 264.4118 - lr: 0.0100\n",
      "Epoch 59/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 266.4707 - val_loss: 259.2747 - lr: 0.0100\n",
      "Epoch 60/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 261.3865 - val_loss: 254.2488 - lr: 0.0100\n",
      "Epoch 61/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 256.3241 - val_loss: 249.3052 - lr: 0.0100\n",
      "Epoch 62/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 251.3727 - val_loss: 244.4366 - lr: 0.0100\n",
      "Epoch 63/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 246.5008 - val_loss: 239.6617 - lr: 0.0100\n",
      "Epoch 64/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 241.7297 - val_loss: 234.9394 - lr: 0.0100\n",
      "Epoch 65/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 237.0337 - val_loss: 230.3590 - lr: 0.0100\n",
      "Epoch 66/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 232.3665 - val_loss: 225.7816 - lr: 0.0100\n",
      "Epoch 67/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 227.8489 - val_loss: 221.2997 - lr: 0.0100\n",
      "Epoch 68/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 223.3407 - val_loss: 216.9280 - lr: 0.0100\n",
      "Epoch 69/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 218.9610 - val_loss: 212.6134 - lr: 0.0100\n",
      "Epoch 70/300\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 214.6210 - val_loss: 208.4147 - lr: 0.0100\n",
      "Epoch 71/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 210.3778 - val_loss: 204.2116 - lr: 0.0100\n",
      "Epoch 72/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 206.2312 - val_loss: 200.1266 - lr: 0.0100\n",
      "Epoch 73/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 202.1015 - val_loss: 196.1236 - lr: 0.0100\n",
      "Epoch 74/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 198.1004 - val_loss: 192.1276 - lr: 0.0100\n",
      "Epoch 75/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 194.1140 - val_loss: 188.2748 - lr: 0.0100\n",
      "Epoch 76/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 190.2514 - val_loss: 184.4541 - lr: 0.0100\n",
      "Epoch 77/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 186.4407 - val_loss: 180.7777 - lr: 0.0100\n",
      "Epoch 78/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 182.6869 - val_loss: 177.0530 - lr: 0.0100\n",
      "Epoch 79/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 179.0279 - val_loss: 173.4681 - lr: 0.0100\n",
      "Epoch 80/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 175.3990 - val_loss: 169.9361 - lr: 0.0100\n",
      "Epoch 81/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 171.8445 - val_loss: 166.4730 - lr: 0.0100\n",
      "Epoch 82/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 168.3857 - val_loss: 163.0939 - lr: 0.0100\n",
      "Epoch 83/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 164.9695 - val_loss: 159.7311 - lr: 0.0100\n",
      "Epoch 84/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 161.6344 - val_loss: 156.4280 - lr: 0.0100\n",
      "Epoch 85/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 158.3424 - val_loss: 153.2679 - lr: 0.0100\n",
      "Epoch 86/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 155.1190 - val_loss: 150.1142 - lr: 0.0100\n",
      "Epoch 87/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 151.9498 - val_loss: 147.0270 - lr: 0.0100\n",
      "Epoch 88/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 148.8670 - val_loss: 143.9935 - lr: 0.0100\n",
      "Epoch 89/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 145.8422 - val_loss: 141.0396 - lr: 0.0100\n",
      "Epoch 90/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 142.8788 - val_loss: 138.1338 - lr: 0.0100\n",
      "Epoch 91/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 139.9583 - val_loss: 135.2740 - lr: 0.0100\n",
      "Epoch 92/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 137.1022 - val_loss: 132.5185 - lr: 0.0100\n",
      "Epoch 93/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 134.3238 - val_loss: 129.7687 - lr: 0.0100\n",
      "Epoch 94/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 131.5654 - val_loss: 127.1325 - lr: 0.0100\n",
      "Epoch 95/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 128.8903 - val_loss: 124.5021 - lr: 0.0100\n",
      "Epoch 96/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 126.2738 - val_loss: 121.9465 - lr: 0.0100\n",
      "Epoch 97/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 123.7055 - val_loss: 119.4641 - lr: 0.0100\n",
      "Epoch 98/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 121.2071 - val_loss: 116.9991 - lr: 0.0100\n",
      "Epoch 99/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 118.7319 - val_loss: 114.5979 - lr: 0.0100\n",
      "Epoch 100/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 116.3140 - val_loss: 112.2359 - lr: 0.0100\n",
      "Epoch 101/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.9579 - val_loss: 109.9775 - lr: 0.0100\n",
      "Epoch 102/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 111.6424 - val_loss: 107.7126 - lr: 0.0100\n",
      "Epoch 103/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 109.4154 - val_loss: 105.5337 - lr: 0.0100\n",
      "Epoch 104/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 107.2063 - val_loss: 103.3846 - lr: 0.0100\n",
      "Epoch 105/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 105.0460 - val_loss: 101.2814 - lr: 0.0100\n",
      "Epoch 106/300\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 102.9477 - val_loss: 99.2715 - lr: 0.0100\n",
      "Epoch 107/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 100.8923 - val_loss: 97.2447 - lr: 0.0100\n",
      "Epoch 108/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 98.8896 - val_loss: 95.3258 - lr: 0.0100\n",
      "Epoch 109/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 96.9330 - val_loss: 93.4181 - lr: 0.0100\n",
      "Epoch 110/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 95.0203 - val_loss: 91.5842 - lr: 0.0100\n",
      "Epoch 111/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 93.1609 - val_loss: 89.7519 - lr: 0.0100\n",
      "Epoch 112/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 91.3242 - val_loss: 87.9956 - lr: 0.0100\n",
      "Epoch 113/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 89.5672 - val_loss: 86.2736 - lr: 0.0100\n",
      "Epoch 114/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 87.8268 - val_loss: 84.5712 - lr: 0.0100\n",
      "Epoch 115/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 86.1238 - val_loss: 82.9605 - lr: 0.0100\n",
      "Epoch 116/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 84.4917 - val_loss: 81.3854 - lr: 0.0100\n",
      "Epoch 117/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 82.8849 - val_loss: 79.7972 - lr: 0.0100\n",
      "Epoch 118/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 81.3156 - val_loss: 78.2971 - lr: 0.0100\n",
      "Epoch 119/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 79.7952 - val_loss: 76.8328 - lr: 0.0100\n",
      "Epoch 120/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 78.3316 - val_loss: 75.3826 - lr: 0.0100\n",
      "Epoch 121/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 76.8560 - val_loss: 74.0054 - lr: 0.0100\n",
      "Epoch 122/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 75.4694 - val_loss: 72.6514 - lr: 0.0100\n",
      "Epoch 123/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 74.0922 - val_loss: 71.3023 - lr: 0.0100\n",
      "Epoch 124/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 72.7594 - val_loss: 70.0379 - lr: 0.0100\n",
      "Epoch 125/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 71.4660 - val_loss: 68.7906 - lr: 0.0100\n",
      "Epoch 126/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 70.1985 - val_loss: 67.5708 - lr: 0.0100\n",
      "Epoch 127/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 68.9653 - val_loss: 66.3963 - lr: 0.0100\n",
      "Epoch 128/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 67.7721 - val_loss: 65.2696 - lr: 0.0100\n",
      "Epoch 129/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 66.6198 - val_loss: 64.1452 - lr: 0.0100\n",
      "Epoch 130/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 65.4984 - val_loss: 63.0525 - lr: 0.0100\n",
      "Epoch 131/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 64.4241 - val_loss: 62.0169 - lr: 0.0100\n",
      "Epoch 132/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 63.3578 - val_loss: 61.0151 - lr: 0.0100\n",
      "Epoch 133/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 62.3283 - val_loss: 60.0105 - lr: 0.0100\n",
      "Epoch 134/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 61.3233 - val_loss: 59.0738 - lr: 0.0100\n",
      "Epoch 135/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 60.3609 - val_loss: 58.1501 - lr: 0.0100\n",
      "Epoch 136/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 59.4436 - val_loss: 57.2501 - lr: 0.0100\n",
      "Epoch 137/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 58.5188 - val_loss: 56.3837 - lr: 0.0100\n",
      "Epoch 138/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 57.6464 - val_loss: 55.5480 - lr: 0.0100\n",
      "Epoch 139/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 56.8055 - val_loss: 54.7383 - lr: 0.0100\n",
      "Epoch 140/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 55.9687 - val_loss: 53.9677 - lr: 0.0100\n",
      "Epoch 141/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 55.1795 - val_loss: 53.1836 - lr: 0.0100\n",
      "Epoch 142/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 54.4059 - val_loss: 52.4575 - lr: 0.0100\n",
      "Epoch 143/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 53.6745 - val_loss: 51.7720 - lr: 0.0100\n",
      "Epoch 144/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 52.9549 - val_loss: 51.0823 - lr: 0.0100\n",
      "Epoch 145/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 52.2582 - val_loss: 50.4377 - lr: 0.0100\n",
      "Epoch 146/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 51.5853 - val_loss: 49.8005 - lr: 0.0100\n",
      "Epoch 147/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 50.9372 - val_loss: 49.1668 - lr: 0.0100\n",
      "Epoch 148/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 50.3065 - val_loss: 48.6074 - lr: 0.0100\n",
      "Epoch 149/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 49.7279 - val_loss: 48.0194 - lr: 0.0100\n",
      "Epoch 150/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 49.1241 - val_loss: 47.4899 - lr: 0.0100\n",
      "Epoch 151/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 48.5721 - val_loss: 46.9223 - lr: 0.0100\n",
      "Epoch 152/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 48.0270 - val_loss: 46.4301 - lr: 0.0100\n",
      "Epoch 153/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 47.5102 - val_loss: 45.9447 - lr: 0.0100\n",
      "Epoch 154/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 47.0098 - val_loss: 45.4804 - lr: 0.0100\n",
      "Epoch 155/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 46.5248 - val_loss: 45.0222 - lr: 0.0100\n",
      "Epoch 156/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 46.0611 - val_loss: 44.5849 - lr: 0.0100\n",
      "Epoch 157/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 45.6194 - val_loss: 44.1954 - lr: 0.0100\n",
      "Epoch 158/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 45.1957 - val_loss: 43.7752 - lr: 0.0100\n",
      "Epoch 159/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 44.7921 - val_loss: 43.4063 - lr: 0.0100\n",
      "Epoch 160/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 44.4019 - val_loss: 43.0334 - lr: 0.0100\n",
      "Epoch 161/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 44.0187 - val_loss: 42.6931 - lr: 0.0100\n",
      "Epoch 162/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 43.6555 - val_loss: 42.3390 - lr: 0.0100\n",
      "Epoch 163/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 43.3152 - val_loss: 42.0469 - lr: 0.0100\n",
      "Epoch 164/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 42.9827 - val_loss: 41.7363 - lr: 0.0100\n",
      "Epoch 165/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 42.6598 - val_loss: 41.4281 - lr: 0.0100\n",
      "Epoch 166/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 42.3551 - val_loss: 41.1566 - lr: 0.0100\n",
      "Epoch 167/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 42.0717 - val_loss: 40.8724 - lr: 0.0100\n",
      "Epoch 168/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 41.7960 - val_loss: 40.6382 - lr: 0.0100\n",
      "Epoch 169/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 41.5246 - val_loss: 40.4000 - lr: 0.0100\n",
      "Epoch 170/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 41.2844 - val_loss: 40.1541 - lr: 0.0100\n",
      "Epoch 171/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 41.0310 - val_loss: 39.9497 - lr: 0.0100\n",
      "Epoch 172/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 40.8082 - val_loss: 39.7558 - lr: 0.0100\n",
      "Epoch 173/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 40.5977 - val_loss: 39.5333 - lr: 0.0100\n",
      "Epoch 174/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 40.3779 - val_loss: 39.3603 - lr: 0.0100\n",
      "Epoch 175/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 40.1803 - val_loss: 39.1722 - lr: 0.0100\n",
      "Epoch 176/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 39.9888 - val_loss: 38.9863 - lr: 0.0100\n",
      "Epoch 177/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 39.8181 - val_loss: 38.8615 - lr: 0.0100\n",
      "Epoch 178/300\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 39.6562 - val_loss: 38.6952 - lr: 0.0100\n",
      "Epoch 179/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 39.4776 - val_loss: 38.5259 - lr: 0.0100\n",
      "Epoch 180/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 39.3272 - val_loss: 38.4008 - lr: 0.0100\n",
      "Epoch 181/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 39.1862 - val_loss: 38.2768 - lr: 0.0100\n",
      "Epoch 182/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 39.0445 - val_loss: 38.1634 - lr: 0.0100\n",
      "Epoch 183/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 38.9149 - val_loss: 38.0422 - lr: 0.0100\n",
      "Epoch 184/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 38.8080 - val_loss: 37.9543 - lr: 0.0100\n",
      "Epoch 185/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 38.7100 - val_loss: 37.8808 - lr: 0.0100\n",
      "Epoch 186/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 38.5627 - val_loss: 37.7534 - lr: 0.0100\n",
      "Epoch 187/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 38.4637 - val_loss: 37.6502 - lr: 0.0100\n",
      "Epoch 188/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 38.3675 - val_loss: 37.5644 - lr: 0.0100\n",
      "Epoch 189/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 38.2709 - val_loss: 37.5016 - lr: 0.0100\n",
      "Epoch 190/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 38.1807 - val_loss: 37.4035 - lr: 0.0100\n",
      "Epoch 191/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 38.1055 - val_loss: 37.3662 - lr: 0.0100\n",
      "Epoch 192/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 38.0246 - val_loss: 37.2579 - lr: 0.0100\n",
      "Epoch 193/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.9443 - val_loss: 37.2438 - lr: 0.0100\n",
      "Epoch 194/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.8791 - val_loss: 37.1759 - lr: 0.0100\n",
      "Epoch 195/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.8308 - val_loss: 37.1103 - lr: 0.0100\n",
      "Epoch 196/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.7556 - val_loss: 37.0730 - lr: 0.0100\n",
      "Epoch 197/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.7096 - val_loss: 37.0085 - lr: 0.0100\n",
      "Epoch 198/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.6570 - val_loss: 36.9663 - lr: 0.0100\n",
      "Epoch 199/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.6144 - val_loss: 36.9735 - lr: 0.0100\n",
      "Epoch 200/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.5622 - val_loss: 36.9052 - lr: 0.0100\n",
      "Epoch 201/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.5185 - val_loss: 36.8732 - lr: 0.0100\n",
      "Epoch 202/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.4989 - val_loss: 36.8954 - lr: 0.0100\n",
      "Epoch 203/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.4616 - val_loss: 36.8046 - lr: 0.0100\n",
      "Epoch 204/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.4239 - val_loss: 36.7684 - lr: 0.0100\n",
      "Epoch 205/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.3819 - val_loss: 36.7767 - lr: 0.0100\n",
      "Epoch 206/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.3433 - val_loss: 36.7276 - lr: 0.0100\n",
      "Epoch 207/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.3108 - val_loss: 36.7146 - lr: 0.0100\n",
      "Epoch 208/300\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 37.2956 - val_loss: 36.6982 - lr: 0.0100\n",
      "Epoch 209/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.2671 - val_loss: 36.6830 - lr: 0.0100\n",
      "Epoch 210/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.2497 - val_loss: 36.6797 - lr: 0.0100\n",
      "Epoch 211/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.2254 - val_loss: 36.6480 - lr: 0.0100\n",
      "Epoch 212/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.2080 - val_loss: 36.6320 - lr: 0.0100\n",
      "Epoch 213/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.1844 - val_loss: 36.6489 - lr: 0.0100\n",
      "Epoch 214/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.1759 - val_loss: 36.6227 - lr: 0.0100\n",
      "Epoch 215/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.1556 - val_loss: 36.6229 - lr: 0.0100\n",
      "Epoch 216/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.1463 - val_loss: 36.6063 - lr: 0.0100\n",
      "Epoch 217/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.1328 - val_loss: 36.6003 - lr: 0.0100\n",
      "Epoch 218/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.1168 - val_loss: 36.6082 - lr: 0.0100\n",
      "Epoch 219/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.1242 - val_loss: 36.5784 - lr: 0.0100\n",
      "Epoch 220/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0989 - val_loss: 36.5727 - lr: 0.0100\n",
      "Epoch 221/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 37.0929 - val_loss: 36.5808 - lr: 0.0100\n",
      "Epoch 222/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0850 - val_loss: 36.5647 - lr: 0.0100\n",
      "Epoch 223/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0863 - val_loss: 36.5647 - lr: 0.0100\n",
      "Epoch 224/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0671 - val_loss: 36.5906 - lr: 0.0100\n",
      "Epoch 225/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0857 - val_loss: 36.5861 - lr: 0.0100\n",
      "Epoch 226/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0479 - val_loss: 36.5717 - lr: 1.0000e-03\n",
      "Epoch 227/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0407 - val_loss: 36.5636 - lr: 1.0000e-03\n",
      "Epoch 228/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0390 - val_loss: 36.5625 - lr: 1.0000e-03\n",
      "Epoch 229/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0394 - val_loss: 36.5624 - lr: 1.0000e-03\n",
      "Epoch 230/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0381 - val_loss: 36.5601 - lr: 1.0000e-03\n",
      "Epoch 231/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0371 - val_loss: 36.5577 - lr: 1.0000e-03\n",
      "Epoch 232/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0364 - val_loss: 36.5564 - lr: 1.0000e-03\n",
      "Epoch 233/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0356 - val_loss: 36.5590 - lr: 1.0000e-03\n",
      "Epoch 234/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0350 - val_loss: 36.5589 - lr: 1.0000e-03\n",
      "Epoch 235/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0348 - val_loss: 36.5560 - lr: 1.0000e-03\n",
      "Epoch 236/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0348 - val_loss: 36.5555 - lr: 1.0000e-03\n",
      "Epoch 237/300\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 37.0336 - val_loss: 36.5544 - lr: 1.0000e-03\n",
      "Epoch 238/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0331 - val_loss: 36.5529 - lr: 1.0000e-03\n",
      "Epoch 239/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0328 - val_loss: 36.5555 - lr: 1.0000e-03\n",
      "Epoch 240/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0321 - val_loss: 36.5555 - lr: 1.0000e-03\n",
      "Epoch 241/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0332 - val_loss: 36.5499 - lr: 1.0000e-03\n",
      "Epoch 242/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0313 - val_loss: 36.5545 - lr: 1.0000e-03\n",
      "Epoch 243/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0307 - val_loss: 36.5533 - lr: 1.0000e-03\n",
      "Epoch 244/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0305 - val_loss: 36.5537 - lr: 1.0000e-03\n",
      "Epoch 245/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0273 - val_loss: 36.5534 - lr: 1.0000e-04\n",
      "Epoch 246/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 37.0273 - val_loss: 36.5537 - lr: 1.0000e-04\n",
      "Epoch 247/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 37.0271 - val_loss: 36.5535 - lr: 1.0000e-04\n",
      "Epoch 248/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0269 - val_loss: 36.5535 - lr: 1.0000e-05\n",
      "Epoch 249/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0269 - val_loss: 36.5535 - lr: 1.0000e-05\n",
      "Epoch 250/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0268 - val_loss: 36.5535 - lr: 1.0000e-05\n",
      "Epoch 251/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0269 - val_loss: 36.5535 - lr: 1.0000e-05\n",
      "Epoch 252/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0269 - val_loss: 36.5535 - lr: 1.0000e-05\n",
      "Epoch 253/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0269 - val_loss: 36.5535 - lr: 1.0000e-05\n",
      "Epoch 254/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0269 - val_loss: 36.5535 - lr: 1.0000e-05\n",
      "Epoch 255/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0268 - val_loss: 36.5535 - lr: 1.0000e-05\n",
      "Epoch 256/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0269 - val_loss: 36.5535 - lr: 1.0000e-05\n",
      "Epoch 257/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0268 - val_loss: 36.5535 - lr: 1.0000e-05\n",
      "Epoch 258/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0269 - val_loss: 36.5535 - lr: 1.0000e-05\n",
      "Epoch 259/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0268 - val_loss: 36.5535 - lr: 1.0000e-05\n",
      "Epoch 260/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0269 - val_loss: 36.5535 - lr: 1.0000e-05\n",
      "Epoch 261/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0268 - val_loss: 36.5535 - lr: 1.0000e-05\n",
      "220/220 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "neural_network.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), \n",
    "              loss='mse')\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-5)\n",
    "\n",
    "neural_network.fit(\n",
    "    X_train_scaled, y_train, \n",
    "    epochs=300, batch_size=1024, \n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    callbacks=[reduce_lr, early_stopping]\n",
    ")\n",
    "\n",
    "predictions = neural_network.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Relative Difference: 0.20481709490241856\n",
      "Mean Squared Error: 36.553635043665196\n",
      "R2_score = 0.571891050722696\n"
     ]
    }
   ],
   "source": [
    "predictions = predictions.reshape((predictions.shape[0]))\n",
    "mse = mean_squared_error(y_test, predictions.T)\n",
    "average_relative_difference = np.mean(abs(y_test - predictions.T) / y_test)\n",
    "print(f'Average Relative Difference: {average_relative_difference}')\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R2_score = {r2_score(y_test, predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_diffs = np.sort(abs(y_test - predictions.T) / y_test) * 100\n",
    "plt.hist(sorted_diffs)\n",
    "plt.xlabel('relative difference (%)')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jednostavna linearna regresija (bez skrivenih slojeva) sa polinomijalno transformiranim zna훾ajkama "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 1)                 121       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121 (484.00 Byte)\n",
      "Trainable params: 121 (484.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = X_train_scaled_poly.shape[1]\n",
    "\n",
    "input_shape = (input_size,)\n",
    "neural_network = create_neural_network(input_shape, [], [])\n",
    "\n",
    "neural_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 8ms/step - loss: 762.1467 - val_loss: 731.9682 - lr: 0.0100\n",
      "Epoch 2/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 731.1776 - val_loss: 714.5160 - lr: 0.0100\n",
      "Epoch 3/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 716.0529 - val_loss: 701.5215 - lr: 0.0100\n",
      "Epoch 4/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 704.0244 - val_loss: 689.7394 - lr: 0.0100\n",
      "Epoch 5/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 692.0544 - val_loss: 678.4059 - lr: 0.0100\n",
      "Epoch 6/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 680.8082 - val_loss: 667.2024 - lr: 0.0100\n",
      "Epoch 7/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 669.5236 - val_loss: 656.1531 - lr: 0.0100\n",
      "Epoch 8/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 658.5407 - val_loss: 645.4943 - lr: 0.0100\n",
      "Epoch 9/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 647.7903 - val_loss: 634.5388 - lr: 0.0100\n",
      "Epoch 10/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 636.8845 - val_loss: 624.0784 - lr: 0.0100\n",
      "Epoch 11/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 626.4607 - val_loss: 613.5930 - lr: 0.0100\n",
      "Epoch 12/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 615.9816 - val_loss: 603.3977 - lr: 0.0100\n",
      "Epoch 13/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 605.7350 - val_loss: 593.1107 - lr: 0.0100\n",
      "Epoch 14/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 595.5535 - val_loss: 583.1001 - lr: 0.0100\n",
      "Epoch 15/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 585.6719 - val_loss: 573.1624 - lr: 0.0100\n",
      "Epoch 16/300\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 575.7501 - val_loss: 563.5199 - lr: 0.0100\n",
      "Epoch 17/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 565.9842 - val_loss: 553.7885 - lr: 0.0100\n",
      "Epoch 18/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 556.3431 - val_loss: 544.4352 - lr: 0.0100\n",
      "Epoch 19/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 546.8655 - val_loss: 534.9327 - lr: 0.0100\n",
      "Epoch 20/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 537.6077 - val_loss: 525.8489 - lr: 0.0100\n",
      "Epoch 21/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 528.3159 - val_loss: 516.7166 - lr: 0.0100\n",
      "Epoch 22/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 519.2601 - val_loss: 507.6772 - lr: 0.0100\n",
      "Epoch 23/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 510.4241 - val_loss: 499.0347 - lr: 0.0100\n",
      "Epoch 24/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 501.4118 - val_loss: 490.1931 - lr: 0.0100\n",
      "Epoch 25/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 492.5746 - val_loss: 481.5025 - lr: 0.0100\n",
      "Epoch 26/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 484.0969 - val_loss: 473.1231 - lr: 0.0100\n",
      "Epoch 27/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 475.5791 - val_loss: 464.6301 - lr: 0.0100\n",
      "Epoch 28/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 467.1943 - val_loss: 456.5263 - lr: 0.0100\n",
      "Epoch 29/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 458.9312 - val_loss: 448.3119 - lr: 0.0100\n",
      "Epoch 30/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 450.8564 - val_loss: 440.3707 - lr: 0.0100\n",
      "Epoch 31/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 442.8571 - val_loss: 432.3896 - lr: 0.0100\n",
      "Epoch 32/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 434.9967 - val_loss: 424.7672 - lr: 0.0100\n",
      "Epoch 33/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 427.2776 - val_loss: 417.0713 - lr: 0.0100\n",
      "Epoch 34/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 419.6010 - val_loss: 409.3539 - lr: 0.0100\n",
      "Epoch 35/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 411.9397 - val_loss: 402.0744 - lr: 0.0100\n",
      "Epoch 36/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 404.5894 - val_loss: 394.6409 - lr: 0.0100\n",
      "Epoch 37/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 397.1796 - val_loss: 387.3423 - lr: 0.0100\n",
      "Epoch 38/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 389.8407 - val_loss: 380.3592 - lr: 0.0100\n",
      "Epoch 39/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 382.7928 - val_loss: 373.2015 - lr: 0.0100\n",
      "Epoch 40/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 375.7638 - val_loss: 366.3735 - lr: 0.0100\n",
      "Epoch 41/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 368.8786 - val_loss: 359.5273 - lr: 0.0100\n",
      "Epoch 42/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 362.0042 - val_loss: 352.8053 - lr: 0.0100\n",
      "Epoch 43/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 355.3406 - val_loss: 346.1058 - lr: 0.0100\n",
      "Epoch 44/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 348.6996 - val_loss: 339.6147 - lr: 0.0100\n",
      "Epoch 45/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 342.2936 - val_loss: 333.1852 - lr: 0.0100\n",
      "Epoch 46/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 335.7839 - val_loss: 327.1849 - lr: 0.0100\n",
      "Epoch 47/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 329.4819 - val_loss: 320.6205 - lr: 0.0100\n",
      "Epoch 48/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 323.3376 - val_loss: 314.7499 - lr: 0.0100\n",
      "Epoch 49/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 317.0553 - val_loss: 308.5429 - lr: 0.0100\n",
      "Epoch 50/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 311.1463 - val_loss: 302.5741 - lr: 0.0100\n",
      "Epoch 51/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 305.1410 - val_loss: 296.9884 - lr: 0.0100\n",
      "Epoch 52/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 299.1925 - val_loss: 291.0514 - lr: 0.0100\n",
      "Epoch 53/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 293.4225 - val_loss: 285.3455 - lr: 0.0100\n",
      "Epoch 54/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 287.7235 - val_loss: 279.7843 - lr: 0.0100\n",
      "Epoch 55/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 282.2034 - val_loss: 274.3717 - lr: 0.0100\n",
      "Epoch 56/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 276.6892 - val_loss: 268.8346 - lr: 0.0100\n",
      "Epoch 57/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 271.3104 - val_loss: 263.5730 - lr: 0.0100\n",
      "Epoch 58/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 265.9694 - val_loss: 258.4092 - lr: 0.0100\n",
      "Epoch 59/300\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 260.7813 - val_loss: 253.1660 - lr: 0.0100\n",
      "Epoch 60/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 255.6184 - val_loss: 248.1958 - lr: 0.0100\n",
      "Epoch 61/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 250.5451 - val_loss: 243.1640 - lr: 0.0100\n",
      "Epoch 62/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 245.5142 - val_loss: 238.3518 - lr: 0.0100\n",
      "Epoch 63/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 240.6115 - val_loss: 233.4416 - lr: 0.0100\n",
      "Epoch 64/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 235.8765 - val_loss: 228.8318 - lr: 0.0100\n",
      "Epoch 65/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 231.1576 - val_loss: 224.1974 - lr: 0.0100\n",
      "Epoch 66/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 226.4695 - val_loss: 219.5596 - lr: 0.0100\n",
      "Epoch 67/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 221.9069 - val_loss: 215.2428 - lr: 0.0100\n",
      "Epoch 68/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 217.3668 - val_loss: 210.6319 - lr: 0.0100\n",
      "Epoch 69/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 212.9639 - val_loss: 206.3142 - lr: 0.0100\n",
      "Epoch 70/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 208.5466 - val_loss: 202.0565 - lr: 0.0100\n",
      "Epoch 71/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 204.2475 - val_loss: 197.8031 - lr: 0.0100\n",
      "Epoch 72/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 200.2271 - val_loss: 193.8474 - lr: 0.0100\n",
      "Epoch 73/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 196.0876 - val_loss: 189.9653 - lr: 0.0100\n",
      "Epoch 74/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 191.9445 - val_loss: 185.6826 - lr: 0.0100\n",
      "Epoch 75/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 187.9750 - val_loss: 181.8783 - lr: 0.0100\n",
      "Epoch 76/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 184.0571 - val_loss: 178.0843 - lr: 0.0100\n",
      "Epoch 77/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 180.2651 - val_loss: 174.2171 - lr: 0.0100\n",
      "Epoch 78/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 176.5168 - val_loss: 170.6696 - lr: 0.0100\n",
      "Epoch 79/300\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 172.8396 - val_loss: 166.9761 - lr: 0.0100\n",
      "Epoch 80/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 169.1549 - val_loss: 163.3893 - lr: 0.0100\n",
      "Epoch 81/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 165.5848 - val_loss: 159.9343 - lr: 0.0100\n",
      "Epoch 82/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 162.1246 - val_loss: 156.4772 - lr: 0.0100\n",
      "Epoch 83/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 158.6447 - val_loss: 153.1749 - lr: 0.0100\n",
      "Epoch 84/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 155.2888 - val_loss: 149.9278 - lr: 0.0100\n",
      "Epoch 85/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 152.0204 - val_loss: 146.6316 - lr: 0.0100\n",
      "Epoch 86/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 148.7862 - val_loss: 143.6418 - lr: 0.0100\n",
      "Epoch 87/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 145.5918 - val_loss: 140.3501 - lr: 0.0100\n",
      "Epoch 88/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 142.4841 - val_loss: 137.4373 - lr: 0.0100\n",
      "Epoch 89/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 139.4393 - val_loss: 134.3349 - lr: 0.0100\n",
      "Epoch 90/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 136.4312 - val_loss: 131.5150 - lr: 0.0100\n",
      "Epoch 91/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 133.5112 - val_loss: 128.7130 - lr: 0.0100\n",
      "Epoch 92/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 130.6675 - val_loss: 125.8099 - lr: 0.0100\n",
      "Epoch 93/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 127.9018 - val_loss: 123.0877 - lr: 0.0100\n",
      "Epoch 94/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 125.0890 - val_loss: 120.4075 - lr: 0.0100\n",
      "Epoch 95/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 122.4070 - val_loss: 117.7271 - lr: 0.0100\n",
      "Epoch 96/300\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 119.7613 - val_loss: 115.2181 - lr: 0.0100\n",
      "Epoch 97/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 117.1818 - val_loss: 112.7332 - lr: 0.0100\n",
      "Epoch 98/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.6284 - val_loss: 110.1788 - lr: 0.0100\n",
      "Epoch 99/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.1905 - val_loss: 107.7647 - lr: 0.0100\n",
      "Epoch 100/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 109.7774 - val_loss: 105.4750 - lr: 0.0100\n",
      "Epoch 101/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 107.4430 - val_loss: 103.1226 - lr: 0.0100\n",
      "Epoch 102/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 105.0706 - val_loss: 100.9818 - lr: 0.0100\n",
      "Epoch 103/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 102.8543 - val_loss: 98.6911 - lr: 0.0100\n",
      "Epoch 104/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 100.6090 - val_loss: 96.5541 - lr: 0.0100\n",
      "Epoch 105/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 98.4826 - val_loss: 94.5411 - lr: 0.0100\n",
      "Epoch 106/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 96.3489 - val_loss: 92.3860 - lr: 0.0100\n",
      "Epoch 107/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 94.2764 - val_loss: 90.4005 - lr: 0.0100\n",
      "Epoch 108/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 92.2481 - val_loss: 88.3896 - lr: 0.0100\n",
      "Epoch 109/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 90.3190 - val_loss: 86.5107 - lr: 0.0100\n",
      "Epoch 110/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 88.4066 - val_loss: 84.7097 - lr: 0.0100\n",
      "Epoch 111/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 86.4923 - val_loss: 82.9056 - lr: 0.0100\n",
      "Epoch 112/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 84.6371 - val_loss: 81.0217 - lr: 0.0100\n",
      "Epoch 113/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 82.8825 - val_loss: 79.3770 - lr: 0.0100\n",
      "Epoch 114/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 81.1434 - val_loss: 77.6283 - lr: 0.0100\n",
      "Epoch 115/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 79.4426 - val_loss: 76.0322 - lr: 0.0100\n",
      "Epoch 116/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 77.7620 - val_loss: 74.3762 - lr: 0.0100\n",
      "Epoch 117/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 76.1654 - val_loss: 72.8099 - lr: 0.0100\n",
      "Epoch 118/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 74.5722 - val_loss: 71.4382 - lr: 0.0100\n",
      "Epoch 119/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 73.1001 - val_loss: 69.8832 - lr: 0.0100\n",
      "Epoch 120/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 71.5534 - val_loss: 68.4400 - lr: 0.0100\n",
      "Epoch 121/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 70.0955 - val_loss: 66.9569 - lr: 0.0100\n",
      "Epoch 122/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 68.6958 - val_loss: 65.6441 - lr: 0.0100\n",
      "Epoch 123/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 67.2944 - val_loss: 64.3295 - lr: 0.0100\n",
      "Epoch 124/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 65.9459 - val_loss: 62.9868 - lr: 0.0100\n",
      "Epoch 125/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 64.6590 - val_loss: 61.8804 - lr: 0.0100\n",
      "Epoch 126/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 63.4048 - val_loss: 60.5726 - lr: 0.0100\n",
      "Epoch 127/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 62.1603 - val_loss: 59.4535 - lr: 0.0100\n",
      "Epoch 128/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 60.9643 - val_loss: 58.2108 - lr: 0.0100\n",
      "Epoch 129/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 59.8182 - val_loss: 57.0777 - lr: 0.0100\n",
      "Epoch 130/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 58.6780 - val_loss: 55.9842 - lr: 0.0100\n",
      "Epoch 131/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 57.5873 - val_loss: 54.9460 - lr: 0.0100\n",
      "Epoch 132/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 56.5048 - val_loss: 53.9817 - lr: 0.0100\n",
      "Epoch 133/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 55.4551 - val_loss: 52.9712 - lr: 0.0100\n",
      "Epoch 134/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 54.4827 - val_loss: 51.9705 - lr: 0.0100\n",
      "Epoch 135/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 53.5039 - val_loss: 51.1301 - lr: 0.0100\n",
      "Epoch 136/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 52.5731 - val_loss: 50.1661 - lr: 0.0100\n",
      "Epoch 137/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 51.6825 - val_loss: 49.3043 - lr: 0.0100\n",
      "Epoch 138/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 50.7737 - val_loss: 48.4613 - lr: 0.0100\n",
      "Epoch 139/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 49.9506 - val_loss: 47.6696 - lr: 0.0100\n",
      "Epoch 140/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 49.1115 - val_loss: 46.8538 - lr: 0.0100\n",
      "Epoch 141/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 48.2788 - val_loss: 46.0499 - lr: 0.0100\n",
      "Epoch 142/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 47.5128 - val_loss: 45.3175 - lr: 0.0100\n",
      "Epoch 143/300\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 46.7724 - val_loss: 44.6908 - lr: 0.0100\n",
      "Epoch 144/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 46.0633 - val_loss: 43.9512 - lr: 0.0100\n",
      "Epoch 145/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 45.3275 - val_loss: 43.2391 - lr: 0.0100\n",
      "Epoch 146/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 44.6598 - val_loss: 42.5971 - lr: 0.0100\n",
      "Epoch 147/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 43.9994 - val_loss: 41.9958 - lr: 0.0100\n",
      "Epoch 148/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 43.3799 - val_loss: 41.3841 - lr: 0.0100\n",
      "Epoch 149/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 42.7780 - val_loss: 40.8086 - lr: 0.0100\n",
      "Epoch 150/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 42.2156 - val_loss: 40.2623 - lr: 0.0100\n",
      "Epoch 151/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 41.6511 - val_loss: 39.7102 - lr: 0.0100\n",
      "Epoch 152/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 41.0998 - val_loss: 39.3041 - lr: 0.0100\n",
      "Epoch 153/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 40.6043 - val_loss: 38.7048 - lr: 0.0100\n",
      "Epoch 154/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 40.0376 - val_loss: 38.2544 - lr: 0.0100\n",
      "Epoch 155/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 39.5403 - val_loss: 37.9226 - lr: 0.0100\n",
      "Epoch 156/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 39.1282 - val_loss: 37.4680 - lr: 0.0100\n",
      "Epoch 157/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 38.6625 - val_loss: 36.9632 - lr: 0.0100\n",
      "Epoch 158/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 38.2397 - val_loss: 36.5039 - lr: 0.0100\n",
      "Epoch 159/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.8103 - val_loss: 36.1771 - lr: 0.0100\n",
      "Epoch 160/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.3972 - val_loss: 35.8597 - lr: 0.0100\n",
      "Epoch 161/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.0132 - val_loss: 35.5195 - lr: 0.0100\n",
      "Epoch 162/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 36.6509 - val_loss: 35.0999 - lr: 0.0100\n",
      "Epoch 163/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 36.2858 - val_loss: 34.8986 - lr: 0.0100\n",
      "Epoch 164/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 35.9870 - val_loss: 34.5586 - lr: 0.0100\n",
      "Epoch 165/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 35.6462 - val_loss: 34.1945 - lr: 0.0100\n",
      "Epoch 166/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 35.3561 - val_loss: 33.8540 - lr: 0.0100\n",
      "Epoch 167/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 35.0669 - val_loss: 33.6353 - lr: 0.0100\n",
      "Epoch 168/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 34.7768 - val_loss: 33.3609 - lr: 0.0100\n",
      "Epoch 169/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 34.5191 - val_loss: 33.1455 - lr: 0.0100\n",
      "Epoch 170/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 34.2583 - val_loss: 32.8769 - lr: 0.0100\n",
      "Epoch 171/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 34.0132 - val_loss: 32.6774 - lr: 0.0100\n",
      "Epoch 172/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 33.7701 - val_loss: 32.4951 - lr: 0.0100\n",
      "Epoch 173/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 33.5399 - val_loss: 32.2352 - lr: 0.0100\n",
      "Epoch 174/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 33.3272 - val_loss: 32.0910 - lr: 0.0100\n",
      "Epoch 175/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 33.1193 - val_loss: 31.8519 - lr: 0.0100\n",
      "Epoch 176/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 32.9414 - val_loss: 31.7026 - lr: 0.0100\n",
      "Epoch 177/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 32.7369 - val_loss: 31.5760 - lr: 0.0100\n",
      "Epoch 178/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 32.5740 - val_loss: 31.3783 - lr: 0.0100\n",
      "Epoch 179/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 32.3971 - val_loss: 31.2335 - lr: 0.0100\n",
      "Epoch 180/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 32.2553 - val_loss: 31.1757 - lr: 0.0100\n",
      "Epoch 181/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 32.1034 - val_loss: 31.0629 - lr: 0.0100\n",
      "Epoch 182/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 31.9737 - val_loss: 30.9432 - lr: 0.0100\n",
      "Epoch 183/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 31.8449 - val_loss: 30.7138 - lr: 0.0100\n",
      "Epoch 184/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 31.7248 - val_loss: 30.6106 - lr: 0.0100\n",
      "Epoch 185/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 31.5906 - val_loss: 30.5022 - lr: 0.0100\n",
      "Epoch 186/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 31.4620 - val_loss: 30.5168 - lr: 0.0100\n",
      "Epoch 187/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 31.3819 - val_loss: 30.3047 - lr: 0.0100\n",
      "Epoch 188/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 31.2812 - val_loss: 30.2882 - lr: 0.0100\n",
      "Epoch 189/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 31.1738 - val_loss: 30.0775 - lr: 0.0100\n",
      "Epoch 190/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 31.0885 - val_loss: 30.0758 - lr: 0.0100\n",
      "Epoch 191/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 31.0153 - val_loss: 30.0123 - lr: 0.0100\n",
      "Epoch 192/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 30.9138 - val_loss: 29.8886 - lr: 0.0100\n",
      "Epoch 193/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 30.8352 - val_loss: 29.8577 - lr: 0.0100\n",
      "Epoch 194/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 30.7632 - val_loss: 29.8162 - lr: 0.0100\n",
      "Epoch 195/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 30.7075 - val_loss: 29.7790 - lr: 0.0100\n",
      "Epoch 196/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 30.6618 - val_loss: 29.8105 - lr: 0.0100\n",
      "Epoch 197/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 30.5941 - val_loss: 29.6522 - lr: 0.0100\n",
      "Epoch 198/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 30.4974 - val_loss: 29.6015 - lr: 0.0100\n",
      "Epoch 199/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 30.4725 - val_loss: 29.6088 - lr: 0.0100\n",
      "Epoch 200/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 30.4406 - val_loss: 29.5443 - lr: 0.0100\n",
      "Epoch 201/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 30.3951 - val_loss: 29.4513 - lr: 0.0100\n",
      "Epoch 202/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 30.3771 - val_loss: 29.3781 - lr: 0.0100\n",
      "Epoch 203/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 30.3116 - val_loss: 29.3982 - lr: 0.0100\n",
      "Epoch 204/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 30.2656 - val_loss: 29.3688 - lr: 0.0100\n",
      "Epoch 205/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 30.2463 - val_loss: 29.3180 - lr: 0.0100\n",
      "Epoch 206/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 30.1654 - val_loss: 29.3778 - lr: 0.0100\n",
      "Epoch 207/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 30.1696 - val_loss: 29.3324 - lr: 0.0100\n",
      "Epoch 208/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 30.1247 - val_loss: 29.3163 - lr: 0.0100\n",
      "Epoch 209/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 30.1097 - val_loss: 29.2593 - lr: 0.0100\n",
      "Epoch 210/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 30.1000 - val_loss: 29.2573 - lr: 0.0100\n",
      "Epoch 211/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 30.0759 - val_loss: 29.2334 - lr: 0.0100\n",
      "Epoch 212/300\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 30.0733 - val_loss: 29.3344 - lr: 0.0100\n",
      "Epoch 213/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 30.0583 - val_loss: 29.2987 - lr: 0.0100\n",
      "Epoch 214/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 30.0130 - val_loss: 29.3315 - lr: 0.0100\n",
      "Epoch 215/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 29.9679 - val_loss: 29.1845 - lr: 1.0000e-03\n",
      "Epoch 216/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 29.9345 - val_loss: 29.1575 - lr: 1.0000e-03\n",
      "Epoch 217/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 29.9304 - val_loss: 29.1585 - lr: 1.0000e-03\n",
      "Epoch 218/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 29.9296 - val_loss: 29.1346 - lr: 1.0000e-03\n",
      "Epoch 219/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 29.9256 - val_loss: 29.1575 - lr: 1.0000e-03\n",
      "Epoch 220/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 29.9221 - val_loss: 29.1481 - lr: 1.0000e-03\n",
      "Epoch 221/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 29.9208 - val_loss: 29.1380 - lr: 1.0000e-03\n",
      "Epoch 222/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 29.9149 - val_loss: 29.1388 - lr: 1.0000e-04\n",
      "Epoch 223/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 29.9142 - val_loss: 29.1408 - lr: 1.0000e-04\n",
      "Epoch 224/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 29.9138 - val_loss: 29.1405 - lr: 1.0000e-04\n",
      "Epoch 225/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 29.9133 - val_loss: 29.1405 - lr: 1.0000e-05\n",
      "Epoch 226/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 29.9133 - val_loss: 29.1405 - lr: 1.0000e-05\n",
      "Epoch 227/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 29.9133 - val_loss: 29.1406 - lr: 1.0000e-05\n",
      "Epoch 228/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 29.9132 - val_loss: 29.1406 - lr: 1.0000e-05\n",
      "Epoch 229/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 29.9132 - val_loss: 29.1406 - lr: 1.0000e-05\n",
      "Epoch 230/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 29.9132 - val_loss: 29.1405 - lr: 1.0000e-05\n",
      "Epoch 231/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 29.9132 - val_loss: 29.1406 - lr: 1.0000e-05\n",
      "Epoch 232/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 29.9131 - val_loss: 29.1406 - lr: 1.0000e-05\n",
      "Epoch 233/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 29.9131 - val_loss: 29.1405 - lr: 1.0000e-05\n",
      "Epoch 234/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 29.9132 - val_loss: 29.1405 - lr: 1.0000e-05\n",
      "Epoch 235/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 29.9131 - val_loss: 29.1406 - lr: 1.0000e-05\n",
      "Epoch 236/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 29.9131 - val_loss: 29.1407 - lr: 1.0000e-05\n",
      "Epoch 237/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 29.9130 - val_loss: 29.1407 - lr: 1.0000e-05\n",
      "Epoch 238/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 29.9130 - val_loss: 29.1407 - lr: 1.0000e-05\n",
      "220/220 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "neural_network.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), \n",
    "              loss='mse')\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-5)\n",
    "\n",
    "neural_network.fit(\n",
    "    X_train_scaled_poly, y_train, \n",
    "    epochs=300, batch_size=1024, \n",
    "    validation_data=(X_val_scaled_poly, y_val),\n",
    "    callbacks=[reduce_lr, early_stopping]\n",
    ")\n",
    "\n",
    "predictions = neural_network.predict(X_test_scaled_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Relative Difference: 0.1807754039558531\n",
      "Mean Squared Error: 29.60471028830824\n",
      "R2_score = 0.653275484092161\n"
     ]
    }
   ],
   "source": [
    "predictions = predictions.reshape((predictions.shape[0]))\n",
    "mse = mean_squared_error(y_test, predictions.T)\n",
    "average_relative_difference = np.mean(abs(y_test - predictions.T) / y_test)\n",
    "print(f'Average Relative Difference: {average_relative_difference}')\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R2_score = {r2_score(y_test, predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_diffs = np.sort(abs(y_test - predictions.T) / y_test) * 100\n",
    "plt.hist(sorted_diffs)\n",
    "plt.xlabel('relative difference (%)')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linearna regresija sa skrivenim slojevima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 64)                2560      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5185 (20.25 KB)\n",
      "Trainable params: 5185 (20.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = X_train_scaled.shape[1]\n",
    "\n",
    "input_shape = (input_size,)\n",
    "hidden_layer_sizes = [64, 32, 16]\n",
    "activation_functions = ['relu', 'sigmoid', 'relu']\n",
    "\n",
    "neural_network = create_neural_network(input_shape, hidden_layer_sizes, activation_functions)\n",
    "\n",
    "neural_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "22/22 [==============================] - 1s 10ms/step - loss: 390.4366 - val_loss: 82.1637 - lr: 0.0100\n",
      "Epoch 2/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 89.1878 - val_loss: 73.2515 - lr: 0.0100\n",
      "Epoch 3/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 66.0761 - val_loss: 56.7352 - lr: 0.0100\n",
      "Epoch 4/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 51.6766 - val_loss: 45.5245 - lr: 0.0100\n",
      "Epoch 5/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 41.5177 - val_loss: 37.6899 - lr: 0.0100\n",
      "Epoch 6/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 36.4989 - val_loss: 34.8239 - lr: 0.0100\n",
      "Epoch 7/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 33.9132 - val_loss: 32.7543 - lr: 0.0100\n",
      "Epoch 8/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 32.0329 - val_loss: 31.0166 - lr: 0.0100\n",
      "Epoch 9/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 30.0919 - val_loss: 29.2371 - lr: 0.0100\n",
      "Epoch 10/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 28.3796 - val_loss: 27.5858 - lr: 0.0100\n",
      "Epoch 11/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 26.7863 - val_loss: 26.1731 - lr: 0.0100\n",
      "Epoch 12/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 25.6927 - val_loss: 25.5544 - lr: 0.0100\n",
      "Epoch 13/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 24.9668 - val_loss: 24.6457 - lr: 0.0100\n",
      "Epoch 14/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 24.0451 - val_loss: 24.1509 - lr: 0.0100\n",
      "Epoch 15/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 23.1925 - val_loss: 23.2042 - lr: 0.0100\n",
      "Epoch 16/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 22.4251 - val_loss: 22.8953 - lr: 0.0100\n",
      "Epoch 17/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 21.7440 - val_loss: 22.0591 - lr: 0.0100\n",
      "Epoch 18/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 21.1255 - val_loss: 21.3785 - lr: 0.0100\n",
      "Epoch 19/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 20.5892 - val_loss: 21.1717 - lr: 0.0100\n",
      "Epoch 20/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 20.1016 - val_loss: 20.7999 - lr: 0.0100\n",
      "Epoch 21/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 19.7847 - val_loss: 20.4381 - lr: 0.0100\n",
      "Epoch 22/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 19.3818 - val_loss: 20.5079 - lr: 0.0100\n",
      "Epoch 23/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 19.0534 - val_loss: 20.1614 - lr: 0.0100\n",
      "Epoch 24/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 18.8683 - val_loss: 19.6958 - lr: 0.0100\n",
      "Epoch 25/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 18.6117 - val_loss: 20.1394 - lr: 0.0100\n",
      "Epoch 26/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 18.4068 - val_loss: 19.8311 - lr: 0.0100\n",
      "Epoch 27/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 18.1303 - val_loss: 19.5322 - lr: 0.0100\n",
      "Epoch 28/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 18.0162 - val_loss: 19.6014 - lr: 0.0100\n",
      "Epoch 29/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 17.9011 - val_loss: 19.2498 - lr: 0.0100\n",
      "Epoch 30/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 17.6140 - val_loss: 19.0551 - lr: 0.0100\n",
      "Epoch 31/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 17.2998 - val_loss: 18.6635 - lr: 0.0100\n",
      "Epoch 32/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 17.1272 - val_loss: 18.6422 - lr: 0.0100\n",
      "Epoch 33/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 16.9759 - val_loss: 18.6348 - lr: 0.0100\n",
      "Epoch 34/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 16.8363 - val_loss: 18.3647 - lr: 0.0100\n",
      "Epoch 35/300\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 16.6391 - val_loss: 18.1828 - lr: 0.0100\n",
      "Epoch 36/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.5079 - val_loss: 18.2142 - lr: 0.0100\n",
      "Epoch 37/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.4453 - val_loss: 18.0765 - lr: 0.0100\n",
      "Epoch 38/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 16.2626 - val_loss: 18.1389 - lr: 0.0100\n",
      "Epoch 39/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.1738 - val_loss: 17.9566 - lr: 0.0100\n",
      "Epoch 40/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.1268 - val_loss: 17.7652 - lr: 0.0100\n",
      "Epoch 41/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 15.9493 - val_loss: 18.0651 - lr: 0.0100\n",
      "Epoch 42/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 15.8605 - val_loss: 17.6547 - lr: 0.0100\n",
      "Epoch 43/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 15.6663 - val_loss: 17.7120 - lr: 0.0100\n",
      "Epoch 44/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 15.5163 - val_loss: 17.7339 - lr: 0.0100\n",
      "Epoch 45/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 15.4246 - val_loss: 17.3399 - lr: 0.0100\n",
      "Epoch 46/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 15.3153 - val_loss: 17.5684 - lr: 0.0100\n",
      "Epoch 47/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 15.3716 - val_loss: 17.9558 - lr: 0.0100\n",
      "Epoch 48/300\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 15.3369 - val_loss: 17.5463 - lr: 0.0100\n",
      "Epoch 49/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 14.8469 - val_loss: 17.1238 - lr: 1.0000e-03\n",
      "Epoch 50/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 14.6404 - val_loss: 17.1719 - lr: 1.0000e-03\n",
      "Epoch 51/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 14.5924 - val_loss: 17.2035 - lr: 1.0000e-03\n",
      "Epoch 52/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 14.5726 - val_loss: 17.1488 - lr: 1.0000e-03\n",
      "Epoch 53/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 14.5092 - val_loss: 17.1535 - lr: 1.0000e-04\n",
      "Epoch 54/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 14.5036 - val_loss: 17.1624 - lr: 1.0000e-04\n",
      "Epoch 55/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 14.5010 - val_loss: 17.1607 - lr: 1.0000e-04\n",
      "Epoch 56/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 14.4939 - val_loss: 17.1612 - lr: 1.0000e-05\n",
      "Epoch 57/300\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 14.4936 - val_loss: 17.1613 - lr: 1.0000e-05\n",
      "Epoch 58/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 14.4933 - val_loss: 17.1612 - lr: 1.0000e-05\n",
      "Epoch 59/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 14.4932 - val_loss: 17.1609 - lr: 1.0000e-05\n",
      "Epoch 60/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 14.4930 - val_loss: 17.1606 - lr: 1.0000e-05\n",
      "Epoch 61/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 14.4928 - val_loss: 17.1609 - lr: 1.0000e-05\n",
      "Epoch 62/300\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 14.4927 - val_loss: 17.1607 - lr: 1.0000e-05\n",
      "Epoch 63/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 14.4925 - val_loss: 17.1613 - lr: 1.0000e-05\n",
      "Epoch 64/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 14.4923 - val_loss: 17.1615 - lr: 1.0000e-05\n",
      "Epoch 65/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 14.4922 - val_loss: 17.1610 - lr: 1.0000e-05\n",
      "Epoch 66/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 14.4919 - val_loss: 17.1607 - lr: 1.0000e-05\n",
      "Epoch 67/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 14.4918 - val_loss: 17.1613 - lr: 1.0000e-05\n",
      "Epoch 68/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 14.4915 - val_loss: 17.1614 - lr: 1.0000e-05\n",
      "Epoch 69/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 14.4914 - val_loss: 17.1611 - lr: 1.0000e-05\n",
      "220/220 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "neural_network.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), \n",
    "              loss='mse')\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-5)\n",
    "\n",
    "neural_network.fit(\n",
    "    X_train_scaled, y_train, \n",
    "    epochs=300, batch_size=1024, \n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    callbacks=[reduce_lr, early_stopping]\n",
    ")\n",
    "\n",
    "predictions = neural_network.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Relative Difference: 0.13994079799243378\n",
      "Mean Squared Error: 17.51026963029489\n",
      "R2_score = 0.7949231827687421\n"
     ]
    }
   ],
   "source": [
    "predictions = predictions.reshape((predictions.shape[0]))\n",
    "mse = mean_squared_error(y_test, predictions.T)\n",
    "average_relative_difference = np.mean(abs(y_test - predictions.T) / y_test)\n",
    "print(f'Average Relative Difference: {average_relative_difference}')\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R2_score = {r2_score(y_test, predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_diffs = np.sort(abs(y_test - predictions.T) / y_test * 100)\n",
    "plt.hist(sorted_diffs)\n",
    "plt.xlabel('relative difference (%)')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linearna regresija sa skrivenim slojevima i polinomijalno transformiranim zna훾ajkama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 64)                7744      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10369 (40.50 KB)\n",
      "Trainable params: 10369 (40.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = X_train_scaled_poly.shape[1]\n",
    "\n",
    "input_shape = (input_size,)\n",
    "hidden_layer_sizes = [64, 32, 16]\n",
    "activation_functions = ['relu', 'sigmoid', 'relu']\n",
    "\n",
    "neural_network = create_neural_network(input_shape, hidden_layer_sizes, activation_functions)\n",
    "\n",
    "neural_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "22/22 [==============================] - 1s 10ms/step - loss: 351.4550 - val_loss: 93.9392 - lr: 0.0100\n",
      "Epoch 2/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 85.3656 - val_loss: 70.2833 - lr: 0.0100\n",
      "Epoch 3/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 62.1821 - val_loss: 51.3101 - lr: 0.0100\n",
      "Epoch 4/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 47.0497 - val_loss: 41.6628 - lr: 0.0100\n",
      "Epoch 5/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 39.0741 - val_loss: 35.6858 - lr: 0.0100\n",
      "Epoch 6/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 34.0829 - val_loss: 31.7449 - lr: 0.0100\n",
      "Epoch 7/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 30.2185 - val_loss: 28.6402 - lr: 0.0100\n",
      "Epoch 8/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 27.3829 - val_loss: 26.3689 - lr: 0.0100\n",
      "Epoch 9/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 25.1979 - val_loss: 24.6808 - lr: 0.0100\n",
      "Epoch 10/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 23.8127 - val_loss: 23.0579 - lr: 0.0100\n",
      "Epoch 11/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 22.5200 - val_loss: 22.6139 - lr: 0.0100\n",
      "Epoch 12/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 21.8064 - val_loss: 21.5105 - lr: 0.0100\n",
      "Epoch 13/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 21.0859 - val_loss: 21.5020 - lr: 0.0100\n",
      "Epoch 14/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 20.7529 - val_loss: 21.5882 - lr: 0.0100\n",
      "Epoch 15/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 20.7189 - val_loss: 21.4279 - lr: 0.0100\n",
      "Epoch 16/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 20.2353 - val_loss: 20.5683 - lr: 0.0100\n",
      "Epoch 17/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 19.8585 - val_loss: 20.6270 - lr: 0.0100\n",
      "Epoch 18/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 19.8084 - val_loss: 20.4180 - lr: 0.0100\n",
      "Epoch 19/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 19.4628 - val_loss: 20.0875 - lr: 0.0100\n",
      "Epoch 20/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 19.0965 - val_loss: 19.8100 - lr: 0.0100\n",
      "Epoch 21/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 18.9988 - val_loss: 19.8744 - lr: 0.0100\n",
      "Epoch 22/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 18.7668 - val_loss: 19.9466 - lr: 0.0100\n",
      "Epoch 23/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 18.7522 - val_loss: 19.6492 - lr: 0.0100\n",
      "Epoch 24/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 18.4145 - val_loss: 19.4192 - lr: 0.0100\n",
      "Epoch 25/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 18.2663 - val_loss: 19.4779 - lr: 0.0100\n",
      "Epoch 26/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 18.1422 - val_loss: 19.5192 - lr: 0.0100\n",
      "Epoch 27/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 18.2679 - val_loss: 19.4460 - lr: 0.0100\n",
      "Epoch 28/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 17.5386 - val_loss: 18.8467 - lr: 1.0000e-03\n",
      "Epoch 29/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 17.2206 - val_loss: 18.7083 - lr: 1.0000e-03\n",
      "Epoch 30/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 17.1118 - val_loss: 18.7164 - lr: 1.0000e-03\n",
      "Epoch 31/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 17.0655 - val_loss: 18.6042 - lr: 1.0000e-03\n",
      "Epoch 32/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 17.0697 - val_loss: 18.6178 - lr: 1.0000e-03\n",
      "Epoch 33/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 17.0320 - val_loss: 18.6269 - lr: 1.0000e-03\n",
      "Epoch 34/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 17.0006 - val_loss: 18.6621 - lr: 1.0000e-03\n",
      "Epoch 35/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.9183 - val_loss: 18.6271 - lr: 1.0000e-04\n",
      "Epoch 36/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.9048 - val_loss: 18.5974 - lr: 1.0000e-04\n",
      "Epoch 37/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8966 - val_loss: 18.5953 - lr: 1.0000e-04\n",
      "Epoch 38/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8974 - val_loss: 18.5976 - lr: 1.0000e-04\n",
      "Epoch 39/300\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 16.8930 - val_loss: 18.5913 - lr: 1.0000e-04\n",
      "Epoch 40/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8898 - val_loss: 18.5923 - lr: 1.0000e-04\n",
      "Epoch 41/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8874 - val_loss: 18.5957 - lr: 1.0000e-04\n",
      "Epoch 42/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8872 - val_loss: 18.5846 - lr: 1.0000e-04\n",
      "Epoch 43/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8826 - val_loss: 18.5900 - lr: 1.0000e-04\n",
      "Epoch 44/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8799 - val_loss: 18.5877 - lr: 1.0000e-04\n",
      "Epoch 45/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8786 - val_loss: 18.5841 - lr: 1.0000e-04\n",
      "Epoch 46/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8744 - val_loss: 18.5837 - lr: 1.0000e-04\n",
      "Epoch 47/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8737 - val_loss: 18.5803 - lr: 1.0000e-04\n",
      "Epoch 48/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8697 - val_loss: 18.5811 - lr: 1.0000e-04\n",
      "Epoch 49/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8684 - val_loss: 18.5764 - lr: 1.0000e-04\n",
      "Epoch 50/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8665 - val_loss: 18.5808 - lr: 1.0000e-04\n",
      "Epoch 51/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8635 - val_loss: 18.5773 - lr: 1.0000e-04\n",
      "Epoch 52/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8625 - val_loss: 18.5763 - lr: 1.0000e-04\n",
      "Epoch 53/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8516 - val_loss: 18.5762 - lr: 1.0000e-05\n",
      "Epoch 54/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8514 - val_loss: 18.5770 - lr: 1.0000e-05\n",
      "Epoch 55/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8512 - val_loss: 18.5771 - lr: 1.0000e-05\n",
      "Epoch 56/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8509 - val_loss: 18.5762 - lr: 1.0000e-05\n",
      "Epoch 57/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8507 - val_loss: 18.5757 - lr: 1.0000e-05\n",
      "Epoch 58/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8504 - val_loss: 18.5763 - lr: 1.0000e-05\n",
      "Epoch 59/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8500 - val_loss: 18.5763 - lr: 1.0000e-05\n",
      "Epoch 60/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8498 - val_loss: 18.5763 - lr: 1.0000e-05\n",
      "Epoch 61/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8497 - val_loss: 18.5758 - lr: 1.0000e-05\n",
      "Epoch 62/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8494 - val_loss: 18.5756 - lr: 1.0000e-05\n",
      "Epoch 63/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8492 - val_loss: 18.5755 - lr: 1.0000e-05\n",
      "Epoch 64/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8489 - val_loss: 18.5762 - lr: 1.0000e-05\n",
      "Epoch 65/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8485 - val_loss: 18.5761 - lr: 1.0000e-05\n",
      "Epoch 66/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8485 - val_loss: 18.5753 - lr: 1.0000e-05\n",
      "Epoch 67/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8482 - val_loss: 18.5763 - lr: 1.0000e-05\n",
      "Epoch 68/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8480 - val_loss: 18.5753 - lr: 1.0000e-05\n",
      "Epoch 69/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8479 - val_loss: 18.5753 - lr: 1.0000e-05\n",
      "Epoch 70/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8478 - val_loss: 18.5764 - lr: 1.0000e-05\n",
      "Epoch 71/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8472 - val_loss: 18.5746 - lr: 1.0000e-05\n",
      "Epoch 72/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8469 - val_loss: 18.5746 - lr: 1.0000e-05\n",
      "Epoch 73/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8467 - val_loss: 18.5745 - lr: 1.0000e-05\n",
      "Epoch 74/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8465 - val_loss: 18.5743 - lr: 1.0000e-05\n",
      "Epoch 75/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8463 - val_loss: 18.5749 - lr: 1.0000e-05\n",
      "Epoch 76/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8459 - val_loss: 18.5744 - lr: 1.0000e-05\n",
      "Epoch 77/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8456 - val_loss: 18.5744 - lr: 1.0000e-05\n",
      "Epoch 78/300\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 16.8455 - val_loss: 18.5751 - lr: 1.0000e-05\n",
      "Epoch 79/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8451 - val_loss: 18.5743 - lr: 1.0000e-05\n",
      "Epoch 80/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8450 - val_loss: 18.5745 - lr: 1.0000e-05\n",
      "Epoch 81/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8446 - val_loss: 18.5731 - lr: 1.0000e-05\n",
      "Epoch 82/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8444 - val_loss: 18.5731 - lr: 1.0000e-05\n",
      "Epoch 83/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8443 - val_loss: 18.5725 - lr: 1.0000e-05\n",
      "Epoch 84/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8436 - val_loss: 18.5729 - lr: 1.0000e-05\n",
      "Epoch 85/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8435 - val_loss: 18.5736 - lr: 1.0000e-05\n",
      "Epoch 86/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8433 - val_loss: 18.5730 - lr: 1.0000e-05\n",
      "Epoch 87/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8431 - val_loss: 18.5736 - lr: 1.0000e-05\n",
      "Epoch 88/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8428 - val_loss: 18.5731 - lr: 1.0000e-05\n",
      "Epoch 89/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8426 - val_loss: 18.5729 - lr: 1.0000e-05\n",
      "Epoch 90/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8423 - val_loss: 18.5731 - lr: 1.0000e-05\n",
      "Epoch 91/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8420 - val_loss: 18.5719 - lr: 1.0000e-05\n",
      "Epoch 92/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8418 - val_loss: 18.5725 - lr: 1.0000e-05\n",
      "Epoch 93/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8414 - val_loss: 18.5717 - lr: 1.0000e-05\n",
      "Epoch 94/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8412 - val_loss: 18.5722 - lr: 1.0000e-05\n",
      "Epoch 95/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8409 - val_loss: 18.5722 - lr: 1.0000e-05\n",
      "Epoch 96/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8407 - val_loss: 18.5718 - lr: 1.0000e-05\n",
      "Epoch 97/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8403 - val_loss: 18.5709 - lr: 1.0000e-05\n",
      "Epoch 98/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8401 - val_loss: 18.5716 - lr: 1.0000e-05\n",
      "Epoch 99/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8399 - val_loss: 18.5715 - lr: 1.0000e-05\n",
      "Epoch 100/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8396 - val_loss: 18.5715 - lr: 1.0000e-05\n",
      "Epoch 101/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8397 - val_loss: 18.5719 - lr: 1.0000e-05\n",
      "Epoch 102/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8391 - val_loss: 18.5713 - lr: 1.0000e-05\n",
      "Epoch 103/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8387 - val_loss: 18.5704 - lr: 1.0000e-05\n",
      "Epoch 104/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8386 - val_loss: 18.5704 - lr: 1.0000e-05\n",
      "Epoch 105/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8383 - val_loss: 18.5704 - lr: 1.0000e-05\n",
      "Epoch 106/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8380 - val_loss: 18.5712 - lr: 1.0000e-05\n",
      "Epoch 107/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8377 - val_loss: 18.5699 - lr: 1.0000e-05\n",
      "Epoch 108/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8374 - val_loss: 18.5693 - lr: 1.0000e-05\n",
      "Epoch 109/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8373 - val_loss: 18.5690 - lr: 1.0000e-05\n",
      "Epoch 110/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8368 - val_loss: 18.5699 - lr: 1.0000e-05\n",
      "Epoch 111/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8368 - val_loss: 18.5696 - lr: 1.0000e-05\n",
      "Epoch 112/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8364 - val_loss: 18.5701 - lr: 1.0000e-05\n",
      "Epoch 113/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8362 - val_loss: 18.5693 - lr: 1.0000e-05\n",
      "Epoch 114/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8359 - val_loss: 18.5689 - lr: 1.0000e-05\n",
      "Epoch 115/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8356 - val_loss: 18.5696 - lr: 1.0000e-05\n",
      "Epoch 116/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8353 - val_loss: 18.5697 - lr: 1.0000e-05\n",
      "Epoch 117/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8349 - val_loss: 18.5700 - lr: 1.0000e-05\n",
      "Epoch 118/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8348 - val_loss: 18.5692 - lr: 1.0000e-05\n",
      "Epoch 119/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8345 - val_loss: 18.5690 - lr: 1.0000e-05\n",
      "Epoch 120/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8340 - val_loss: 18.5681 - lr: 1.0000e-05\n",
      "Epoch 121/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8339 - val_loss: 18.5677 - lr: 1.0000e-05\n",
      "Epoch 122/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8338 - val_loss: 18.5674 - lr: 1.0000e-05\n",
      "Epoch 123/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8335 - val_loss: 18.5673 - lr: 1.0000e-05\n",
      "Epoch 124/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8332 - val_loss: 18.5677 - lr: 1.0000e-05\n",
      "Epoch 125/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8328 - val_loss: 18.5685 - lr: 1.0000e-05\n",
      "Epoch 126/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8325 - val_loss: 18.5673 - lr: 1.0000e-05\n",
      "Epoch 127/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8322 - val_loss: 18.5675 - lr: 1.0000e-05\n",
      "Epoch 128/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8320 - val_loss: 18.5672 - lr: 1.0000e-05\n",
      "Epoch 129/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8316 - val_loss: 18.5677 - lr: 1.0000e-05\n",
      "Epoch 130/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8314 - val_loss: 18.5684 - lr: 1.0000e-05\n",
      "Epoch 131/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8314 - val_loss: 18.5651 - lr: 1.0000e-05\n",
      "Epoch 132/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8309 - val_loss: 18.5665 - lr: 1.0000e-05\n",
      "Epoch 133/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8305 - val_loss: 18.5668 - lr: 1.0000e-05\n",
      "Epoch 134/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8302 - val_loss: 18.5670 - lr: 1.0000e-05\n",
      "Epoch 135/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8300 - val_loss: 18.5656 - lr: 1.0000e-05\n",
      "Epoch 136/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8297 - val_loss: 18.5665 - lr: 1.0000e-05\n",
      "Epoch 137/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8295 - val_loss: 18.5673 - lr: 1.0000e-05\n",
      "Epoch 138/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8291 - val_loss: 18.5668 - lr: 1.0000e-05\n",
      "Epoch 139/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8287 - val_loss: 18.5656 - lr: 1.0000e-05\n",
      "Epoch 140/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8285 - val_loss: 18.5654 - lr: 1.0000e-05\n",
      "Epoch 141/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8281 - val_loss: 18.5652 - lr: 1.0000e-05\n",
      "Epoch 142/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8280 - val_loss: 18.5651 - lr: 1.0000e-05\n",
      "Epoch 143/300\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 16.8276 - val_loss: 18.5655 - lr: 1.0000e-05\n",
      "Epoch 144/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8273 - val_loss: 18.5650 - lr: 1.0000e-05\n",
      "Epoch 145/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8272 - val_loss: 18.5643 - lr: 1.0000e-05\n",
      "Epoch 146/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8267 - val_loss: 18.5647 - lr: 1.0000e-05\n",
      "Epoch 147/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8267 - val_loss: 18.5642 - lr: 1.0000e-05\n",
      "Epoch 148/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8262 - val_loss: 18.5640 - lr: 1.0000e-05\n",
      "Epoch 149/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8259 - val_loss: 18.5643 - lr: 1.0000e-05\n",
      "Epoch 150/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8257 - val_loss: 18.5630 - lr: 1.0000e-05\n",
      "Epoch 151/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8255 - val_loss: 18.5649 - lr: 1.0000e-05\n",
      "Epoch 152/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8250 - val_loss: 18.5632 - lr: 1.0000e-05\n",
      "Epoch 153/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8247 - val_loss: 18.5636 - lr: 1.0000e-05\n",
      "Epoch 154/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8245 - val_loss: 18.5637 - lr: 1.0000e-05\n",
      "Epoch 155/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8240 - val_loss: 18.5635 - lr: 1.0000e-05\n",
      "Epoch 156/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8239 - val_loss: 18.5640 - lr: 1.0000e-05\n",
      "Epoch 157/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8236 - val_loss: 18.5633 - lr: 1.0000e-05\n",
      "Epoch 158/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8231 - val_loss: 18.5623 - lr: 1.0000e-05\n",
      "Epoch 159/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8230 - val_loss: 18.5629 - lr: 1.0000e-05\n",
      "Epoch 160/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8229 - val_loss: 18.5613 - lr: 1.0000e-05\n",
      "Epoch 161/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8225 - val_loss: 18.5618 - lr: 1.0000e-05\n",
      "Epoch 162/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8220 - val_loss: 18.5619 - lr: 1.0000e-05\n",
      "Epoch 163/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8220 - val_loss: 18.5612 - lr: 1.0000e-05\n",
      "Epoch 164/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8218 - val_loss: 18.5630 - lr: 1.0000e-05\n",
      "Epoch 165/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8212 - val_loss: 18.5609 - lr: 1.0000e-05\n",
      "Epoch 166/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8209 - val_loss: 18.5616 - lr: 1.0000e-05\n",
      "Epoch 167/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8207 - val_loss: 18.5612 - lr: 1.0000e-05\n",
      "Epoch 168/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8204 - val_loss: 18.5611 - lr: 1.0000e-05\n",
      "Epoch 169/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8201 - val_loss: 18.5617 - lr: 1.0000e-05\n",
      "Epoch 170/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8198 - val_loss: 18.5608 - lr: 1.0000e-05\n",
      "Epoch 171/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8196 - val_loss: 18.5604 - lr: 1.0000e-05\n",
      "Epoch 172/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8193 - val_loss: 18.5609 - lr: 1.0000e-05\n",
      "Epoch 173/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8189 - val_loss: 18.5604 - lr: 1.0000e-05\n",
      "Epoch 174/300\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 16.8186 - val_loss: 18.5610 - lr: 1.0000e-05\n",
      "Epoch 175/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8183 - val_loss: 18.5613 - lr: 1.0000e-05\n",
      "Epoch 176/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8180 - val_loss: 18.5597 - lr: 1.0000e-05\n",
      "Epoch 177/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8176 - val_loss: 18.5601 - lr: 1.0000e-05\n",
      "Epoch 178/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8174 - val_loss: 18.5597 - lr: 1.0000e-05\n",
      "Epoch 179/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8169 - val_loss: 18.5594 - lr: 1.0000e-05\n",
      "Epoch 180/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8168 - val_loss: 18.5608 - lr: 1.0000e-05\n",
      "Epoch 181/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8165 - val_loss: 18.5608 - lr: 1.0000e-05\n",
      "Epoch 182/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8161 - val_loss: 18.5593 - lr: 1.0000e-05\n",
      "Epoch 183/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8158 - val_loss: 18.5578 - lr: 1.0000e-05\n",
      "Epoch 184/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8155 - val_loss: 18.5585 - lr: 1.0000e-05\n",
      "Epoch 185/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8152 - val_loss: 18.5590 - lr: 1.0000e-05\n",
      "Epoch 186/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8150 - val_loss: 18.5578 - lr: 1.0000e-05\n",
      "Epoch 187/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8147 - val_loss: 18.5578 - lr: 1.0000e-05\n",
      "Epoch 188/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8143 - val_loss: 18.5584 - lr: 1.0000e-05\n",
      "Epoch 189/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8141 - val_loss: 18.5576 - lr: 1.0000e-05\n",
      "Epoch 190/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8137 - val_loss: 18.5583 - lr: 1.0000e-05\n",
      "Epoch 191/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8134 - val_loss: 18.5575 - lr: 1.0000e-05\n",
      "Epoch 192/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8133 - val_loss: 18.5564 - lr: 1.0000e-05\n",
      "Epoch 193/300\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 16.8130 - val_loss: 18.5590 - lr: 1.0000e-05\n",
      "Epoch 194/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8128 - val_loss: 18.5589 - lr: 1.0000e-05\n",
      "Epoch 195/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8125 - val_loss: 18.5561 - lr: 1.0000e-05\n",
      "Epoch 196/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8121 - val_loss: 18.5576 - lr: 1.0000e-05\n",
      "Epoch 197/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8120 - val_loss: 18.5551 - lr: 1.0000e-05\n",
      "Epoch 198/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8113 - val_loss: 18.5568 - lr: 1.0000e-05\n",
      "Epoch 199/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8110 - val_loss: 18.5569 - lr: 1.0000e-05\n",
      "Epoch 200/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8108 - val_loss: 18.5556 - lr: 1.0000e-05\n",
      "Epoch 201/300\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 16.8105 - val_loss: 18.5553 - lr: 1.0000e-05\n",
      "Epoch 202/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8100 - val_loss: 18.5567 - lr: 1.0000e-05\n",
      "Epoch 203/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8098 - val_loss: 18.5560 - lr: 1.0000e-05\n",
      "Epoch 204/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8097 - val_loss: 18.5564 - lr: 1.0000e-05\n",
      "Epoch 205/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8094 - val_loss: 18.5558 - lr: 1.0000e-05\n",
      "Epoch 206/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8092 - val_loss: 18.5555 - lr: 1.0000e-05\n",
      "Epoch 207/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8089 - val_loss: 18.5534 - lr: 1.0000e-05\n",
      "Epoch 208/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8084 - val_loss: 18.5553 - lr: 1.0000e-05\n",
      "Epoch 209/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8080 - val_loss: 18.5549 - lr: 1.0000e-05\n",
      "Epoch 210/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8081 - val_loss: 18.5550 - lr: 1.0000e-05\n",
      "Epoch 211/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8075 - val_loss: 18.5534 - lr: 1.0000e-05\n",
      "Epoch 212/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8072 - val_loss: 18.5534 - lr: 1.0000e-05\n",
      "Epoch 213/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8069 - val_loss: 18.5536 - lr: 1.0000e-05\n",
      "Epoch 214/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8066 - val_loss: 18.5553 - lr: 1.0000e-05\n",
      "Epoch 215/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8063 - val_loss: 18.5538 - lr: 1.0000e-05\n",
      "Epoch 216/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8061 - val_loss: 18.5549 - lr: 1.0000e-05\n",
      "Epoch 217/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8057 - val_loss: 18.5528 - lr: 1.0000e-05\n",
      "Epoch 218/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8051 - val_loss: 18.5535 - lr: 1.0000e-05\n",
      "Epoch 219/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8051 - val_loss: 18.5535 - lr: 1.0000e-05\n",
      "Epoch 220/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8046 - val_loss: 18.5528 - lr: 1.0000e-05\n",
      "Epoch 221/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8043 - val_loss: 18.5522 - lr: 1.0000e-05\n",
      "Epoch 222/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8041 - val_loss: 18.5528 - lr: 1.0000e-05\n",
      "Epoch 223/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8040 - val_loss: 18.5524 - lr: 1.0000e-05\n",
      "Epoch 224/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8035 - val_loss: 18.5524 - lr: 1.0000e-05\n",
      "Epoch 225/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8032 - val_loss: 18.5521 - lr: 1.0000e-05\n",
      "Epoch 226/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8030 - val_loss: 18.5525 - lr: 1.0000e-05\n",
      "Epoch 227/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8027 - val_loss: 18.5512 - lr: 1.0000e-05\n",
      "Epoch 228/300\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 16.8022 - val_loss: 18.5528 - lr: 1.0000e-05\n",
      "Epoch 229/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8020 - val_loss: 18.5517 - lr: 1.0000e-05\n",
      "Epoch 230/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8017 - val_loss: 18.5514 - lr: 1.0000e-05\n",
      "Epoch 231/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8016 - val_loss: 18.5504 - lr: 1.0000e-05\n",
      "Epoch 232/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8011 - val_loss: 18.5515 - lr: 1.0000e-05\n",
      "Epoch 233/300\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 16.8008 - val_loss: 18.5507 - lr: 1.0000e-05\n",
      "Epoch 234/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8005 - val_loss: 18.5507 - lr: 1.0000e-05\n",
      "Epoch 235/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8003 - val_loss: 18.5511 - lr: 1.0000e-05\n",
      "Epoch 236/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.8000 - val_loss: 18.5501 - lr: 1.0000e-05\n",
      "Epoch 237/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7996 - val_loss: 18.5498 - lr: 1.0000e-05\n",
      "Epoch 238/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7993 - val_loss: 18.5508 - lr: 1.0000e-05\n",
      "Epoch 239/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7993 - val_loss: 18.5516 - lr: 1.0000e-05\n",
      "Epoch 240/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7989 - val_loss: 18.5483 - lr: 1.0000e-05\n",
      "Epoch 241/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7984 - val_loss: 18.5491 - lr: 1.0000e-05\n",
      "Epoch 242/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7982 - val_loss: 18.5489 - lr: 1.0000e-05\n",
      "Epoch 243/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7980 - val_loss: 18.5488 - lr: 1.0000e-05\n",
      "Epoch 244/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7975 - val_loss: 18.5496 - lr: 1.0000e-05\n",
      "Epoch 245/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7974 - val_loss: 18.5498 - lr: 1.0000e-05\n",
      "Epoch 246/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7971 - val_loss: 18.5483 - lr: 1.0000e-05\n",
      "Epoch 247/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7967 - val_loss: 18.5484 - lr: 1.0000e-05\n",
      "Epoch 248/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7965 - val_loss: 18.5471 - lr: 1.0000e-05\n",
      "Epoch 249/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7961 - val_loss: 18.5476 - lr: 1.0000e-05\n",
      "Epoch 250/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7957 - val_loss: 18.5485 - lr: 1.0000e-05\n",
      "Epoch 251/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7956 - val_loss: 18.5477 - lr: 1.0000e-05\n",
      "Epoch 252/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7952 - val_loss: 18.5482 - lr: 1.0000e-05\n",
      "Epoch 253/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7950 - val_loss: 18.5484 - lr: 1.0000e-05\n",
      "Epoch 254/300\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 16.7948 - val_loss: 18.5462 - lr: 1.0000e-05\n",
      "Epoch 255/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7943 - val_loss: 18.5480 - lr: 1.0000e-05\n",
      "Epoch 256/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7941 - val_loss: 18.5469 - lr: 1.0000e-05\n",
      "Epoch 257/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7937 - val_loss: 18.5479 - lr: 1.0000e-05\n",
      "Epoch 258/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7936 - val_loss: 18.5471 - lr: 1.0000e-05\n",
      "Epoch 259/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7933 - val_loss: 18.5469 - lr: 1.0000e-05\n",
      "Epoch 260/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7930 - val_loss: 18.5446 - lr: 1.0000e-05\n",
      "Epoch 261/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7928 - val_loss: 18.5441 - lr: 1.0000e-05\n",
      "Epoch 262/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7923 - val_loss: 18.5471 - lr: 1.0000e-05\n",
      "Epoch 263/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7920 - val_loss: 18.5467 - lr: 1.0000e-05\n",
      "Epoch 264/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7916 - val_loss: 18.5463 - lr: 1.0000e-05\n",
      "Epoch 265/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7915 - val_loss: 18.5462 - lr: 1.0000e-05\n",
      "Epoch 266/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7912 - val_loss: 18.5451 - lr: 1.0000e-05\n",
      "Epoch 267/300\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 16.7910 - val_loss: 18.5460 - lr: 1.0000e-05\n",
      "Epoch 268/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7907 - val_loss: 18.5459 - lr: 1.0000e-05\n",
      "Epoch 269/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7902 - val_loss: 18.5443 - lr: 1.0000e-05\n",
      "Epoch 270/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7902 - val_loss: 18.5451 - lr: 1.0000e-05\n",
      "Epoch 271/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7902 - val_loss: 18.5467 - lr: 1.0000e-05\n",
      "Epoch 272/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7901 - val_loss: 18.5421 - lr: 1.0000e-05\n",
      "Epoch 273/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7893 - val_loss: 18.5440 - lr: 1.0000e-05\n",
      "Epoch 274/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7892 - val_loss: 18.5447 - lr: 1.0000e-05\n",
      "Epoch 275/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7885 - val_loss: 18.5429 - lr: 1.0000e-05\n",
      "Epoch 276/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7881 - val_loss: 18.5426 - lr: 1.0000e-05\n",
      "Epoch 277/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7879 - val_loss: 18.5428 - lr: 1.0000e-05\n",
      "Epoch 278/300\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 16.7875 - val_loss: 18.5426 - lr: 1.0000e-05\n",
      "Epoch 279/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7874 - val_loss: 18.5440 - lr: 1.0000e-05\n",
      "Epoch 280/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7870 - val_loss: 18.5422 - lr: 1.0000e-05\n",
      "Epoch 281/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7868 - val_loss: 18.5425 - lr: 1.0000e-05\n",
      "Epoch 282/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7864 - val_loss: 18.5431 - lr: 1.0000e-05\n",
      "Epoch 283/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7864 - val_loss: 18.5419 - lr: 1.0000e-05\n",
      "Epoch 284/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7860 - val_loss: 18.5424 - lr: 1.0000e-05\n",
      "Epoch 285/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7856 - val_loss: 18.5424 - lr: 1.0000e-05\n",
      "Epoch 286/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7854 - val_loss: 18.5413 - lr: 1.0000e-05\n",
      "Epoch 287/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7850 - val_loss: 18.5412 - lr: 1.0000e-05\n",
      "Epoch 288/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7849 - val_loss: 18.5419 - lr: 1.0000e-05\n",
      "Epoch 289/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7847 - val_loss: 18.5412 - lr: 1.0000e-05\n",
      "Epoch 290/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7841 - val_loss: 18.5414 - lr: 1.0000e-05\n",
      "Epoch 291/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7841 - val_loss: 18.5417 - lr: 1.0000e-05\n",
      "Epoch 292/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7840 - val_loss: 18.5420 - lr: 1.0000e-05\n",
      "Epoch 293/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7834 - val_loss: 18.5409 - lr: 1.0000e-05\n",
      "Epoch 294/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7833 - val_loss: 18.5403 - lr: 1.0000e-05\n",
      "Epoch 295/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7828 - val_loss: 18.5399 - lr: 1.0000e-05\n",
      "Epoch 296/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7828 - val_loss: 18.5408 - lr: 1.0000e-05\n",
      "Epoch 297/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7824 - val_loss: 18.5404 - lr: 1.0000e-05\n",
      "Epoch 298/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7819 - val_loss: 18.5395 - lr: 1.0000e-05\n",
      "Epoch 299/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7821 - val_loss: 18.5413 - lr: 1.0000e-05\n",
      "Epoch 300/300\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 16.7816 - val_loss: 18.5388 - lr: 1.0000e-05\n",
      "220/220 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "neural_network.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), \n",
    "              loss='mse')\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-5)\n",
    "\n",
    "neural_network.fit(\n",
    "    X_train_scaled_poly, y_train, \n",
    "    epochs=300, batch_size=1024, \n",
    "    validation_data=(X_val_scaled_poly, y_val),\n",
    "    callbacks=[reduce_lr, early_stopping]\n",
    ")\n",
    "\n",
    "predictions = neural_network.predict(X_test_scaled_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Relative Difference: 0.1445955299477998\n",
      "Mean Squared Error: 18.668362251644307\n",
      "R2_score = 0.7813598308695546\n"
     ]
    }
   ],
   "source": [
    "predictions = predictions.reshape((predictions.shape[0]))\n",
    "mse = mean_squared_error(y_test, predictions.T)\n",
    "average_relative_difference = np.mean(abs(y_test - predictions.T) / y_test)\n",
    "print(f'Average Relative Difference: {average_relative_difference}')\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R2_score = {r2_score(y_test, predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_diffs = np.sort(abs(y_test - predictions.T) / y_test) * 100\n",
    "plt.hist(sorted_diffs)\n",
    "plt.xlabel('relative difference (%)')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testiranje alternativnih pristupa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression:\n",
      "Best parameters: {}\n",
      "Best MSE score: 37.05612537227641\n",
      "\n",
      "Ridge:\n",
      "Best parameters: {'alpha': 0.01}\n",
      "Best MSE score: 37.067124495129725\n",
      "\n",
      "Lasso:\n",
      "Best parameters: {'alpha': 0.01}\n",
      "Best MSE score: 37.062039224295646\n",
      "\n",
      "ElasticNet:\n",
      "Best parameters: {'alpha': 0.01, 'l1_ratio': 0.9}\n",
      "Best MSE score: 37.06281641754651\n",
      "\n",
      "SVR:\n",
      "Best parameters: {'C': 10.0, 'kernel': 'rbf'}\n",
      "Best MSE score: 26.981562040995943\n",
      "\n",
      "DecisionTreeRegressor:\n",
      "Best parameters: {'max_depth': 7}\n",
      "Best MSE score: 23.95440872347864\n",
      "\n",
      "RandomForestRegressor:\n",
      "Best parameters: {'n_estimators': 300}\n",
      "Best MSE score: 14.72544651573044\n",
      "\n",
      "GradientBoostingRegressor:\n",
      "Best parameters: {'max_depth': 9, 'n_estimators': 30}\n",
      "Best MSE score: 14.264676579932788\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost\n",
    "import numpy as np\n",
    "\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(),\n",
    "    Lasso(),\n",
    "    ElasticNet(),\n",
    "    SVR(),\n",
    "    DecisionTreeRegressor(),\n",
    "    RandomForestRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "]\n",
    "\n",
    "param_grid = [\n",
    "    {},  \n",
    "    {'alpha': [0.01, 0.1, 1.0]},\n",
    "    {'alpha': [0.01, 0.1, 1.0]},\n",
    "    {'alpha': [0.01, 0.1, 1.0], 'l1_ratio': [0.1, 0.5, 0.9]},\n",
    "    {'C': [0.1, 1.0, 10.0], 'kernel': ['linear', 'rbf']},\n",
    "    {'max_depth': [3, 5, 7]},\n",
    "    {'n_estimators': [100, 200, 300]},\n",
    "    {'n_estimators': [20, 25, 30], 'max_depth': [5, 7, 9]},\n",
    "]\n",
    "\n",
    "best_models = []\n",
    "for i, model in enumerate(models):\n",
    "    grid_search = GridSearchCV(model, param_grid[i], cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "    model_name = model.__class__.__name__\n",
    "    best_models.append((model_name, grid_search.best_estimator_))\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "    print(\"Best MSE score:\", -1 * grid_search.best_score_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression on train dataset:\n",
      "Average Relative Difference: 0.21171951866344046\n",
      "Mean Squared Error: 36.94517270329782\n",
      "R2_score = 0.5790374645880672\n",
      "\n",
      "Ridge on train dataset:\n",
      "Average Relative Difference: 0.21180806954080603\n",
      "Mean Squared Error: 36.959300497416805\n",
      "R2_score = 0.5788764889694156\n",
      "\n",
      "Lasso on train dataset:\n",
      "Average Relative Difference: 0.21199031858688436\n",
      "Mean Squared Error: 36.99117638564835\n",
      "R2_score = 0.5785132871287795\n",
      "\n",
      "ElasticNet on train dataset:\n",
      "Average Relative Difference: 0.21199445240689782\n",
      "Mean Squared Error: 36.9907613803908\n",
      "R2_score = 0.5785180158024503\n",
      "\n",
      "SVR on train dataset:\n",
      "Average Relative Difference: 0.1503413293815662\n",
      "Mean Squared Error: 21.637021168525344\n",
      "R2_score = 0.7534623707672896\n",
      "\n",
      "DecisionTreeRegressor on train dataset:\n",
      "Average Relative Difference: 0.16196642960683777\n",
      "Mean Squared Error: 23.2166808110996\n",
      "R2_score = 0.7354633338277057\n",
      "\n",
      "RandomForestRegressor on train dataset:\n",
      "Average Relative Difference: 0.048095777000826644\n",
      "Mean Squared Error: 1.9916258200870085\n",
      "R2_score = 0.9773069174273785\n",
      "\n",
      "GradientBoostingRegressor on train dataset:\n",
      "Average Relative Difference: 0.11455607637638326\n",
      "Mean Squared Error: 10.634446412920498\n",
      "R2_score = 0.8788284585746233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, best_model in best_models:\n",
    "    predictions = best_model.predict(X_train_scaled)\n",
    "    mse = mean_squared_error(y_train, predictions)\n",
    "    average_relative_difference = np.mean(abs(y_train - predictions) / y_train)\n",
    "    print(f\"{name} on train dataset:\")\n",
    "    print(f'Average Relative Difference: {average_relative_difference}')\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "    print(f'R2_score = {r2_score(y_train, predictions)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression on test dataset:\n",
      "Average Relative Difference: 2.7064801565308736\n",
      "Mean Squared Error: 5036.443960294177\n",
      "R2_score = -57.98583627483111\n",
      "\n",
      "Ridge on test dataset:\n",
      "Average Relative Difference: 0.20657605434393833\n",
      "Mean Squared Error: 36.45995682085744\n",
      "R2_score = 0.5729881915539288\n",
      "\n",
      "Lasso on test dataset:\n",
      "Average Relative Difference: 0.20653568503498035\n",
      "Mean Squared Error: 36.41608898892133\n",
      "R2_score = 0.5735019629316539\n",
      "\n",
      "ElasticNet on test dataset:\n",
      "Average Relative Difference: 0.2065403649866773\n",
      "Mean Squared Error: 36.41688878235121\n",
      "R2_score = 0.573492595909072\n",
      "\n",
      "SVR on test dataset:\n",
      "Average Relative Difference: 0.1708410134566895\n",
      "Mean Squared Error: 26.12130690911599\n",
      "R2_score = 0.6940724160195493\n",
      "\n",
      "DecisionTreeRegressor on test dataset:\n",
      "Average Relative Difference: 0.16025879033722043\n",
      "Mean Squared Error: 23.452010282339078\n",
      "R2_score = 0.7253346905603396\n",
      "\n",
      "RandomForestRegressor on test dataset:\n",
      "Average Relative Difference: 0.12881714217783946\n",
      "Mean Squared Error: 14.521581532043989\n",
      "R2_score = 0.8299261070998344\n",
      "\n",
      "GradientBoostingRegressor on test dataset:\n",
      "Average Relative Difference: 0.12907939585357114\n",
      "Mean Squared Error: 14.221037788577213\n",
      "R2_score = 0.833446016024726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, best_model in best_models:\n",
    "    predictions = best_model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    average_relative_difference = np.mean(abs(y_test - predictions) / y_test)\n",
    "    print(f\"{name} on test dataset:\")\n",
    "    print(f'Average Relative Difference: {average_relative_difference}')\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "    print(f'R2_score = {r2_score(y_test, predictions)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testiranje alternativnih pristupa sa polinomijalno transformiranim zna훾ajkama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression:\n",
      "Best parameters: {}\n",
      "Best MSE score: 29.53214628722558\n",
      "\n",
      "Ridge:\n",
      "Best parameters: {'alpha': 0.1}\n",
      "Best MSE score: 29.502524647409395\n",
      "\n",
      "Lasso:\n",
      "Best parameters: {'alpha': 0.01}\n",
      "Best MSE score: 29.892185000363458\n",
      "\n",
      "ElasticNet:\n",
      "Best parameters: {'alpha': 0.01, 'l1_ratio': 0.9}\n",
      "Best MSE score: 29.995022648019006\n",
      "\n",
      "SVR:\n",
      "Best parameters: {'C': 10.0, 'kernel': 'rbf'}\n",
      "Best MSE score: 22.650160372597842\n",
      "\n",
      "DecisionTreeRegressor:\n",
      "Best parameters: {'max_depth': 7}\n",
      "Best MSE score: 19.118562861480164\n",
      "\n",
      "RandomForestRegressor:\n",
      "Best parameters: {'n_estimators': 300}\n",
      "Best MSE score: 16.576495071736183\n",
      "\n",
      "GradientBoostingRegressor:\n",
      "Best parameters: {'max_depth': 7, 'n_estimators': 30}\n",
      "Best MSE score: 16.361649499659215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost\n",
    "import numpy as np\n",
    "\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(),\n",
    "    Lasso(),\n",
    "    ElasticNet(),\n",
    "    SVR(),\n",
    "    DecisionTreeRegressor(),\n",
    "    RandomForestRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "]\n",
    "\n",
    "param_grid = [\n",
    "    {},  \n",
    "    {'alpha': [0.01, 0.1, 1.0]},\n",
    "    {'alpha': [0.01, 0.1, 1.0]},\n",
    "    {'alpha': [0.01, 0.1, 1.0], 'l1_ratio': [0.1, 0.5, 0.9]},\n",
    "    {'C': [0.1, 1.0, 10.0], 'kernel': ['linear', 'rbf']},\n",
    "    {'max_depth': [3, 5, 7]},\n",
    "    {'n_estimators': [100, 200, 300]},\n",
    "    {'n_estimators': [20, 25, 30], 'max_depth': [5, 7, 9]},\n",
    "]\n",
    "\n",
    "best_models_on_poly = []\n",
    "for i, model in enumerate(models):\n",
    "    grid_search = GridSearchCV(model, param_grid[i], cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train_scaled_poly, y_train)\n",
    "\n",
    "    model_name = model.__class__.__name__\n",
    "    best_models_on_poly.append((model_name, grid_search.best_estimator_))\n",
    "    print(f\"{model_name}:\")\n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "    print(\"Best MSE score:\", -1 * grid_search.best_score_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression on train dataset:\n",
      "Average Relative Difference: 0.18807096026283146\n",
      "Mean Squared Error: 29.17801364794456\n",
      "R2_score = 0.6675384169356902\n",
      "\n",
      "Ridge on train dataset:\n",
      "Average Relative Difference: 0.1880907543832698\n",
      "Mean Squared Error: 29.17763314484293\n",
      "R2_score = 0.6675427524831697\n",
      "\n",
      "Lasso on train dataset:\n",
      "Average Relative Difference: 0.1896418537175998\n",
      "Mean Squared Error: 29.71066797296579\n",
      "R2_score = 0.6614692203735355\n",
      "\n",
      "ElasticNet on train dataset:\n",
      "Average Relative Difference: 0.1900419437681835\n",
      "Mean Squared Error: 29.80062505777326\n",
      "R2_score = 0.6604442268567116\n",
      "\n",
      "SVR on train dataset:\n",
      "Average Relative Difference: 0.1449010306243352\n",
      "Mean Squared Error: 19.65537977384492\n",
      "R2_score = 0.7760416883003607\n",
      "\n",
      "DecisionTreeRegressor on train dataset:\n",
      "Average Relative Difference: 0.140178206398271\n",
      "Mean Squared Error: 17.56347042522961\n",
      "R2_score = 0.7998774264715459\n",
      "\n",
      "RandomForestRegressor on train dataset:\n",
      "Average Relative Difference: 0.05011528223636337\n",
      "Mean Squared Error: 2.2528339683241074\n",
      "R2_score = 0.9743306464748726\n",
      "\n",
      "GradientBoostingRegressor on train dataset:\n",
      "Average Relative Difference: 0.1289032759306372\n",
      "Mean Squared Error: 13.655576047390827\n",
      "R2_score = 0.8444049521276976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, best_model in best_models_on_poly:\n",
    "    predictions = best_model.predict(X_train_scaled_poly)\n",
    "    mse = mean_squared_error(y_train, predictions)\n",
    "    average_relative_difference = np.mean(abs(y_train - predictions) / y_train)\n",
    "    print(f\"{name} on train dataset:\")\n",
    "    print(f'Average Relative Difference: {average_relative_difference}')\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "    print(f'R2_score = {r2_score(y_train, predictions)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression on test dataset:\n",
      "Average Relative Difference: 0.18210702257919034\n",
      "Mean Squared Error: 29.00344660881981\n",
      "R2_score = 0.6603173654743248\n",
      "\n",
      "Ridge on test dataset:\n",
      "Average Relative Difference: 0.1821046993460745\n",
      "Mean Squared Error: 28.994326887748347\n",
      "R2_score = 0.6604241738451186\n",
      "\n",
      "Lasso on test dataset:\n",
      "Average Relative Difference: 0.18293332979368454\n",
      "Mean Squared Error: 29.242901058244946\n",
      "R2_score = 0.6575129222877385\n",
      "\n",
      "ElasticNet on test dataset:\n",
      "Average Relative Difference: 0.183338369949162\n",
      "Mean Squared Error: 29.339216233004663\n",
      "R2_score = 0.6563848979964036\n",
      "\n",
      "SVR on test dataset:\n",
      "Average Relative Difference: 0.15364567244212862\n",
      "Mean Squared Error: 21.862951962804555\n",
      "R2_score = 0.743945427541864\n",
      "\n",
      "DecisionTreeRegressor on test dataset:\n",
      "Average Relative Difference: 0.14151725660236958\n",
      "Mean Squared Error: 18.59823093508553\n",
      "R2_score = 0.7821811949885417\n",
      "\n",
      "RandomForestRegressor on test dataset:\n",
      "Average Relative Difference: 0.13498204694644347\n",
      "Mean Squared Error: 16.43111786548022\n",
      "R2_score = 0.8075619949578356\n",
      "\n",
      "GradientBoostingRegressor on test dataset:\n",
      "Average Relative Difference: 0.13595409506589753\n",
      "Mean Squared Error: 16.119362479767\n",
      "R2_score = 0.8112132124208814\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, best_model in best_models_on_poly:\n",
    "    predictions = best_model.predict(X_test_scaled_poly)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    average_relative_difference = np.mean(abs(y_test - predictions) / y_test)\n",
    "    print(f\"{name} on test dataset:\")\n",
    "    print(f'Average Relative Difference: {average_relative_difference}')\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "    print(f'R2_score = {r2_score(y_test, predictions)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Devijacija srednje kvadratne gre큄ke (MSE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "31/31 [==============================] - 1s 10ms/step - loss: 691.9472 - val_loss: 585.8790 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 504.7539 - val_loss: 412.1212 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 335.5839 - val_loss: 252.5517 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 192.6676 - val_loss: 137.7855 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 110.1443 - val_loss: 92.3515 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 83.7777 - val_loss: 80.8662 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 75.4525 - val_loss: 74.3022 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 68.4181 - val_loss: 67.1415 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 60.8152 - val_loss: 59.8515 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 53.5964 - val_loss: 53.1314 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 47.6292 - val_loss: 48.0045 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 43.3965 - val_loss: 44.5719 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 40.6164 - val_loss: 42.3024 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 38.6966 - val_loss: 40.7337 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 37.3112 - val_loss: 39.5530 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 36.2324 - val_loss: 38.5998 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 35.2986 - val_loss: 37.7728 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 34.4727 - val_loss: 37.0530 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 33.7076 - val_loss: 36.2211 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 32.9938 - val_loss: 35.5483 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 32.3165 - val_loss: 34.8651 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 31.7073 - val_loss: 34.2192 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 31.1043 - val_loss: 33.5913 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 30.5470 - val_loss: 33.0627 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 30.0589 - val_loss: 32.5396 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 29.6050 - val_loss: 32.0491 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 29.1648 - val_loss: 31.6009 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 28.7644 - val_loss: 31.2686 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 28.4003 - val_loss: 30.8736 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 28.0580 - val_loss: 30.4800 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 27.7385 - val_loss: 30.1093 - lr: 0.0010\n",
      "Epoch 32/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 27.3187 - val_loss: 29.7230 - lr: 0.0010\n",
      "Epoch 33/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.9701 - val_loss: 29.4186 - lr: 0.0010\n",
      "Epoch 34/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.6443 - val_loss: 29.0557 - lr: 0.0010\n",
      "Epoch 35/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.2972 - val_loss: 28.7435 - lr: 0.0010\n",
      "Epoch 36/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.9838 - val_loss: 28.3802 - lr: 0.0010\n",
      "Epoch 37/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.7172 - val_loss: 28.1103 - lr: 0.0010\n",
      "Epoch 38/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.4474 - val_loss: 27.8532 - lr: 0.0010\n",
      "Epoch 39/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.1935 - val_loss: 27.6397 - lr: 0.0010\n",
      "Epoch 40/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.9898 - val_loss: 27.4437 - lr: 0.0010\n",
      "Epoch 41/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 24.7681 - val_loss: 27.2268 - lr: 0.0010\n",
      "Epoch 42/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.5776 - val_loss: 27.1214 - lr: 0.0010\n",
      "Epoch 43/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.4911 - val_loss: 26.9959 - lr: 0.0010\n",
      "Epoch 44/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.2692 - val_loss: 26.7198 - lr: 0.0010\n",
      "Epoch 45/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.1189 - val_loss: 26.5673 - lr: 0.0010\n",
      "Epoch 46/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.9762 - val_loss: 26.4209 - lr: 0.0010\n",
      "Epoch 47/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.7998 - val_loss: 26.2600 - lr: 0.0010\n",
      "Epoch 48/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.6559 - val_loss: 26.0997 - lr: 0.0010\n",
      "Epoch 49/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 23.5222 - val_loss: 25.9366 - lr: 0.0010\n",
      "Epoch 50/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.3858 - val_loss: 25.8356 - lr: 0.0010\n",
      "Epoch 51/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.2631 - val_loss: 25.6814 - lr: 0.0010\n",
      "Epoch 52/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.0787 - val_loss: 25.5539 - lr: 0.0010\n",
      "Epoch 53/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.9763 - val_loss: 25.4545 - lr: 0.0010\n",
      "Epoch 54/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.8332 - val_loss: 25.3364 - lr: 0.0010\n",
      "Epoch 55/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.7192 - val_loss: 25.1895 - lr: 0.0010\n",
      "Epoch 56/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.6045 - val_loss: 25.0212 - lr: 0.0010\n",
      "Epoch 57/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.4616 - val_loss: 24.9104 - lr: 0.0010\n",
      "Epoch 58/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.2983 - val_loss: 24.7823 - lr: 0.0010\n",
      "Epoch 59/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.1723 - val_loss: 24.6167 - lr: 0.0010\n",
      "Epoch 60/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.0712 - val_loss: 24.4837 - lr: 0.0010\n",
      "Epoch 61/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.9711 - val_loss: 24.3637 - lr: 0.0010\n",
      "Epoch 62/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.8475 - val_loss: 24.2077 - lr: 0.0010\n",
      "Epoch 63/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.7096 - val_loss: 24.1100 - lr: 0.0010\n",
      "Epoch 64/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.5733 - val_loss: 23.9771 - lr: 0.0010\n",
      "Epoch 65/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.4620 - val_loss: 23.8908 - lr: 0.0010\n",
      "Epoch 66/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.3216 - val_loss: 23.7265 - lr: 0.0010\n",
      "Epoch 67/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.1854 - val_loss: 23.6030 - lr: 0.0010\n",
      "Epoch 68/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.1109 - val_loss: 23.4861 - lr: 0.0010\n",
      "Epoch 69/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 20.9549 - val_loss: 23.3149 - lr: 0.0010\n",
      "Epoch 70/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 20.8575 - val_loss: 23.1632 - lr: 0.0010\n",
      "Epoch 71/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.7504 - val_loss: 23.0798 - lr: 0.0010\n",
      "Epoch 72/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.5915 - val_loss: 22.9538 - lr: 0.0010\n",
      "Epoch 73/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.5259 - val_loss: 22.8326 - lr: 0.0010\n",
      "Epoch 74/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.3574 - val_loss: 22.6376 - lr: 0.0010\n",
      "Epoch 75/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.3078 - val_loss: 22.6293 - lr: 0.0010\n",
      "Epoch 76/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.1723 - val_loss: 22.4904 - lr: 0.0010\n",
      "Epoch 77/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.0832 - val_loss: 22.2976 - lr: 0.0010\n",
      "Epoch 78/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.9531 - val_loss: 22.2335 - lr: 0.0010\n",
      "Epoch 79/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.8638 - val_loss: 22.1045 - lr: 0.0010\n",
      "Epoch 80/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.7591 - val_loss: 22.0092 - lr: 0.0010\n",
      "Epoch 81/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 19.6719 - val_loss: 21.8816 - lr: 0.0010\n",
      "Epoch 82/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.6222 - val_loss: 21.8072 - lr: 0.0010\n",
      "Epoch 83/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.4788 - val_loss: 21.7234 - lr: 0.0010\n",
      "Epoch 84/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.4475 - val_loss: 21.6062 - lr: 0.0010\n",
      "Epoch 85/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.3284 - val_loss: 21.4797 - lr: 0.0010\n",
      "Epoch 86/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 19.2474 - val_loss: 21.4216 - lr: 0.0010\n",
      "Epoch 87/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 19.1621 - val_loss: 21.3241 - lr: 0.0010\n",
      "Epoch 88/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.0773 - val_loss: 21.2444 - lr: 0.0010\n",
      "Epoch 89/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.0203 - val_loss: 21.1733 - lr: 0.0010\n",
      "Epoch 90/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.9741 - val_loss: 21.0683 - lr: 0.0010\n",
      "Epoch 91/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.8782 - val_loss: 20.9747 - lr: 0.0010\n",
      "Epoch 92/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.7858 - val_loss: 20.9113 - lr: 0.0010\n",
      "Epoch 93/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.7416 - val_loss: 20.8411 - lr: 0.0010\n",
      "Epoch 94/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.6682 - val_loss: 20.7362 - lr: 0.0010\n",
      "Epoch 95/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.5761 - val_loss: 20.7029 - lr: 0.0010\n",
      "Epoch 96/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.4979 - val_loss: 20.6391 - lr: 0.0010\n",
      "Epoch 97/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.4282 - val_loss: 20.5102 - lr: 0.0010\n",
      "Epoch 98/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.3519 - val_loss: 20.4703 - lr: 0.0010\n",
      "Epoch 99/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.3371 - val_loss: 20.4423 - lr: 0.0010\n",
      "Epoch 100/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.2470 - val_loss: 20.3413 - lr: 0.0010\n",
      "Epoch 101/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.1428 - val_loss: 20.2858 - lr: 0.0010\n",
      "Epoch 102/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.0547 - val_loss: 20.2045 - lr: 0.0010\n",
      "Epoch 103/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.0167 - val_loss: 20.1316 - lr: 0.0010\n",
      "Epoch 104/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.9320 - val_loss: 20.0439 - lr: 0.0010\n",
      "Epoch 105/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.9247 - val_loss: 20.0099 - lr: 0.0010\n",
      "Epoch 106/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.8143 - val_loss: 19.9105 - lr: 0.0010\n",
      "Epoch 107/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.7335 - val_loss: 19.8486 - lr: 0.0010\n",
      "Epoch 108/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.6785 - val_loss: 19.7879 - lr: 0.0010\n",
      "Epoch 109/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.6138 - val_loss: 19.7434 - lr: 0.0010\n",
      "Epoch 110/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.5486 - val_loss: 19.6694 - lr: 0.0010\n",
      "Epoch 111/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.4823 - val_loss: 19.5409 - lr: 0.0010\n",
      "Epoch 112/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.4102 - val_loss: 19.4901 - lr: 0.0010\n",
      "Epoch 113/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.3462 - val_loss: 19.4465 - lr: 0.0010\n",
      "Epoch 114/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.2813 - val_loss: 19.4554 - lr: 0.0010\n",
      "Epoch 115/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 17.2815 - val_loss: 19.3361 - lr: 0.0010\n",
      "Epoch 116/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.1735 - val_loss: 19.3442 - lr: 0.0010\n",
      "Epoch 117/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.1586 - val_loss: 19.2054 - lr: 0.0010\n",
      "Epoch 118/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.0762 - val_loss: 19.1752 - lr: 0.0010\n",
      "Epoch 119/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.9827 - val_loss: 19.0961 - lr: 0.0010\n",
      "Epoch 120/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.9243 - val_loss: 19.0616 - lr: 0.0010\n",
      "Epoch 121/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.8985 - val_loss: 18.9589 - lr: 0.0010\n",
      "Epoch 122/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.8350 - val_loss: 18.9116 - lr: 0.0010\n",
      "Epoch 123/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.7657 - val_loss: 18.8773 - lr: 0.0010\n",
      "Epoch 124/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.7213 - val_loss: 18.8790 - lr: 0.0010\n",
      "Epoch 125/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.7094 - val_loss: 18.8196 - lr: 0.0010\n",
      "Epoch 126/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.6594 - val_loss: 18.7147 - lr: 0.0010\n",
      "Epoch 127/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.5686 - val_loss: 18.7423 - lr: 0.0010\n",
      "Epoch 128/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.5230 - val_loss: 18.6455 - lr: 0.0010\n",
      "Epoch 129/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4626 - val_loss: 18.5933 - lr: 0.0010\n",
      "Epoch 130/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 16.4251 - val_loss: 18.5097 - lr: 0.0010\n",
      "Epoch 131/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3971 - val_loss: 18.5513 - lr: 0.0010\n",
      "Epoch 132/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3206 - val_loss: 18.4364 - lr: 0.0010\n",
      "Epoch 133/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3009 - val_loss: 18.4412 - lr: 0.0010\n",
      "Epoch 134/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.2575 - val_loss: 18.3917 - lr: 0.0010\n",
      "Epoch 135/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.1843 - val_loss: 18.3020 - lr: 0.0010\n",
      "Epoch 136/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.1489 - val_loss: 18.3563 - lr: 0.0010\n",
      "Epoch 137/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.1219 - val_loss: 18.2535 - lr: 0.0010\n",
      "Epoch 138/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.0528 - val_loss: 18.2681 - lr: 0.0010\n",
      "Epoch 139/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.0271 - val_loss: 18.1321 - lr: 0.0010\n",
      "Epoch 140/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9942 - val_loss: 18.1395 - lr: 0.0010\n",
      "Epoch 141/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9149 - val_loss: 18.1748 - lr: 0.0010\n",
      "Epoch 142/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9074 - val_loss: 18.0886 - lr: 0.0010\n",
      "Epoch 143/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9235 - val_loss: 18.1120 - lr: 0.0010\n",
      "Epoch 144/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8756 - val_loss: 18.2164 - lr: 0.0010\n",
      "Epoch 145/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.8573 - val_loss: 18.0579 - lr: 0.0010\n",
      "Epoch 146/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.7334 - val_loss: 17.9593 - lr: 0.0010\n",
      "Epoch 147/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6893 - val_loss: 17.8978 - lr: 0.0010\n",
      "Epoch 148/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6853 - val_loss: 18.0321 - lr: 0.0010\n",
      "Epoch 149/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7196 - val_loss: 17.8875 - lr: 0.0010\n",
      "Epoch 150/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.5817 - val_loss: 17.8088 - lr: 0.0010\n",
      "Epoch 151/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.5352 - val_loss: 17.8105 - lr: 0.0010\n",
      "Epoch 152/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.5294 - val_loss: 17.8188 - lr: 0.0010\n",
      "Epoch 153/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.4946 - val_loss: 17.8357 - lr: 0.0010\n",
      "Epoch 154/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.3941 - val_loss: 17.7936 - lr: 1.0000e-04\n",
      "Epoch 155/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.3513 - val_loss: 17.7844 - lr: 1.0000e-04\n",
      "Epoch 156/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.3435 - val_loss: 17.7724 - lr: 1.0000e-04\n",
      "Epoch 157/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.3357 - val_loss: 17.7625 - lr: 1.0000e-04\n",
      "Epoch 158/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.3331 - val_loss: 17.7558 - lr: 1.0000e-04\n",
      "Epoch 159/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.3301 - val_loss: 17.7452 - lr: 1.0000e-04\n",
      "Epoch 160/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.3233 - val_loss: 17.7373 - lr: 1.0000e-04\n",
      "Epoch 161/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.3169 - val_loss: 17.7456 - lr: 1.0000e-04\n",
      "Epoch 162/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.3149 - val_loss: 17.7488 - lr: 1.0000e-04\n",
      "Epoch 163/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.3086 - val_loss: 17.7338 - lr: 1.0000e-04\n",
      "Epoch 164/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.3066 - val_loss: 17.7334 - lr: 1.0000e-04\n",
      "Epoch 165/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.3016 - val_loss: 17.7222 - lr: 1.0000e-04\n",
      "Epoch 166/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2964 - val_loss: 17.7240 - lr: 1.0000e-04\n",
      "Epoch 167/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2912 - val_loss: 17.7186 - lr: 1.0000e-04\n",
      "Epoch 168/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2887 - val_loss: 17.7134 - lr: 1.0000e-04\n",
      "Epoch 169/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2847 - val_loss: 17.7052 - lr: 1.0000e-04\n",
      "Epoch 170/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2815 - val_loss: 17.6944 - lr: 1.0000e-04\n",
      "Epoch 171/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2778 - val_loss: 17.6908 - lr: 1.0000e-04\n",
      "Epoch 172/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2727 - val_loss: 17.6846 - lr: 1.0000e-04\n",
      "Epoch 173/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2709 - val_loss: 17.6856 - lr: 1.0000e-04\n",
      "Epoch 174/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2675 - val_loss: 17.6842 - lr: 1.0000e-04\n",
      "Epoch 175/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2619 - val_loss: 17.6814 - lr: 1.0000e-04\n",
      "Epoch 176/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2587 - val_loss: 17.6755 - lr: 1.0000e-04\n",
      "Epoch 177/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2553 - val_loss: 17.6704 - lr: 1.0000e-04\n",
      "Epoch 178/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2523 - val_loss: 17.6712 - lr: 1.0000e-04\n",
      "Epoch 179/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2476 - val_loss: 17.6584 - lr: 1.0000e-04\n",
      "Epoch 180/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2431 - val_loss: 17.6630 - lr: 1.0000e-04\n",
      "Epoch 181/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2431 - val_loss: 17.6604 - lr: 1.0000e-04\n",
      "Epoch 182/300\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 15.2352 - val_loss: 17.6577 - lr: 1.0000e-04\n",
      "Epoch 183/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2371 - val_loss: 17.6550 - lr: 1.0000e-04\n",
      "Epoch 184/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2334 - val_loss: 17.6601 - lr: 1.0000e-04\n",
      "Epoch 185/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2290 - val_loss: 17.6558 - lr: 1.0000e-04\n",
      "Epoch 186/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2222 - val_loss: 17.6640 - lr: 1.0000e-04\n",
      "Epoch 187/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2124 - val_loss: 17.6633 - lr: 1.0000e-05\n",
      "Epoch 188/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2114 - val_loss: 17.6611 - lr: 1.0000e-05\n",
      "Epoch 189/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2104 - val_loss: 17.6588 - lr: 1.0000e-05\n",
      "Epoch 190/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2095 - val_loss: 17.6578 - lr: 1.0000e-05\n",
      "Epoch 191/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2092 - val_loss: 17.6553 - lr: 1.0000e-05\n",
      "Epoch 192/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2083 - val_loss: 17.6546 - lr: 1.0000e-05\n",
      "Epoch 193/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2077 - val_loss: 17.6529 - lr: 1.0000e-05\n",
      "Epoch 194/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2069 - val_loss: 17.6493 - lr: 1.0000e-05\n",
      "Epoch 195/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2065 - val_loss: 17.6484 - lr: 1.0000e-05\n",
      "Epoch 196/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2062 - val_loss: 17.6484 - lr: 1.0000e-05\n",
      "Epoch 197/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2056 - val_loss: 17.6479 - lr: 1.0000e-05\n",
      "Epoch 198/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2054 - val_loss: 17.6487 - lr: 1.0000e-05\n",
      "Epoch 199/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2047 - val_loss: 17.6482 - lr: 1.0000e-05\n",
      "Epoch 200/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2045 - val_loss: 17.6472 - lr: 1.0000e-05\n",
      "Epoch 201/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.2042 - val_loss: 17.6467 - lr: 1.0000e-05\n",
      "Epoch 202/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2036 - val_loss: 17.6450 - lr: 1.0000e-05\n",
      "Epoch 203/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2032 - val_loss: 17.6462 - lr: 1.0000e-05\n",
      "Epoch 204/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2024 - val_loss: 17.6431 - lr: 1.0000e-05\n",
      "Epoch 205/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2019 - val_loss: 17.6429 - lr: 1.0000e-05\n",
      "Epoch 206/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2017 - val_loss: 17.6445 - lr: 1.0000e-05\n",
      "Epoch 207/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2011 - val_loss: 17.6432 - lr: 1.0000e-05\n",
      "Epoch 208/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2007 - val_loss: 17.6406 - lr: 1.0000e-05\n",
      "Epoch 209/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2000 - val_loss: 17.6389 - lr: 1.0000e-05\n",
      "Epoch 210/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1998 - val_loss: 17.6362 - lr: 1.0000e-05\n",
      "Epoch 211/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1998 - val_loss: 17.6361 - lr: 1.0000e-05\n",
      "Epoch 212/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1989 - val_loss: 17.6367 - lr: 1.0000e-05\n",
      "Epoch 213/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1984 - val_loss: 17.6369 - lr: 1.0000e-05\n",
      "Epoch 214/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1985 - val_loss: 17.6363 - lr: 1.0000e-05\n",
      "Epoch 215/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1976 - val_loss: 17.6355 - lr: 1.0000e-05\n",
      "Epoch 216/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.1976 - val_loss: 17.6347 - lr: 1.0000e-05\n",
      "Epoch 217/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.1971 - val_loss: 17.6335 - lr: 1.0000e-05\n",
      "Epoch 218/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1965 - val_loss: 17.6347 - lr: 1.0000e-05\n",
      "Epoch 219/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1962 - val_loss: 17.6353 - lr: 1.0000e-05\n",
      "Epoch 220/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1955 - val_loss: 17.6370 - lr: 1.0000e-05\n",
      "Epoch 221/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1954 - val_loss: 17.6359 - lr: 1.0000e-05\n",
      "Epoch 222/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1948 - val_loss: 17.6357 - lr: 1.0000e-05\n",
      "Epoch 223/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1945 - val_loss: 17.6349 - lr: 1.0000e-05\n",
      "Epoch 224/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1939 - val_loss: 17.6361 - lr: 1.0000e-05\n",
      "Epoch 225/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1935 - val_loss: 17.6353 - lr: 1.0000e-05\n",
      "Epoch 226/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1934 - val_loss: 17.6340 - lr: 1.0000e-05\n",
      "Epoch 227/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1929 - val_loss: 17.6340 - lr: 1.0000e-05\n",
      "Epoch 228/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1924 - val_loss: 17.6336 - lr: 1.0000e-05\n",
      "Epoch 229/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1919 - val_loss: 17.6331 - lr: 1.0000e-05\n",
      "Epoch 230/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.1913 - val_loss: 17.6327 - lr: 1.0000e-05\n",
      "Epoch 231/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1914 - val_loss: 17.6313 - lr: 1.0000e-05\n",
      "Epoch 232/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1909 - val_loss: 17.6311 - lr: 1.0000e-05\n",
      "Epoch 233/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1905 - val_loss: 17.6315 - lr: 1.0000e-05\n",
      "Epoch 234/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.1900 - val_loss: 17.6315 - lr: 1.0000e-05\n",
      "Epoch 235/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1896 - val_loss: 17.6304 - lr: 1.0000e-05\n",
      "Epoch 236/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1896 - val_loss: 17.6298 - lr: 1.0000e-05\n",
      "Epoch 237/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1887 - val_loss: 17.6295 - lr: 1.0000e-05\n",
      "Epoch 238/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1883 - val_loss: 17.6273 - lr: 1.0000e-05\n",
      "Epoch 239/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1883 - val_loss: 17.6286 - lr: 1.0000e-05\n",
      "Epoch 240/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1876 - val_loss: 17.6281 - lr: 1.0000e-05\n",
      "Epoch 241/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1873 - val_loss: 17.6285 - lr: 1.0000e-05\n",
      "Epoch 242/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1867 - val_loss: 17.6292 - lr: 1.0000e-05\n",
      "Epoch 243/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.1862 - val_loss: 17.6311 - lr: 1.0000e-05\n",
      "Epoch 244/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1860 - val_loss: 17.6317 - lr: 1.0000e-05\n",
      "Epoch 245/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1856 - val_loss: 17.6309 - lr: 1.0000e-05\n",
      "Epoch 246/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1852 - val_loss: 17.6300 - lr: 1.0000e-05\n",
      "Epoch 247/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1847 - val_loss: 17.6281 - lr: 1.0000e-05\n",
      "Epoch 248/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1844 - val_loss: 17.6272 - lr: 1.0000e-05\n",
      "Epoch 249/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1840 - val_loss: 17.6266 - lr: 1.0000e-05\n",
      "Epoch 250/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1840 - val_loss: 17.6249 - lr: 1.0000e-05\n",
      "Epoch 251/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.1832 - val_loss: 17.6252 - lr: 1.0000e-05\n",
      "Epoch 252/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1826 - val_loss: 17.6239 - lr: 1.0000e-05\n",
      "Epoch 253/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1823 - val_loss: 17.6234 - lr: 1.0000e-05\n",
      "Epoch 254/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1819 - val_loss: 17.6229 - lr: 1.0000e-05\n",
      "Epoch 255/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1812 - val_loss: 17.6230 - lr: 1.0000e-05\n",
      "Epoch 256/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1811 - val_loss: 17.6239 - lr: 1.0000e-05\n",
      "Epoch 257/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1807 - val_loss: 17.6245 - lr: 1.0000e-05\n",
      "Epoch 258/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1802 - val_loss: 17.6248 - lr: 1.0000e-05\n",
      "Epoch 259/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1799 - val_loss: 17.6249 - lr: 1.0000e-05\n",
      "Epoch 260/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1795 - val_loss: 17.6237 - lr: 1.0000e-05\n",
      "Epoch 261/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1792 - val_loss: 17.6229 - lr: 1.0000e-05\n",
      "Epoch 262/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1786 - val_loss: 17.6239 - lr: 1.0000e-05\n",
      "Epoch 263/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1785 - val_loss: 17.6244 - lr: 1.0000e-05\n",
      "Epoch 264/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1781 - val_loss: 17.6219 - lr: 1.0000e-05\n",
      "Epoch 265/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1776 - val_loss: 17.6199 - lr: 1.0000e-05\n",
      "Epoch 266/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1769 - val_loss: 17.6186 - lr: 1.0000e-05\n",
      "Epoch 267/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1767 - val_loss: 17.6193 - lr: 1.0000e-05\n",
      "Epoch 268/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1764 - val_loss: 17.6194 - lr: 1.0000e-05\n",
      "Epoch 269/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1759 - val_loss: 17.6169 - lr: 1.0000e-05\n",
      "Epoch 270/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1757 - val_loss: 17.6166 - lr: 1.0000e-05\n",
      "Epoch 271/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1754 - val_loss: 17.6158 - lr: 1.0000e-05\n",
      "Epoch 272/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1748 - val_loss: 17.6165 - lr: 1.0000e-05\n",
      "Epoch 273/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1747 - val_loss: 17.6173 - lr: 1.0000e-05\n",
      "Epoch 274/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1740 - val_loss: 17.6167 - lr: 1.0000e-05\n",
      "Epoch 275/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1738 - val_loss: 17.6161 - lr: 1.0000e-05\n",
      "Epoch 276/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1736 - val_loss: 17.6148 - lr: 1.0000e-05\n",
      "Epoch 277/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1731 - val_loss: 17.6149 - lr: 1.0000e-05\n",
      "Epoch 278/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1724 - val_loss: 17.6152 - lr: 1.0000e-05\n",
      "Epoch 279/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1722 - val_loss: 17.6154 - lr: 1.0000e-05\n",
      "Epoch 280/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1718 - val_loss: 17.6155 - lr: 1.0000e-05\n",
      "Epoch 281/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1713 - val_loss: 17.6172 - lr: 1.0000e-05\n",
      "Epoch 282/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1709 - val_loss: 17.6155 - lr: 1.0000e-05\n",
      "Epoch 283/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1704 - val_loss: 17.6167 - lr: 1.0000e-05\n",
      "Epoch 284/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1702 - val_loss: 17.6158 - lr: 1.0000e-05\n",
      "Epoch 285/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1696 - val_loss: 17.6141 - lr: 1.0000e-05\n",
      "Epoch 286/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1691 - val_loss: 17.6145 - lr: 1.0000e-05\n",
      "Epoch 287/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1688 - val_loss: 17.6143 - lr: 1.0000e-05\n",
      "Epoch 288/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1687 - val_loss: 17.6143 - lr: 1.0000e-05\n",
      "Epoch 289/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1682 - val_loss: 17.6145 - lr: 1.0000e-05\n",
      "Epoch 290/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1677 - val_loss: 17.6123 - lr: 1.0000e-05\n",
      "Epoch 291/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1678 - val_loss: 17.6104 - lr: 1.0000e-05\n",
      "Epoch 292/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1674 - val_loss: 17.6115 - lr: 1.0000e-05\n",
      "Epoch 293/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1664 - val_loss: 17.6115 - lr: 1.0000e-05\n",
      "Epoch 294/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1662 - val_loss: 17.6112 - lr: 1.0000e-05\n",
      "Epoch 295/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1660 - val_loss: 17.6107 - lr: 1.0000e-05\n",
      "Epoch 296/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1650 - val_loss: 17.6119 - lr: 1.0000e-05\n",
      "Epoch 297/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.1649 - val_loss: 17.6106 - lr: 1.0000e-05\n",
      "Epoch 298/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.1644 - val_loss: 17.6118 - lr: 1.0000e-05\n",
      "Epoch 299/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1643 - val_loss: 17.6122 - lr: 1.0000e-05\n",
      "Epoch 300/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1639 - val_loss: 17.6103 - lr: 1.0000e-05\n",
      "138/138 [==============================] - 0s 1ms/step\n",
      "Epoch 1/300\n",
      "31/31 [==============================] - 1s 9ms/step - loss: 712.4181 - val_loss: 656.1691 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 585.1421 - val_loss: 514.7897 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 446.8504 - val_loss: 383.7506 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 325.7081 - val_loss: 272.4170 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 224.3584 - val_loss: 183.7695 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 152.0153 - val_loss: 129.3544 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 112.0534 - val_loss: 102.1116 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 93.1688 - val_loss: 90.2932 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 84.9171 - val_loss: 84.1256 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 79.0090 - val_loss: 77.3569 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 71.7308 - val_loss: 69.4691 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 64.0293 - val_loss: 61.6736 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 56.8615 - val_loss: 54.9780 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 51.0539 - val_loss: 49.9477 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 46.6768 - val_loss: 46.2086 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 43.4845 - val_loss: 43.4653 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 41.0516 - val_loss: 41.3387 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 39.1759 - val_loss: 39.6928 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 37.6691 - val_loss: 38.3177 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 36.4447 - val_loss: 37.1994 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 35.4006 - val_loss: 36.2321 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 34.4992 - val_loss: 35.4502 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 33.6834 - val_loss: 34.5931 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 32.8811 - val_loss: 33.8490 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 32.1872 - val_loss: 33.2319 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 31.5117 - val_loss: 32.5125 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 30.9178 - val_loss: 32.0425 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 30.3541 - val_loss: 31.4712 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 29.8813 - val_loss: 31.0443 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 29.4224 - val_loss: 30.5964 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 29.0319 - val_loss: 30.1790 - lr: 0.0010\n",
      "Epoch 32/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 28.6088 - val_loss: 29.8406 - lr: 0.0010\n",
      "Epoch 33/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 28.2898 - val_loss: 29.4939 - lr: 0.0010\n",
      "Epoch 34/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 27.9030 - val_loss: 29.1885 - lr: 0.0010\n",
      "Epoch 35/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 27.6107 - val_loss: 28.8428 - lr: 0.0010\n",
      "Epoch 36/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 27.2812 - val_loss: 28.5208 - lr: 0.0010\n",
      "Epoch 37/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 26.9559 - val_loss: 28.2120 - lr: 0.0010\n",
      "Epoch 38/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 26.6655 - val_loss: 27.9703 - lr: 0.0010\n",
      "Epoch 39/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.3846 - val_loss: 27.6474 - lr: 0.0010\n",
      "Epoch 40/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.0947 - val_loss: 27.4004 - lr: 0.0010\n",
      "Epoch 41/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.8769 - val_loss: 27.1311 - lr: 0.0010\n",
      "Epoch 42/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.6695 - val_loss: 26.8994 - lr: 0.0010\n",
      "Epoch 43/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.3636 - val_loss: 26.6158 - lr: 0.0010\n",
      "Epoch 44/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.1304 - val_loss: 26.3853 - lr: 0.0010\n",
      "Epoch 45/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.9086 - val_loss: 26.1637 - lr: 0.0010\n",
      "Epoch 46/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.6699 - val_loss: 25.9373 - lr: 0.0010\n",
      "Epoch 47/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.5004 - val_loss: 25.7768 - lr: 0.0010\n",
      "Epoch 48/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.3025 - val_loss: 25.6933 - lr: 0.0010\n",
      "Epoch 49/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 24.1635 - val_loss: 25.4407 - lr: 0.0010\n",
      "Epoch 50/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.9836 - val_loss: 25.2542 - lr: 0.0010\n",
      "Epoch 51/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.8312 - val_loss: 25.1405 - lr: 0.0010\n",
      "Epoch 52/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.6879 - val_loss: 24.9688 - lr: 0.0010\n",
      "Epoch 53/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.5093 - val_loss: 24.8120 - lr: 0.0010\n",
      "Epoch 54/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.3669 - val_loss: 24.7423 - lr: 0.0010\n",
      "Epoch 55/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.2392 - val_loss: 24.5233 - lr: 0.0010\n",
      "Epoch 56/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 23.1137 - val_loss: 24.5031 - lr: 0.0010\n",
      "Epoch 57/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.9989 - val_loss: 24.3690 - lr: 0.0010\n",
      "Epoch 58/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.8521 - val_loss: 24.2868 - lr: 0.0010\n",
      "Epoch 59/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.7586 - val_loss: 24.1301 - lr: 0.0010\n",
      "Epoch 60/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.6154 - val_loss: 24.0076 - lr: 0.0010\n",
      "Epoch 61/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.4931 - val_loss: 23.8576 - lr: 0.0010\n",
      "Epoch 62/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.3586 - val_loss: 23.7585 - lr: 0.0010\n",
      "Epoch 63/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.2223 - val_loss: 23.6577 - lr: 0.0010\n",
      "Epoch 64/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 22.1045 - val_loss: 23.6056 - lr: 0.0010\n",
      "Epoch 65/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 21.9585 - val_loss: 23.4562 - lr: 0.0010\n",
      "Epoch 66/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.8120 - val_loss: 23.3611 - lr: 0.0010\n",
      "Epoch 67/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.7016 - val_loss: 23.2403 - lr: 0.0010\n",
      "Epoch 68/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.5907 - val_loss: 23.1762 - lr: 0.0010\n",
      "Epoch 69/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.4522 - val_loss: 23.0593 - lr: 0.0010\n",
      "Epoch 70/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.3805 - val_loss: 22.9563 - lr: 0.0010\n",
      "Epoch 71/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.2187 - val_loss: 22.8575 - lr: 0.0010\n",
      "Epoch 72/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 21.0738 - val_loss: 22.7324 - lr: 0.0010\n",
      "Epoch 73/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 20.9930 - val_loss: 22.7082 - lr: 0.0010\n",
      "Epoch 74/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.8707 - val_loss: 22.5837 - lr: 0.0010\n",
      "Epoch 75/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.7450 - val_loss: 22.4298 - lr: 0.0010\n",
      "Epoch 76/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.6055 - val_loss: 22.3775 - lr: 0.0010\n",
      "Epoch 77/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 20.5650 - val_loss: 22.3014 - lr: 0.0010\n",
      "Epoch 78/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.3926 - val_loss: 22.1506 - lr: 0.0010\n",
      "Epoch 79/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.2946 - val_loss: 22.0875 - lr: 0.0010\n",
      "Epoch 80/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.1891 - val_loss: 21.8963 - lr: 0.0010\n",
      "Epoch 81/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.0799 - val_loss: 21.8607 - lr: 0.0010\n",
      "Epoch 82/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.9804 - val_loss: 21.7733 - lr: 0.0010\n",
      "Epoch 83/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.8879 - val_loss: 21.7144 - lr: 0.0010\n",
      "Epoch 84/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.8043 - val_loss: 21.5775 - lr: 0.0010\n",
      "Epoch 85/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.6716 - val_loss: 21.5110 - lr: 0.0010\n",
      "Epoch 86/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 19.6041 - val_loss: 21.4131 - lr: 0.0010\n",
      "Epoch 87/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.4757 - val_loss: 21.3985 - lr: 0.0010\n",
      "Epoch 88/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.4214 - val_loss: 21.2456 - lr: 0.0010\n",
      "Epoch 89/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 19.2968 - val_loss: 21.1906 - lr: 0.0010\n",
      "Epoch 90/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.1942 - val_loss: 21.1453 - lr: 0.0010\n",
      "Epoch 91/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 19.1896 - val_loss: 21.0450 - lr: 0.0010\n",
      "Epoch 92/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.0698 - val_loss: 21.0099 - lr: 0.0010\n",
      "Epoch 93/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.9652 - val_loss: 20.8336 - lr: 0.0010\n",
      "Epoch 94/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.0174 - val_loss: 20.7460 - lr: 0.0010\n",
      "Epoch 95/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 18.7747 - val_loss: 20.6659 - lr: 0.0010\n",
      "Epoch 96/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.7174 - val_loss: 20.6226 - lr: 0.0010\n",
      "Epoch 97/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 18.6609 - val_loss: 20.5584 - lr: 0.0010\n",
      "Epoch 98/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.5330 - val_loss: 20.4373 - lr: 0.0010\n",
      "Epoch 99/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.4990 - val_loss: 20.3656 - lr: 0.0010\n",
      "Epoch 100/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.4273 - val_loss: 20.3063 - lr: 0.0010\n",
      "Epoch 101/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.3062 - val_loss: 20.2468 - lr: 0.0010\n",
      "Epoch 102/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.2487 - val_loss: 20.1917 - lr: 0.0010\n",
      "Epoch 103/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.1909 - val_loss: 20.1311 - lr: 0.0010\n",
      "Epoch 104/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.1213 - val_loss: 19.9850 - lr: 0.0010\n",
      "Epoch 105/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.0911 - val_loss: 19.9726 - lr: 0.0010\n",
      "Epoch 106/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 17.9826 - val_loss: 19.8888 - lr: 0.0010\n",
      "Epoch 107/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.9447 - val_loss: 19.8829 - lr: 0.0010\n",
      "Epoch 108/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.8476 - val_loss: 19.8154 - lr: 0.0010\n",
      "Epoch 109/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.7911 - val_loss: 19.7775 - lr: 0.0010\n",
      "Epoch 110/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.7366 - val_loss: 19.6530 - lr: 0.0010\n",
      "Epoch 111/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.6862 - val_loss: 19.6915 - lr: 0.0010\n",
      "Epoch 112/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.6774 - val_loss: 19.5868 - lr: 0.0010\n",
      "Epoch 113/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.5776 - val_loss: 19.5704 - lr: 0.0010\n",
      "Epoch 114/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.5262 - val_loss: 19.4765 - lr: 0.0010\n",
      "Epoch 115/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.4679 - val_loss: 19.3691 - lr: 0.0010\n",
      "Epoch 116/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.4349 - val_loss: 19.2636 - lr: 0.0010\n",
      "Epoch 117/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.3094 - val_loss: 19.2909 - lr: 0.0010\n",
      "Epoch 118/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 17.2621 - val_loss: 19.1511 - lr: 0.0010\n",
      "Epoch 119/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.2661 - val_loss: 19.1096 - lr: 0.0010\n",
      "Epoch 120/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.1506 - val_loss: 19.1096 - lr: 0.0010\n",
      "Epoch 121/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.1265 - val_loss: 19.0205 - lr: 0.0010\n",
      "Epoch 122/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.0446 - val_loss: 18.9782 - lr: 0.0010\n",
      "Epoch 123/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.9950 - val_loss: 18.8760 - lr: 0.0010\n",
      "Epoch 124/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.9261 - val_loss: 18.8933 - lr: 0.0010\n",
      "Epoch 125/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.8925 - val_loss: 18.7594 - lr: 0.0010\n",
      "Epoch 126/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.8086 - val_loss: 18.7080 - lr: 0.0010\n",
      "Epoch 127/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.7854 - val_loss: 18.6779 - lr: 0.0010\n",
      "Epoch 128/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 16.7329 - val_loss: 18.6040 - lr: 0.0010\n",
      "Epoch 129/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.7140 - val_loss: 18.5870 - lr: 0.0010\n",
      "Epoch 130/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.6444 - val_loss: 18.6093 - lr: 0.0010\n",
      "Epoch 131/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 16.6210 - val_loss: 18.5656 - lr: 0.0010\n",
      "Epoch 132/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.5095 - val_loss: 18.4599 - lr: 0.0010\n",
      "Epoch 133/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4658 - val_loss: 18.4774 - lr: 0.0010\n",
      "Epoch 134/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4205 - val_loss: 18.3613 - lr: 0.0010\n",
      "Epoch 135/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3558 - val_loss: 18.2880 - lr: 0.0010\n",
      "Epoch 136/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3220 - val_loss: 18.2899 - lr: 0.0010\n",
      "Epoch 137/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.3034 - val_loss: 18.2034 - lr: 0.0010\n",
      "Epoch 138/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 16.3143 - val_loss: 18.1786 - lr: 0.0010\n",
      "Epoch 139/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.2259 - val_loss: 18.1699 - lr: 0.0010\n",
      "Epoch 140/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.1792 - val_loss: 18.1612 - lr: 0.0010\n",
      "Epoch 141/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.1288 - val_loss: 18.0895 - lr: 0.0010\n",
      "Epoch 142/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.1093 - val_loss: 18.0408 - lr: 0.0010\n",
      "Epoch 143/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.0168 - val_loss: 17.9671 - lr: 0.0010\n",
      "Epoch 144/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9817 - val_loss: 17.9661 - lr: 0.0010\n",
      "Epoch 145/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9466 - val_loss: 17.9430 - lr: 0.0010\n",
      "Epoch 146/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9264 - val_loss: 17.8502 - lr: 0.0010\n",
      "Epoch 147/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8598 - val_loss: 17.8955 - lr: 0.0010\n",
      "Epoch 148/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8269 - val_loss: 17.8281 - lr: 0.0010\n",
      "Epoch 149/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7959 - val_loss: 17.8513 - lr: 0.0010\n",
      "Epoch 150/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7662 - val_loss: 17.7586 - lr: 0.0010\n",
      "Epoch 151/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7373 - val_loss: 17.6993 - lr: 0.0010\n",
      "Epoch 152/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6746 - val_loss: 17.6705 - lr: 0.0010\n",
      "Epoch 153/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6442 - val_loss: 17.6619 - lr: 0.0010\n",
      "Epoch 154/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6147 - val_loss: 17.6900 - lr: 0.0010\n",
      "Epoch 155/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.5702 - val_loss: 17.6701 - lr: 0.0010\n",
      "Epoch 156/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.5259 - val_loss: 17.6485 - lr: 0.0010\n",
      "Epoch 157/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.5491 - val_loss: 17.5363 - lr: 0.0010\n",
      "Epoch 158/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.4590 - val_loss: 17.5341 - lr: 0.0010\n",
      "Epoch 159/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.4431 - val_loss: 17.3808 - lr: 0.0010\n",
      "Epoch 160/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.3906 - val_loss: 17.4756 - lr: 0.0010\n",
      "Epoch 161/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.3822 - val_loss: 17.4596 - lr: 0.0010\n",
      "Epoch 162/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.3674 - val_loss: 17.3727 - lr: 0.0010\n",
      "Epoch 163/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.3000 - val_loss: 17.4438 - lr: 0.0010\n",
      "Epoch 164/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2712 - val_loss: 17.3970 - lr: 0.0010\n",
      "Epoch 165/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2646 - val_loss: 17.3099 - lr: 0.0010\n",
      "Epoch 166/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2209 - val_loss: 17.3339 - lr: 0.0010\n",
      "Epoch 167/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.2206 - val_loss: 17.2880 - lr: 0.0010\n",
      "Epoch 168/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.1529 - val_loss: 17.2415 - lr: 0.0010\n",
      "Epoch 169/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1460 - val_loss: 17.2338 - lr: 0.0010\n",
      "Epoch 170/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1287 - val_loss: 17.1680 - lr: 0.0010\n",
      "Epoch 171/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.0725 - val_loss: 17.1867 - lr: 0.0010\n",
      "Epoch 172/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.0519 - val_loss: 17.1315 - lr: 0.0010\n",
      "Epoch 173/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.0225 - val_loss: 17.1514 - lr: 0.0010\n",
      "Epoch 174/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.9740 - val_loss: 17.1000 - lr: 0.0010\n",
      "Epoch 175/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.9584 - val_loss: 17.0780 - lr: 0.0010\n",
      "Epoch 176/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.9516 - val_loss: 17.0896 - lr: 0.0010\n",
      "Epoch 177/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.9276 - val_loss: 17.0121 - lr: 0.0010\n",
      "Epoch 178/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8988 - val_loss: 17.0601 - lr: 0.0010\n",
      "Epoch 179/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8945 - val_loss: 16.9657 - lr: 0.0010\n",
      "Epoch 180/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8449 - val_loss: 16.9251 - lr: 0.0010\n",
      "Epoch 181/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8133 - val_loss: 16.9942 - lr: 0.0010\n",
      "Epoch 182/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7810 - val_loss: 16.9169 - lr: 0.0010\n",
      "Epoch 183/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8671 - val_loss: 17.0219 - lr: 0.0010\n",
      "Epoch 184/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7512 - val_loss: 16.8298 - lr: 0.0010\n",
      "Epoch 185/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.6789 - val_loss: 16.7968 - lr: 0.0010\n",
      "Epoch 186/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.6900 - val_loss: 16.9516 - lr: 0.0010\n",
      "Epoch 187/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6916 - val_loss: 16.7782 - lr: 0.0010\n",
      "Epoch 188/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6303 - val_loss: 16.8011 - lr: 0.0010\n",
      "Epoch 189/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6708 - val_loss: 16.8095 - lr: 0.0010\n",
      "Epoch 190/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5910 - val_loss: 16.7814 - lr: 0.0010\n",
      "Epoch 191/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.4856 - val_loss: 16.7244 - lr: 1.0000e-04\n",
      "Epoch 192/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.4558 - val_loss: 16.7317 - lr: 1.0000e-04\n",
      "Epoch 193/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.4440 - val_loss: 16.7242 - lr: 1.0000e-04\n",
      "Epoch 194/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.4385 - val_loss: 16.7236 - lr: 1.0000e-04\n",
      "Epoch 195/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.4397 - val_loss: 16.7422 - lr: 1.0000e-04\n",
      "Epoch 196/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.4300 - val_loss: 16.7233 - lr: 1.0000e-04\n",
      "Epoch 197/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.4289 - val_loss: 16.7546 - lr: 1.0000e-04\n",
      "Epoch 198/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.4291 - val_loss: 16.7193 - lr: 1.0000e-04\n",
      "Epoch 199/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.4199 - val_loss: 16.7077 - lr: 1.0000e-04\n",
      "Epoch 200/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.4173 - val_loss: 16.7228 - lr: 1.0000e-04\n",
      "Epoch 201/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.4193 - val_loss: 16.7427 - lr: 1.0000e-04\n",
      "Epoch 202/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.4123 - val_loss: 16.7315 - lr: 1.0000e-04\n",
      "Epoch 203/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.3995 - val_loss: 16.7249 - lr: 1.0000e-05\n",
      "Epoch 204/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.3985 - val_loss: 16.7227 - lr: 1.0000e-05\n",
      "Epoch 205/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.3976 - val_loss: 16.7183 - lr: 1.0000e-05\n",
      "Epoch 206/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.3972 - val_loss: 16.7140 - lr: 1.0000e-05\n",
      "Epoch 207/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.3972 - val_loss: 16.7136 - lr: 1.0000e-05\n",
      "Epoch 208/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.3968 - val_loss: 16.7109 - lr: 1.0000e-05\n",
      "Epoch 209/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.3960 - val_loss: 16.7174 - lr: 1.0000e-05\n",
      "Epoch 210/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.3958 - val_loss: 16.7185 - lr: 1.0000e-05\n",
      "Epoch 211/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.3954 - val_loss: 16.7200 - lr: 1.0000e-05\n",
      "Epoch 212/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.3950 - val_loss: 16.7137 - lr: 1.0000e-05\n",
      "Epoch 213/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.3942 - val_loss: 16.7181 - lr: 1.0000e-05\n",
      "Epoch 214/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.3940 - val_loss: 16.7184 - lr: 1.0000e-05\n",
      "Epoch 215/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.3934 - val_loss: 16.7139 - lr: 1.0000e-05\n",
      "Epoch 216/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.3931 - val_loss: 16.7148 - lr: 1.0000e-05\n",
      "Epoch 217/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.3925 - val_loss: 16.7123 - lr: 1.0000e-05\n",
      "Epoch 218/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.3923 - val_loss: 16.7126 - lr: 1.0000e-05\n",
      "Epoch 219/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.3920 - val_loss: 16.7121 - lr: 1.0000e-05\n",
      "138/138 [==============================] - 0s 2ms/step\n",
      "Epoch 1/300\n",
      "31/31 [==============================] - 1s 8ms/step - loss: 718.6758 - val_loss: 646.0179 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 590.0843 - val_loss: 511.8351 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 454.6570 - val_loss: 380.9709 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 331.7293 - val_loss: 270.0114 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 231.1941 - val_loss: 182.1559 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 155.1549 - val_loss: 123.2502 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 110.2418 - val_loss: 94.0789 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 90.5496 - val_loss: 83.6829 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 83.3290 - val_loss: 78.8499 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 77.9128 - val_loss: 72.8006 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 71.2564 - val_loss: 65.7974 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 63.8687 - val_loss: 58.1570 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 56.1330 - val_loss: 50.6756 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 49.4138 - val_loss: 44.9097 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 44.5028 - val_loss: 40.9340 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 41.2093 - val_loss: 38.2369 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 38.9593 - val_loss: 36.4227 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 37.3301 - val_loss: 35.0157 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 36.0963 - val_loss: 33.9457 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 35.0498 - val_loss: 32.9184 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 34.0781 - val_loss: 32.0222 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 33.1548 - val_loss: 31.1961 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 32.2804 - val_loss: 30.4135 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 31.5350 - val_loss: 29.8391 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 30.8940 - val_loss: 29.2503 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 30.2860 - val_loss: 28.8217 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 29.7723 - val_loss: 28.3488 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 29.2662 - val_loss: 27.9416 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 28.7614 - val_loss: 27.5747 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 28.3229 - val_loss: 27.2194 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 27.9433 - val_loss: 26.9210 - lr: 0.0010\n",
      "Epoch 32/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 27.5487 - val_loss: 26.5967 - lr: 0.0010\n",
      "Epoch 33/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 27.1682 - val_loss: 26.2114 - lr: 0.0010\n",
      "Epoch 34/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.8398 - val_loss: 25.9552 - lr: 0.0010\n",
      "Epoch 35/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.5208 - val_loss: 25.6949 - lr: 0.0010\n",
      "Epoch 36/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.2435 - val_loss: 25.4226 - lr: 0.0010\n",
      "Epoch 37/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 25.9811 - val_loss: 25.3692 - lr: 0.0010\n",
      "Epoch 38/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.7415 - val_loss: 24.9883 - lr: 0.0010\n",
      "Epoch 39/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.4864 - val_loss: 24.8330 - lr: 0.0010\n",
      "Epoch 40/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.2601 - val_loss: 24.6656 - lr: 0.0010\n",
      "Epoch 41/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 25.0668 - val_loss: 24.5244 - lr: 0.0010\n",
      "Epoch 42/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.9267 - val_loss: 24.3345 - lr: 0.0010\n",
      "Epoch 43/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.6787 - val_loss: 24.1487 - lr: 0.0010\n",
      "Epoch 44/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.4939 - val_loss: 23.9250 - lr: 0.0010\n",
      "Epoch 45/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.3210 - val_loss: 23.8079 - lr: 0.0010\n",
      "Epoch 46/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.1605 - val_loss: 23.6417 - lr: 0.0010\n",
      "Epoch 47/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.9784 - val_loss: 23.5108 - lr: 0.0010\n",
      "Epoch 48/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.8324 - val_loss: 23.4462 - lr: 0.0010\n",
      "Epoch 49/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.6996 - val_loss: 23.2373 - lr: 0.0010\n",
      "Epoch 50/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 23.5638 - val_loss: 23.2329 - lr: 0.0010\n",
      "Epoch 51/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.4736 - val_loss: 23.0337 - lr: 0.0010\n",
      "Epoch 52/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.3343 - val_loss: 23.1353 - lr: 0.0010\n",
      "Epoch 53/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.1647 - val_loss: 22.8087 - lr: 0.0010\n",
      "Epoch 54/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.0440 - val_loss: 22.7402 - lr: 0.0010\n",
      "Epoch 55/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.8872 - val_loss: 22.6579 - lr: 0.0010\n",
      "Epoch 56/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.7700 - val_loss: 22.5084 - lr: 0.0010\n",
      "Epoch 57/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.7249 - val_loss: 22.3756 - lr: 0.0010\n",
      "Epoch 58/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.5048 - val_loss: 22.1975 - lr: 0.0010\n",
      "Epoch 59/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.3607 - val_loss: 22.1777 - lr: 0.0010\n",
      "Epoch 60/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.2902 - val_loss: 22.2194 - lr: 0.0010\n",
      "Epoch 61/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.2360 - val_loss: 21.9689 - lr: 0.0010\n",
      "Epoch 62/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.0347 - val_loss: 21.8773 - lr: 0.0010\n",
      "Epoch 63/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.9793 - val_loss: 21.7045 - lr: 0.0010\n",
      "Epoch 64/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 21.8424 - val_loss: 21.6193 - lr: 0.0010\n",
      "Epoch 65/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.7144 - val_loss: 21.5980 - lr: 0.0010\n",
      "Epoch 66/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.6298 - val_loss: 21.3853 - lr: 0.0010\n",
      "Epoch 67/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.5323 - val_loss: 21.3715 - lr: 0.0010\n",
      "Epoch 68/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.4259 - val_loss: 21.1908 - lr: 0.0010\n",
      "Epoch 69/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.3449 - val_loss: 21.1879 - lr: 0.0010\n",
      "Epoch 70/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.2422 - val_loss: 21.1144 - lr: 0.0010\n",
      "Epoch 71/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.1717 - val_loss: 20.9576 - lr: 0.0010\n",
      "Epoch 72/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.1023 - val_loss: 20.9737 - lr: 0.0010\n",
      "Epoch 73/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.9978 - val_loss: 20.8621 - lr: 0.0010\n",
      "Epoch 74/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 20.9016 - val_loss: 20.7828 - lr: 0.0010\n",
      "Epoch 75/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.7891 - val_loss: 20.7533 - lr: 0.0010\n",
      "Epoch 76/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.7486 - val_loss: 20.7525 - lr: 0.0010\n",
      "Epoch 77/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.6694 - val_loss: 20.5930 - lr: 0.0010\n",
      "Epoch 78/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.5553 - val_loss: 20.4116 - lr: 0.0010\n",
      "Epoch 79/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.4632 - val_loss: 20.3490 - lr: 0.0010\n",
      "Epoch 80/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.3468 - val_loss: 20.2756 - lr: 0.0010\n",
      "Epoch 81/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.3072 - val_loss: 20.1308 - lr: 0.0010\n",
      "Epoch 82/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 20.2088 - val_loss: 20.1510 - lr: 0.0010\n",
      "Epoch 83/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.1149 - val_loss: 19.9698 - lr: 0.0010\n",
      "Epoch 84/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.0819 - val_loss: 19.8868 - lr: 0.0010\n",
      "Epoch 85/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.9327 - val_loss: 19.8073 - lr: 0.0010\n",
      "Epoch 86/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.8152 - val_loss: 19.7573 - lr: 0.0010\n",
      "Epoch 87/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.7129 - val_loss: 19.6370 - lr: 0.0010\n",
      "Epoch 88/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.6287 - val_loss: 19.5664 - lr: 0.0010\n",
      "Epoch 89/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.5534 - val_loss: 19.4534 - lr: 0.0010\n",
      "Epoch 90/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.4498 - val_loss: 19.3916 - lr: 0.0010\n",
      "Epoch 91/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.3960 - val_loss: 19.2701 - lr: 0.0010\n",
      "Epoch 92/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.2859 - val_loss: 19.1414 - lr: 0.0010\n",
      "Epoch 93/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.1751 - val_loss: 19.1400 - lr: 0.0010\n",
      "Epoch 94/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 19.1003 - val_loss: 19.0036 - lr: 0.0010\n",
      "Epoch 95/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.0011 - val_loss: 18.8388 - lr: 0.0010\n",
      "Epoch 96/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.9152 - val_loss: 18.8540 - lr: 0.0010\n",
      "Epoch 97/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.8472 - val_loss: 18.7462 - lr: 0.0010\n",
      "Epoch 98/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.7190 - val_loss: 18.6678 - lr: 0.0010\n",
      "Epoch 99/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.6179 - val_loss: 18.5720 - lr: 0.0010\n",
      "Epoch 100/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 18.4947 - val_loss: 18.5400 - lr: 0.0010\n",
      "Epoch 101/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.4265 - val_loss: 18.4765 - lr: 0.0010\n",
      "Epoch 102/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.3588 - val_loss: 18.4396 - lr: 0.0010\n",
      "Epoch 103/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.2933 - val_loss: 18.3367 - lr: 0.0010\n",
      "Epoch 104/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.1698 - val_loss: 18.2743 - lr: 0.0010\n",
      "Epoch 105/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 18.1250 - val_loss: 18.1051 - lr: 0.0010\n",
      "Epoch 106/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.9760 - val_loss: 18.0707 - lr: 0.0010\n",
      "Epoch 107/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.9435 - val_loss: 18.0269 - lr: 0.0010\n",
      "Epoch 108/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.8894 - val_loss: 17.9614 - lr: 0.0010\n",
      "Epoch 109/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 17.7434 - val_loss: 17.8503 - lr: 0.0010\n",
      "Epoch 110/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.6782 - val_loss: 17.8323 - lr: 0.0010\n",
      "Epoch 111/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.6364 - val_loss: 17.7137 - lr: 0.0010\n",
      "Epoch 112/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.5789 - val_loss: 17.7093 - lr: 0.0010\n",
      "Epoch 113/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.4770 - val_loss: 17.6239 - lr: 0.0010\n",
      "Epoch 114/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 17.4518 - val_loss: 17.5391 - lr: 0.0010\n",
      "Epoch 115/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.3858 - val_loss: 17.5583 - lr: 0.0010\n",
      "Epoch 116/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.3254 - val_loss: 17.4972 - lr: 0.0010\n",
      "Epoch 117/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.2294 - val_loss: 17.4705 - lr: 0.0010\n",
      "Epoch 118/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.1688 - val_loss: 17.3729 - lr: 0.0010\n",
      "Epoch 119/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.1257 - val_loss: 17.3356 - lr: 0.0010\n",
      "Epoch 120/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.0650 - val_loss: 17.2799 - lr: 0.0010\n",
      "Epoch 121/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.0461 - val_loss: 17.3224 - lr: 0.0010\n",
      "Epoch 122/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.9267 - val_loss: 17.1956 - lr: 0.0010\n",
      "Epoch 123/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.9337 - val_loss: 17.1139 - lr: 0.0010\n",
      "Epoch 124/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.9078 - val_loss: 17.1552 - lr: 0.0010\n",
      "Epoch 125/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.7895 - val_loss: 17.0686 - lr: 0.0010\n",
      "Epoch 126/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.7425 - val_loss: 17.0090 - lr: 0.0010\n",
      "Epoch 127/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.7514 - val_loss: 17.0376 - lr: 0.0010\n",
      "Epoch 128/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.6695 - val_loss: 16.9797 - lr: 0.0010\n",
      "Epoch 129/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.7066 - val_loss: 16.9195 - lr: 0.0010\n",
      "Epoch 130/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.5874 - val_loss: 16.9567 - lr: 0.0010\n",
      "Epoch 131/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.5223 - val_loss: 16.9076 - lr: 0.0010\n",
      "Epoch 132/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4515 - val_loss: 16.8470 - lr: 0.0010\n",
      "Epoch 133/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4388 - val_loss: 16.8253 - lr: 0.0010\n",
      "Epoch 134/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4359 - val_loss: 16.9084 - lr: 0.0010\n",
      "Epoch 135/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3808 - val_loss: 16.7726 - lr: 0.0010\n",
      "Epoch 136/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3044 - val_loss: 16.6954 - lr: 0.0010\n",
      "Epoch 137/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.2722 - val_loss: 16.7668 - lr: 0.0010\n",
      "Epoch 138/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.2813 - val_loss: 16.7162 - lr: 0.0010\n",
      "Epoch 139/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.2103 - val_loss: 16.7012 - lr: 0.0010\n",
      "Epoch 140/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.0517 - val_loss: 16.5901 - lr: 1.0000e-04\n",
      "Epoch 141/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.0104 - val_loss: 16.5738 - lr: 1.0000e-04\n",
      "Epoch 142/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.0045 - val_loss: 16.5853 - lr: 1.0000e-04\n",
      "Epoch 143/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.9949 - val_loss: 16.5660 - lr: 1.0000e-04\n",
      "Epoch 144/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9948 - val_loss: 16.5915 - lr: 1.0000e-04\n",
      "Epoch 145/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9888 - val_loss: 16.5564 - lr: 1.0000e-04\n",
      "Epoch 146/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9728 - val_loss: 16.5717 - lr: 1.0000e-04\n",
      "Epoch 147/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9698 - val_loss: 16.5564 - lr: 1.0000e-04\n",
      "Epoch 148/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9690 - val_loss: 16.5590 - lr: 1.0000e-04\n",
      "Epoch 149/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9486 - val_loss: 16.5574 - lr: 1.0000e-05\n",
      "Epoch 150/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9473 - val_loss: 16.5572 - lr: 1.0000e-05\n",
      "Epoch 151/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9471 - val_loss: 16.5554 - lr: 1.0000e-05\n",
      "Epoch 152/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9460 - val_loss: 16.5541 - lr: 1.0000e-05\n",
      "Epoch 153/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9455 - val_loss: 16.5547 - lr: 1.0000e-05\n",
      "Epoch 154/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9445 - val_loss: 16.5539 - lr: 1.0000e-05\n",
      "Epoch 155/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9438 - val_loss: 16.5526 - lr: 1.0000e-05\n",
      "Epoch 156/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9433 - val_loss: 16.5548 - lr: 1.0000e-05\n",
      "Epoch 157/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9432 - val_loss: 16.5547 - lr: 1.0000e-05\n",
      "Epoch 158/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9417 - val_loss: 16.5549 - lr: 1.0000e-05\n",
      "Epoch 159/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9412 - val_loss: 16.5524 - lr: 1.0000e-05\n",
      "Epoch 160/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9403 - val_loss: 16.5520 - lr: 1.0000e-05\n",
      "Epoch 161/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9398 - val_loss: 16.5518 - lr: 1.0000e-05\n",
      "Epoch 162/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9392 - val_loss: 16.5512 - lr: 1.0000e-05\n",
      "Epoch 163/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9382 - val_loss: 16.5510 - lr: 1.0000e-05\n",
      "Epoch 164/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9381 - val_loss: 16.5511 - lr: 1.0000e-05\n",
      "Epoch 165/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9374 - val_loss: 16.5504 - lr: 1.0000e-05\n",
      "Epoch 166/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9365 - val_loss: 16.5479 - lr: 1.0000e-05\n",
      "Epoch 167/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9362 - val_loss: 16.5483 - lr: 1.0000e-05\n",
      "Epoch 168/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9353 - val_loss: 16.5467 - lr: 1.0000e-05\n",
      "Epoch 169/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9348 - val_loss: 16.5475 - lr: 1.0000e-05\n",
      "Epoch 170/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9343 - val_loss: 16.5465 - lr: 1.0000e-05\n",
      "Epoch 171/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9338 - val_loss: 16.5447 - lr: 1.0000e-05\n",
      "Epoch 172/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9336 - val_loss: 16.5438 - lr: 1.0000e-05\n",
      "Epoch 173/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9330 - val_loss: 16.5442 - lr: 1.0000e-05\n",
      "Epoch 174/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9322 - val_loss: 16.5456 - lr: 1.0000e-05\n",
      "Epoch 175/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9319 - val_loss: 16.5470 - lr: 1.0000e-05\n",
      "Epoch 176/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9311 - val_loss: 16.5467 - lr: 1.0000e-05\n",
      "Epoch 177/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9309 - val_loss: 16.5460 - lr: 1.0000e-05\n",
      "Epoch 178/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9304 - val_loss: 16.5490 - lr: 1.0000e-05\n",
      "Epoch 179/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9298 - val_loss: 16.5462 - lr: 1.0000e-05\n",
      "Epoch 180/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9295 - val_loss: 16.5488 - lr: 1.0000e-05\n",
      "Epoch 181/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9288 - val_loss: 16.5513 - lr: 1.0000e-05\n",
      "Epoch 182/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9279 - val_loss: 16.5459 - lr: 1.0000e-05\n",
      "Epoch 183/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.9275 - val_loss: 16.5447 - lr: 1.0000e-05\n",
      "Epoch 184/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9271 - val_loss: 16.5421 - lr: 1.0000e-05\n",
      "Epoch 185/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9265 - val_loss: 16.5396 - lr: 1.0000e-05\n",
      "Epoch 186/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9255 - val_loss: 16.5425 - lr: 1.0000e-05\n",
      "Epoch 187/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9254 - val_loss: 16.5412 - lr: 1.0000e-05\n",
      "Epoch 188/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9252 - val_loss: 16.5375 - lr: 1.0000e-05\n",
      "Epoch 189/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9244 - val_loss: 16.5391 - lr: 1.0000e-05\n",
      "Epoch 190/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9239 - val_loss: 16.5392 - lr: 1.0000e-05\n",
      "Epoch 191/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9234 - val_loss: 16.5407 - lr: 1.0000e-05\n",
      "Epoch 192/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9227 - val_loss: 16.5413 - lr: 1.0000e-05\n",
      "Epoch 193/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9222 - val_loss: 16.5418 - lr: 1.0000e-05\n",
      "Epoch 194/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9218 - val_loss: 16.5438 - lr: 1.0000e-05\n",
      "Epoch 195/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9215 - val_loss: 16.5447 - lr: 1.0000e-05\n",
      "Epoch 196/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9208 - val_loss: 16.5395 - lr: 1.0000e-05\n",
      "Epoch 197/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9204 - val_loss: 16.5404 - lr: 1.0000e-05\n",
      "Epoch 198/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9199 - val_loss: 16.5396 - lr: 1.0000e-05\n",
      "Epoch 199/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9195 - val_loss: 16.5369 - lr: 1.0000e-05\n",
      "Epoch 200/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.9191 - val_loss: 16.5377 - lr: 1.0000e-05\n",
      "Epoch 201/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9185 - val_loss: 16.5393 - lr: 1.0000e-05\n",
      "Epoch 202/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9178 - val_loss: 16.5356 - lr: 1.0000e-05\n",
      "Epoch 203/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9175 - val_loss: 16.5354 - lr: 1.0000e-05\n",
      "Epoch 204/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9167 - val_loss: 16.5370 - lr: 1.0000e-05\n",
      "Epoch 205/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9163 - val_loss: 16.5383 - lr: 1.0000e-05\n",
      "Epoch 206/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9161 - val_loss: 16.5393 - lr: 1.0000e-05\n",
      "Epoch 207/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9154 - val_loss: 16.5351 - lr: 1.0000e-05\n",
      "Epoch 208/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9146 - val_loss: 16.5339 - lr: 1.0000e-05\n",
      "Epoch 209/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9146 - val_loss: 16.5318 - lr: 1.0000e-05\n",
      "Epoch 210/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.9133 - val_loss: 16.5347 - lr: 1.0000e-05\n",
      "Epoch 211/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9131 - val_loss: 16.5340 - lr: 1.0000e-05\n",
      "Epoch 212/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.9127 - val_loss: 16.5339 - lr: 1.0000e-05\n",
      "Epoch 213/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.9125 - val_loss: 16.5348 - lr: 1.0000e-05\n",
      "Epoch 214/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.9119 - val_loss: 16.5344 - lr: 1.0000e-05\n",
      "Epoch 215/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.9116 - val_loss: 16.5305 - lr: 1.0000e-05\n",
      "Epoch 216/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9108 - val_loss: 16.5302 - lr: 1.0000e-05\n",
      "Epoch 217/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9103 - val_loss: 16.5290 - lr: 1.0000e-05\n",
      "Epoch 218/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.9100 - val_loss: 16.5293 - lr: 1.0000e-05\n",
      "Epoch 219/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.9093 - val_loss: 16.5329 - lr: 1.0000e-05\n",
      "Epoch 220/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9087 - val_loss: 16.5296 - lr: 1.0000e-05\n",
      "Epoch 221/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.9082 - val_loss: 16.5301 - lr: 1.0000e-05\n",
      "Epoch 222/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9084 - val_loss: 16.5339 - lr: 1.0000e-05\n",
      "Epoch 223/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9072 - val_loss: 16.5291 - lr: 1.0000e-05\n",
      "Epoch 224/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9071 - val_loss: 16.5319 - lr: 1.0000e-05\n",
      "Epoch 225/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9067 - val_loss: 16.5295 - lr: 1.0000e-05\n",
      "Epoch 226/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9060 - val_loss: 16.5295 - lr: 1.0000e-05\n",
      "Epoch 227/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9060 - val_loss: 16.5299 - lr: 1.0000e-05\n",
      "Epoch 228/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9049 - val_loss: 16.5268 - lr: 1.0000e-05\n",
      "Epoch 229/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.9047 - val_loss: 16.5305 - lr: 1.0000e-05\n",
      "Epoch 230/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.9040 - val_loss: 16.5310 - lr: 1.0000e-05\n",
      "Epoch 231/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9036 - val_loss: 16.5301 - lr: 1.0000e-05\n",
      "Epoch 232/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9030 - val_loss: 16.5281 - lr: 1.0000e-05\n",
      "Epoch 233/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9029 - val_loss: 16.5283 - lr: 1.0000e-05\n",
      "Epoch 234/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9020 - val_loss: 16.5285 - lr: 1.0000e-05\n",
      "Epoch 235/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9018 - val_loss: 16.5265 - lr: 1.0000e-05\n",
      "Epoch 236/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9011 - val_loss: 16.5240 - lr: 1.0000e-05\n",
      "Epoch 237/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9008 - val_loss: 16.5232 - lr: 1.0000e-05\n",
      "Epoch 238/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.9000 - val_loss: 16.5252 - lr: 1.0000e-05\n",
      "Epoch 239/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.8994 - val_loss: 16.5256 - lr: 1.0000e-05\n",
      "Epoch 240/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8989 - val_loss: 16.5280 - lr: 1.0000e-05\n",
      "Epoch 241/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8986 - val_loss: 16.5261 - lr: 1.0000e-05\n",
      "Epoch 242/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8983 - val_loss: 16.5237 - lr: 1.0000e-05\n",
      "Epoch 243/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8976 - val_loss: 16.5235 - lr: 1.0000e-05\n",
      "Epoch 244/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8976 - val_loss: 16.5243 - lr: 1.0000e-05\n",
      "Epoch 245/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.8966 - val_loss: 16.5242 - lr: 1.0000e-05\n",
      "Epoch 246/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.8965 - val_loss: 16.5224 - lr: 1.0000e-05\n",
      "Epoch 247/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8954 - val_loss: 16.5245 - lr: 1.0000e-05\n",
      "Epoch 248/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8951 - val_loss: 16.5228 - lr: 1.0000e-05\n",
      "Epoch 249/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8947 - val_loss: 16.5204 - lr: 1.0000e-05\n",
      "Epoch 250/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8945 - val_loss: 16.5213 - lr: 1.0000e-05\n",
      "Epoch 251/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8942 - val_loss: 16.5219 - lr: 1.0000e-05\n",
      "Epoch 252/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.8935 - val_loss: 16.5209 - lr: 1.0000e-05\n",
      "Epoch 253/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8933 - val_loss: 16.5206 - lr: 1.0000e-05\n",
      "Epoch 254/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8929 - val_loss: 16.5252 - lr: 1.0000e-05\n",
      "Epoch 255/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8918 - val_loss: 16.5223 - lr: 1.0000e-05\n",
      "Epoch 256/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8917 - val_loss: 16.5241 - lr: 1.0000e-05\n",
      "Epoch 257/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8914 - val_loss: 16.5272 - lr: 1.0000e-05\n",
      "Epoch 258/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.8908 - val_loss: 16.5261 - lr: 1.0000e-05\n",
      "Epoch 259/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8903 - val_loss: 16.5282 - lr: 1.0000e-05\n",
      "Epoch 260/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8896 - val_loss: 16.5253 - lr: 1.0000e-05\n",
      "Epoch 261/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8892 - val_loss: 16.5253 - lr: 1.0000e-05\n",
      "Epoch 262/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8886 - val_loss: 16.5230 - lr: 1.0000e-05\n",
      "Epoch 263/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.8880 - val_loss: 16.5219 - lr: 1.0000e-05\n",
      "Epoch 264/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8875 - val_loss: 16.5228 - lr: 1.0000e-05\n",
      "Epoch 265/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8873 - val_loss: 16.5204 - lr: 1.0000e-05\n",
      "Epoch 266/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8867 - val_loss: 16.5200 - lr: 1.0000e-05\n",
      "Epoch 267/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8860 - val_loss: 16.5189 - lr: 1.0000e-05\n",
      "Epoch 268/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8858 - val_loss: 16.5180 - lr: 1.0000e-05\n",
      "Epoch 269/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8855 - val_loss: 16.5191 - lr: 1.0000e-05\n",
      "Epoch 270/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8848 - val_loss: 16.5178 - lr: 1.0000e-05\n",
      "Epoch 271/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8840 - val_loss: 16.5157 - lr: 1.0000e-05\n",
      "Epoch 272/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8844 - val_loss: 16.5111 - lr: 1.0000e-05\n",
      "Epoch 273/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8832 - val_loss: 16.5155 - lr: 1.0000e-05\n",
      "Epoch 274/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8827 - val_loss: 16.5184 - lr: 1.0000e-05\n",
      "Epoch 275/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.8820 - val_loss: 16.5180 - lr: 1.0000e-05\n",
      "Epoch 276/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8821 - val_loss: 16.5172 - lr: 1.0000e-05\n",
      "Epoch 277/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8818 - val_loss: 16.5192 - lr: 1.0000e-05\n",
      "Epoch 278/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8806 - val_loss: 16.5145 - lr: 1.0000e-05\n",
      "Epoch 279/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8810 - val_loss: 16.5124 - lr: 1.0000e-05\n",
      "Epoch 280/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8801 - val_loss: 16.5126 - lr: 1.0000e-05\n",
      "Epoch 281/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8798 - val_loss: 16.5105 - lr: 1.0000e-05\n",
      "Epoch 282/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.8792 - val_loss: 16.5114 - lr: 1.0000e-05\n",
      "Epoch 283/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8790 - val_loss: 16.5112 - lr: 1.0000e-05\n",
      "Epoch 284/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8783 - val_loss: 16.5082 - lr: 1.0000e-05\n",
      "Epoch 285/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8777 - val_loss: 16.5086 - lr: 1.0000e-05\n",
      "Epoch 286/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8772 - val_loss: 16.5095 - lr: 1.0000e-05\n",
      "Epoch 287/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8771 - val_loss: 16.5072 - lr: 1.0000e-05\n",
      "Epoch 288/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8760 - val_loss: 16.5095 - lr: 1.0000e-05\n",
      "Epoch 289/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8758 - val_loss: 16.5111 - lr: 1.0000e-05\n",
      "Epoch 290/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8758 - val_loss: 16.5085 - lr: 1.0000e-05\n",
      "Epoch 291/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8748 - val_loss: 16.5099 - lr: 1.0000e-05\n",
      "Epoch 292/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8740 - val_loss: 16.5129 - lr: 1.0000e-05\n",
      "Epoch 293/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8743 - val_loss: 16.5157 - lr: 1.0000e-05\n",
      "Epoch 294/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8740 - val_loss: 16.5170 - lr: 1.0000e-05\n",
      "Epoch 295/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8735 - val_loss: 16.5151 - lr: 1.0000e-05\n",
      "Epoch 296/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8728 - val_loss: 16.5151 - lr: 1.0000e-05\n",
      "Epoch 297/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8726 - val_loss: 16.5092 - lr: 1.0000e-05\n",
      "Epoch 298/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8720 - val_loss: 16.5071 - lr: 1.0000e-05\n",
      "Epoch 299/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8717 - val_loss: 16.5085 - lr: 1.0000e-05\n",
      "Epoch 300/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8707 - val_loss: 16.5129 - lr: 1.0000e-05\n",
      "138/138 [==============================] - 0s 2ms/step\n",
      "Epoch 1/300\n",
      "31/31 [==============================] - 1s 11ms/step - loss: 739.7133 - val_loss: 691.0968 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 625.4376 - val_loss: 562.1004 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 491.1253 - val_loss: 426.9641 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 365.5101 - val_loss: 310.9160 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 260.2293 - val_loss: 217.3470 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 180.7038 - val_loss: 151.8342 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 128.7312 - val_loss: 112.8968 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 100.8788 - val_loss: 94.7518 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 89.1683 - val_loss: 87.4222 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 83.6937 - val_loss: 82.4013 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 78.1333 - val_loss: 76.0204 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 71.3645 - val_loss: 69.0247 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 64.3647 - val_loss: 61.8175 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 57.4002 - val_loss: 54.9579 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 51.4666 - val_loss: 49.6409 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 47.2281 - val_loss: 45.8566 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 44.0859 - val_loss: 42.9953 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 41.7394 - val_loss: 40.8699 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 39.9928 - val_loss: 39.3240 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 38.5879 - val_loss: 38.0671 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 37.4658 - val_loss: 36.9964 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 36.5084 - val_loss: 36.1829 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 35.6809 - val_loss: 35.2603 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 34.8375 - val_loss: 34.5156 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 34.0057 - val_loss: 33.6346 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 33.2090 - val_loss: 32.8398 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 32.3897 - val_loss: 32.0425 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 31.6375 - val_loss: 31.4083 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 30.8437 - val_loss: 30.6311 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 30.1530 - val_loss: 30.0130 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 29.5350 - val_loss: 29.3970 - lr: 0.0010\n",
      "Epoch 32/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 28.8952 - val_loss: 28.8214 - lr: 0.0010\n",
      "Epoch 33/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 28.3815 - val_loss: 28.3535 - lr: 0.0010\n",
      "Epoch 34/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 27.8682 - val_loss: 27.8840 - lr: 0.0010\n",
      "Epoch 35/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 27.3146 - val_loss: 27.4164 - lr: 0.0010\n",
      "Epoch 36/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.8843 - val_loss: 26.9228 - lr: 0.0010\n",
      "Epoch 37/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.4548 - val_loss: 26.5704 - lr: 0.0010\n",
      "Epoch 38/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.0793 - val_loss: 26.2605 - lr: 0.0010\n",
      "Epoch 39/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.7963 - val_loss: 25.9362 - lr: 0.0010\n",
      "Epoch 40/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 25.5414 - val_loss: 25.8019 - lr: 0.0010\n",
      "Epoch 41/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.2808 - val_loss: 25.5810 - lr: 0.0010\n",
      "Epoch 42/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.0463 - val_loss: 25.3857 - lr: 0.0010\n",
      "Epoch 43/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.8737 - val_loss: 25.2322 - lr: 0.0010\n",
      "Epoch 44/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 24.7336 - val_loss: 25.0137 - lr: 0.0010\n",
      "Epoch 45/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 24.4945 - val_loss: 24.8184 - lr: 0.0010\n",
      "Epoch 46/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.3012 - val_loss: 24.6277 - lr: 0.0010\n",
      "Epoch 47/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.0965 - val_loss: 24.4845 - lr: 0.0010\n",
      "Epoch 48/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.9399 - val_loss: 24.3733 - lr: 0.0010\n",
      "Epoch 49/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.8023 - val_loss: 24.1604 - lr: 0.0010\n",
      "Epoch 50/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.6392 - val_loss: 23.9922 - lr: 0.0010\n",
      "Epoch 51/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.4174 - val_loss: 23.8964 - lr: 0.0010\n",
      "Epoch 52/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.3145 - val_loss: 23.7386 - lr: 0.0010\n",
      "Epoch 53/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.1336 - val_loss: 23.6710 - lr: 0.0010\n",
      "Epoch 54/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.9790 - val_loss: 23.4180 - lr: 0.0010\n",
      "Epoch 55/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.8176 - val_loss: 23.2943 - lr: 0.0010\n",
      "Epoch 56/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.6567 - val_loss: 23.0907 - lr: 0.0010\n",
      "Epoch 57/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.4230 - val_loss: 22.8908 - lr: 0.0010\n",
      "Epoch 58/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.2857 - val_loss: 22.7339 - lr: 0.0010\n",
      "Epoch 59/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.0802 - val_loss: 22.5737 - lr: 0.0010\n",
      "Epoch 60/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.9693 - val_loss: 22.4599 - lr: 0.0010\n",
      "Epoch 61/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.8174 - val_loss: 22.3089 - lr: 0.0010\n",
      "Epoch 62/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 21.6349 - val_loss: 22.1612 - lr: 0.0010\n",
      "Epoch 63/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 21.5258 - val_loss: 22.0581 - lr: 0.0010\n",
      "Epoch 64/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.3552 - val_loss: 21.8847 - lr: 0.0010\n",
      "Epoch 65/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.2566 - val_loss: 21.8084 - lr: 0.0010\n",
      "Epoch 66/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.1103 - val_loss: 21.5719 - lr: 0.0010\n",
      "Epoch 67/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 20.9547 - val_loss: 21.4451 - lr: 0.0010\n",
      "Epoch 68/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 20.7948 - val_loss: 21.3248 - lr: 0.0010\n",
      "Epoch 69/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.6781 - val_loss: 21.2620 - lr: 0.0010\n",
      "Epoch 70/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.5994 - val_loss: 21.1002 - lr: 0.0010\n",
      "Epoch 71/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 20.4329 - val_loss: 21.0213 - lr: 0.0010\n",
      "Epoch 72/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.3881 - val_loss: 20.9402 - lr: 0.0010\n",
      "Epoch 73/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.2382 - val_loss: 20.8379 - lr: 0.0010\n",
      "Epoch 74/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.1266 - val_loss: 20.7182 - lr: 0.0010\n",
      "Epoch 75/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.0318 - val_loss: 20.6125 - lr: 0.0010\n",
      "Epoch 76/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.9494 - val_loss: 20.5031 - lr: 0.0010\n",
      "Epoch 77/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.8146 - val_loss: 20.4173 - lr: 0.0010\n",
      "Epoch 78/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.7361 - val_loss: 20.3291 - lr: 0.0010\n",
      "Epoch 79/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.6342 - val_loss: 20.1970 - lr: 0.0010\n",
      "Epoch 80/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.5242 - val_loss: 20.1567 - lr: 0.0010\n",
      "Epoch 81/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.4223 - val_loss: 20.0293 - lr: 0.0010\n",
      "Epoch 82/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.3352 - val_loss: 19.9413 - lr: 0.0010\n",
      "Epoch 83/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.2310 - val_loss: 19.8226 - lr: 0.0010\n",
      "Epoch 84/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 19.1226 - val_loss: 19.7706 - lr: 0.0010\n",
      "Epoch 85/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.0281 - val_loss: 19.6498 - lr: 0.0010\n",
      "Epoch 86/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.9674 - val_loss: 19.6390 - lr: 0.0010\n",
      "Epoch 87/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.9084 - val_loss: 19.5123 - lr: 0.0010\n",
      "Epoch 88/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 18.8367 - val_loss: 19.5343 - lr: 0.0010\n",
      "Epoch 89/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.7642 - val_loss: 19.4430 - lr: 0.0010\n",
      "Epoch 90/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.6068 - val_loss: 19.3996 - lr: 0.0010\n",
      "Epoch 91/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.5643 - val_loss: 19.3151 - lr: 0.0010\n",
      "Epoch 92/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.4420 - val_loss: 19.1720 - lr: 0.0010\n",
      "Epoch 93/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.4219 - val_loss: 19.1929 - lr: 0.0010\n",
      "Epoch 94/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 18.3666 - val_loss: 19.0834 - lr: 0.0010\n",
      "Epoch 95/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.2291 - val_loss: 18.9977 - lr: 0.0010\n",
      "Epoch 96/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.1940 - val_loss: 18.9114 - lr: 0.0010\n",
      "Epoch 97/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.0555 - val_loss: 18.7652 - lr: 0.0010\n",
      "Epoch 98/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.0008 - val_loss: 18.7792 - lr: 0.0010\n",
      "Epoch 99/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 17.9155 - val_loss: 18.6710 - lr: 0.0010\n",
      "Epoch 100/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 17.8577 - val_loss: 18.5889 - lr: 0.0010\n",
      "Epoch 101/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.7656 - val_loss: 18.5828 - lr: 0.0010\n",
      "Epoch 102/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.7339 - val_loss: 18.5418 - lr: 0.0010\n",
      "Epoch 103/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.6383 - val_loss: 18.4948 - lr: 0.0010\n",
      "Epoch 104/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.5708 - val_loss: 18.3437 - lr: 0.0010\n",
      "Epoch 105/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.4618 - val_loss: 18.3282 - lr: 0.0010\n",
      "Epoch 106/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.3699 - val_loss: 18.2261 - lr: 0.0010\n",
      "Epoch 107/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.3141 - val_loss: 18.2311 - lr: 0.0010\n",
      "Epoch 108/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.2342 - val_loss: 18.1863 - lr: 0.0010\n",
      "Epoch 109/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.1633 - val_loss: 18.0713 - lr: 0.0010\n",
      "Epoch 110/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 17.1451 - val_loss: 18.0905 - lr: 0.0010\n",
      "Epoch 111/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.0220 - val_loss: 17.9558 - lr: 0.0010\n",
      "Epoch 112/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.9986 - val_loss: 18.0053 - lr: 0.0010\n",
      "Epoch 113/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.8910 - val_loss: 17.8655 - lr: 0.0010\n",
      "Epoch 114/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.8057 - val_loss: 17.9082 - lr: 0.0010\n",
      "Epoch 115/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.9243 - val_loss: 17.7813 - lr: 0.0010\n",
      "Epoch 116/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.6934 - val_loss: 17.7530 - lr: 0.0010\n",
      "Epoch 117/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.6636 - val_loss: 17.6520 - lr: 0.0010\n",
      "Epoch 118/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.5992 - val_loss: 17.7938 - lr: 0.0010\n",
      "Epoch 119/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.5178 - val_loss: 17.6450 - lr: 0.0010\n",
      "Epoch 120/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 16.4957 - val_loss: 17.6101 - lr: 0.0010\n",
      "Epoch 121/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4749 - val_loss: 17.5588 - lr: 0.0010\n",
      "Epoch 122/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3889 - val_loss: 17.4804 - lr: 0.0010\n",
      "Epoch 123/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3251 - val_loss: 17.5108 - lr: 0.0010\n",
      "Epoch 124/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.2776 - val_loss: 17.4016 - lr: 0.0010\n",
      "Epoch 125/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.2558 - val_loss: 17.3758 - lr: 0.0010\n",
      "Epoch 126/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.1832 - val_loss: 17.4421 - lr: 0.0010\n",
      "Epoch 127/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.1356 - val_loss: 17.2857 - lr: 0.0010\n",
      "Epoch 128/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.0645 - val_loss: 17.2616 - lr: 0.0010\n",
      "Epoch 129/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.0469 - val_loss: 17.2733 - lr: 0.0010\n",
      "Epoch 130/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.0187 - val_loss: 17.1660 - lr: 0.0010\n",
      "Epoch 131/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9235 - val_loss: 17.1397 - lr: 0.0010\n",
      "Epoch 132/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8957 - val_loss: 17.1725 - lr: 0.0010\n",
      "Epoch 133/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8777 - val_loss: 17.1127 - lr: 0.0010\n",
      "Epoch 134/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7838 - val_loss: 17.0338 - lr: 0.0010\n",
      "Epoch 135/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7497 - val_loss: 17.0904 - lr: 0.0010\n",
      "Epoch 136/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7138 - val_loss: 16.9985 - lr: 0.0010\n",
      "Epoch 137/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6708 - val_loss: 16.9552 - lr: 0.0010\n",
      "Epoch 138/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6473 - val_loss: 16.9374 - lr: 0.0010\n",
      "Epoch 139/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6037 - val_loss: 16.8930 - lr: 0.0010\n",
      "Epoch 140/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.5515 - val_loss: 16.8958 - lr: 0.0010\n",
      "Epoch 141/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.5675 - val_loss: 16.8866 - lr: 0.0010\n",
      "Epoch 142/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.4673 - val_loss: 16.8642 - lr: 0.0010\n",
      "Epoch 143/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.4301 - val_loss: 16.8055 - lr: 0.0010\n",
      "Epoch 144/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.3834 - val_loss: 16.8248 - lr: 0.0010\n",
      "Epoch 145/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.4019 - val_loss: 16.7648 - lr: 0.0010\n",
      "Epoch 146/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.3672 - val_loss: 16.6948 - lr: 0.0010\n",
      "Epoch 147/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2948 - val_loss: 16.6461 - lr: 0.0010\n",
      "Epoch 148/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2623 - val_loss: 16.6624 - lr: 0.0010\n",
      "Epoch 149/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2506 - val_loss: 16.6543 - lr: 0.0010\n",
      "Epoch 150/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2753 - val_loss: 16.6433 - lr: 0.0010\n",
      "Epoch 151/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1865 - val_loss: 16.4768 - lr: 0.0010\n",
      "Epoch 152/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.1173 - val_loss: 16.5262 - lr: 0.0010\n",
      "Epoch 153/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1349 - val_loss: 16.5744 - lr: 0.0010\n",
      "Epoch 154/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.0941 - val_loss: 16.5851 - lr: 0.0010\n",
      "Epoch 155/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.9522 - val_loss: 16.4772 - lr: 1.0000e-04\n",
      "Epoch 156/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.9062 - val_loss: 16.4691 - lr: 1.0000e-04\n",
      "Epoch 157/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8991 - val_loss: 16.4691 - lr: 1.0000e-04\n",
      "Epoch 158/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8887 - val_loss: 16.4576 - lr: 1.0000e-04\n",
      "Epoch 159/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8859 - val_loss: 16.4501 - lr: 1.0000e-04\n",
      "Epoch 160/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8790 - val_loss: 16.4470 - lr: 1.0000e-04\n",
      "Epoch 161/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8766 - val_loss: 16.4326 - lr: 1.0000e-04\n",
      "Epoch 162/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8729 - val_loss: 16.4318 - lr: 1.0000e-04\n",
      "Epoch 163/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8685 - val_loss: 16.4301 - lr: 1.0000e-04\n",
      "Epoch 164/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8671 - val_loss: 16.4269 - lr: 1.0000e-04\n",
      "Epoch 165/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8639 - val_loss: 16.4292 - lr: 1.0000e-04\n",
      "Epoch 166/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8554 - val_loss: 16.4139 - lr: 1.0000e-04\n",
      "Epoch 167/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8510 - val_loss: 16.4119 - lr: 1.0000e-04\n",
      "Epoch 168/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8462 - val_loss: 16.4147 - lr: 1.0000e-04\n",
      "Epoch 169/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8519 - val_loss: 16.4161 - lr: 1.0000e-04\n",
      "Epoch 170/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8397 - val_loss: 16.4159 - lr: 1.0000e-04\n",
      "Epoch 171/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.8251 - val_loss: 16.4161 - lr: 1.0000e-05\n",
      "Epoch 172/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8244 - val_loss: 16.4161 - lr: 1.0000e-05\n",
      "Epoch 173/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.8240 - val_loss: 16.4162 - lr: 1.0000e-05\n",
      "Epoch 174/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8236 - val_loss: 16.4153 - lr: 1.0000e-05\n",
      "Epoch 175/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8228 - val_loss: 16.4117 - lr: 1.0000e-05\n",
      "Epoch 176/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.8222 - val_loss: 16.4124 - lr: 1.0000e-05\n",
      "Epoch 177/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8218 - val_loss: 16.4094 - lr: 1.0000e-05\n",
      "Epoch 178/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8213 - val_loss: 16.4086 - lr: 1.0000e-05\n",
      "Epoch 179/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8211 - val_loss: 16.4096 - lr: 1.0000e-05\n",
      "Epoch 180/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8202 - val_loss: 16.4057 - lr: 1.0000e-05\n",
      "Epoch 181/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8198 - val_loss: 16.4068 - lr: 1.0000e-05\n",
      "Epoch 182/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.8195 - val_loss: 16.4082 - lr: 1.0000e-05\n",
      "Epoch 183/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8188 - val_loss: 16.4041 - lr: 1.0000e-05\n",
      "Epoch 184/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.8187 - val_loss: 16.4016 - lr: 1.0000e-05\n",
      "Epoch 185/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8183 - val_loss: 16.4024 - lr: 1.0000e-05\n",
      "Epoch 186/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8180 - val_loss: 16.4073 - lr: 1.0000e-05\n",
      "Epoch 187/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8174 - val_loss: 16.4079 - lr: 1.0000e-05\n",
      "Epoch 188/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8170 - val_loss: 16.4072 - lr: 1.0000e-05\n",
      "Epoch 189/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8168 - val_loss: 16.4064 - lr: 1.0000e-05\n",
      "Epoch 190/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8158 - val_loss: 16.4060 - lr: 1.0000e-05\n",
      "Epoch 191/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8159 - val_loss: 16.4065 - lr: 1.0000e-05\n",
      "Epoch 192/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8157 - val_loss: 16.4031 - lr: 1.0000e-05\n",
      "Epoch 193/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8149 - val_loss: 16.4035 - lr: 1.0000e-05\n",
      "Epoch 194/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8142 - val_loss: 16.4032 - lr: 1.0000e-05\n",
      "Epoch 195/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8137 - val_loss: 16.4050 - lr: 1.0000e-05\n",
      "Epoch 196/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8134 - val_loss: 16.4033 - lr: 1.0000e-05\n",
      "Epoch 197/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.8129 - val_loss: 16.4050 - lr: 1.0000e-05\n",
      "Epoch 198/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8127 - val_loss: 16.4080 - lr: 1.0000e-05\n",
      "Epoch 199/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8125 - val_loss: 16.4076 - lr: 1.0000e-05\n",
      "Epoch 200/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8117 - val_loss: 16.4044 - lr: 1.0000e-05\n",
      "Epoch 201/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8114 - val_loss: 16.4026 - lr: 1.0000e-05\n",
      "Epoch 202/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8109 - val_loss: 16.4015 - lr: 1.0000e-05\n",
      "Epoch 203/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8106 - val_loss: 16.4033 - lr: 1.0000e-05\n",
      "Epoch 204/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8102 - val_loss: 16.4046 - lr: 1.0000e-05\n",
      "Epoch 205/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8099 - val_loss: 16.4041 - lr: 1.0000e-05\n",
      "Epoch 206/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8095 - val_loss: 16.4055 - lr: 1.0000e-05\n",
      "Epoch 207/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.8089 - val_loss: 16.4032 - lr: 1.0000e-05\n",
      "Epoch 208/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.8083 - val_loss: 16.3983 - lr: 1.0000e-05\n",
      "Epoch 209/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.8084 - val_loss: 16.3971 - lr: 1.0000e-05\n",
      "Epoch 210/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8078 - val_loss: 16.3991 - lr: 1.0000e-05\n",
      "Epoch 211/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8073 - val_loss: 16.3967 - lr: 1.0000e-05\n",
      "Epoch 212/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8071 - val_loss: 16.3961 - lr: 1.0000e-05\n",
      "Epoch 213/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8073 - val_loss: 16.3986 - lr: 1.0000e-05\n",
      "Epoch 214/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8060 - val_loss: 16.3970 - lr: 1.0000e-05\n",
      "Epoch 215/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.8059 - val_loss: 16.3954 - lr: 1.0000e-05\n",
      "Epoch 216/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8054 - val_loss: 16.3955 - lr: 1.0000e-05\n",
      "Epoch 217/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8050 - val_loss: 16.3965 - lr: 1.0000e-05\n",
      "Epoch 218/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.8054 - val_loss: 16.3988 - lr: 1.0000e-05\n",
      "Epoch 219/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8044 - val_loss: 16.3958 - lr: 1.0000e-05\n",
      "Epoch 220/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8043 - val_loss: 16.3935 - lr: 1.0000e-05\n",
      "Epoch 221/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8037 - val_loss: 16.3942 - lr: 1.0000e-05\n",
      "Epoch 222/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8032 - val_loss: 16.3934 - lr: 1.0000e-05\n",
      "Epoch 223/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.8030 - val_loss: 16.3936 - lr: 1.0000e-05\n",
      "Epoch 224/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8022 - val_loss: 16.3921 - lr: 1.0000e-05\n",
      "Epoch 225/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.8021 - val_loss: 16.3899 - lr: 1.0000e-05\n",
      "Epoch 226/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8018 - val_loss: 16.3915 - lr: 1.0000e-05\n",
      "Epoch 227/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8015 - val_loss: 16.3907 - lr: 1.0000e-05\n",
      "Epoch 228/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8007 - val_loss: 16.3911 - lr: 1.0000e-05\n",
      "Epoch 229/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8003 - val_loss: 16.3915 - lr: 1.0000e-05\n",
      "Epoch 230/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7999 - val_loss: 16.3918 - lr: 1.0000e-05\n",
      "Epoch 231/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7996 - val_loss: 16.3902 - lr: 1.0000e-05\n",
      "Epoch 232/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7995 - val_loss: 16.3917 - lr: 1.0000e-05\n",
      "Epoch 233/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7989 - val_loss: 16.3912 - lr: 1.0000e-05\n",
      "Epoch 234/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7981 - val_loss: 16.3904 - lr: 1.0000e-05\n",
      "Epoch 235/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7982 - val_loss: 16.3903 - lr: 1.0000e-05\n",
      "Epoch 236/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7974 - val_loss: 16.3888 - lr: 1.0000e-05\n",
      "Epoch 237/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.7971 - val_loss: 16.3885 - lr: 1.0000e-05\n",
      "Epoch 238/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7967 - val_loss: 16.3875 - lr: 1.0000e-05\n",
      "Epoch 239/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7966 - val_loss: 16.3884 - lr: 1.0000e-05\n",
      "Epoch 240/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7961 - val_loss: 16.3895 - lr: 1.0000e-05\n",
      "Epoch 241/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7957 - val_loss: 16.3916 - lr: 1.0000e-05\n",
      "Epoch 242/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7953 - val_loss: 16.3914 - lr: 1.0000e-05\n",
      "Epoch 243/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.7954 - val_loss: 16.3933 - lr: 1.0000e-05\n",
      "Epoch 244/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.7949 - val_loss: 16.3893 - lr: 1.0000e-05\n",
      "Epoch 245/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7941 - val_loss: 16.3873 - lr: 1.0000e-05\n",
      "Epoch 246/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7938 - val_loss: 16.3852 - lr: 1.0000e-05\n",
      "Epoch 247/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7939 - val_loss: 16.3830 - lr: 1.0000e-05\n",
      "Epoch 248/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7940 - val_loss: 16.3872 - lr: 1.0000e-05\n",
      "Epoch 249/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7927 - val_loss: 16.3834 - lr: 1.0000e-05\n",
      "Epoch 250/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7922 - val_loss: 16.3817 - lr: 1.0000e-05\n",
      "Epoch 251/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7919 - val_loss: 16.3818 - lr: 1.0000e-05\n",
      "Epoch 252/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7916 - val_loss: 16.3840 - lr: 1.0000e-05\n",
      "Epoch 253/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7910 - val_loss: 16.3828 - lr: 1.0000e-05\n",
      "Epoch 254/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7904 - val_loss: 16.3855 - lr: 1.0000e-05\n",
      "Epoch 255/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7902 - val_loss: 16.3865 - lr: 1.0000e-05\n",
      "Epoch 256/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7899 - val_loss: 16.3881 - lr: 1.0000e-05\n",
      "Epoch 257/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7894 - val_loss: 16.3862 - lr: 1.0000e-05\n",
      "Epoch 258/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.7890 - val_loss: 16.3861 - lr: 1.0000e-05\n",
      "Epoch 259/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.7889 - val_loss: 16.3856 - lr: 1.0000e-05\n",
      "Epoch 260/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7885 - val_loss: 16.3878 - lr: 1.0000e-05\n",
      "Epoch 261/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.7879 - val_loss: 16.3872 - lr: 1.0000e-05\n",
      "Epoch 262/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.7874 - val_loss: 16.3852 - lr: 1.0000e-05\n",
      "Epoch 263/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7873 - val_loss: 16.3837 - lr: 1.0000e-05\n",
      "Epoch 264/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.7873 - val_loss: 16.3803 - lr: 1.0000e-05\n",
      "Epoch 265/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7876 - val_loss: 16.3818 - lr: 1.0000e-05\n",
      "Epoch 266/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7862 - val_loss: 16.3816 - lr: 1.0000e-05\n",
      "Epoch 267/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7863 - val_loss: 16.3811 - lr: 1.0000e-05\n",
      "Epoch 268/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7855 - val_loss: 16.3818 - lr: 1.0000e-05\n",
      "Epoch 269/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7853 - val_loss: 16.3803 - lr: 1.0000e-05\n",
      "Epoch 270/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.7849 - val_loss: 16.3795 - lr: 1.0000e-05\n",
      "Epoch 271/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.7841 - val_loss: 16.3795 - lr: 1.0000e-05\n",
      "Epoch 272/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7841 - val_loss: 16.3789 - lr: 1.0000e-05\n",
      "Epoch 273/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.7835 - val_loss: 16.3775 - lr: 1.0000e-05\n",
      "Epoch 274/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7833 - val_loss: 16.3802 - lr: 1.0000e-05\n",
      "Epoch 275/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7826 - val_loss: 16.3810 - lr: 1.0000e-05\n",
      "Epoch 276/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7822 - val_loss: 16.3792 - lr: 1.0000e-05\n",
      "Epoch 277/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7817 - val_loss: 16.3768 - lr: 1.0000e-05\n",
      "Epoch 278/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7814 - val_loss: 16.3770 - lr: 1.0000e-05\n",
      "Epoch 279/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7811 - val_loss: 16.3778 - lr: 1.0000e-05\n",
      "Epoch 280/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7802 - val_loss: 16.3803 - lr: 1.0000e-05\n",
      "Epoch 281/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7803 - val_loss: 16.3777 - lr: 1.0000e-05\n",
      "Epoch 282/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7803 - val_loss: 16.3782 - lr: 1.0000e-05\n",
      "Epoch 283/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7798 - val_loss: 16.3769 - lr: 1.0000e-05\n",
      "Epoch 284/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7794 - val_loss: 16.3791 - lr: 1.0000e-05\n",
      "Epoch 285/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7786 - val_loss: 16.3815 - lr: 1.0000e-05\n",
      "Epoch 286/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7784 - val_loss: 16.3798 - lr: 1.0000e-05\n",
      "Epoch 287/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7781 - val_loss: 16.3791 - lr: 1.0000e-05\n",
      "Epoch 288/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.7776 - val_loss: 16.3792 - lr: 1.0000e-05\n",
      "Epoch 289/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7774 - val_loss: 16.3775 - lr: 1.0000e-05\n",
      "Epoch 290/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7770 - val_loss: 16.3738 - lr: 1.0000e-05\n",
      "Epoch 291/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7766 - val_loss: 16.3728 - lr: 1.0000e-05\n",
      "Epoch 292/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7762 - val_loss: 16.3740 - lr: 1.0000e-05\n",
      "Epoch 293/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.7758 - val_loss: 16.3761 - lr: 1.0000e-05\n",
      "Epoch 294/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7752 - val_loss: 16.3751 - lr: 1.0000e-05\n",
      "Epoch 295/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7750 - val_loss: 16.3729 - lr: 1.0000e-05\n",
      "Epoch 296/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7744 - val_loss: 16.3725 - lr: 1.0000e-05\n",
      "Epoch 297/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7742 - val_loss: 16.3702 - lr: 1.0000e-05\n",
      "Epoch 298/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7744 - val_loss: 16.3710 - lr: 1.0000e-05\n",
      "Epoch 299/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7736 - val_loss: 16.3687 - lr: 1.0000e-05\n",
      "Epoch 300/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7733 - val_loss: 16.3675 - lr: 1.0000e-05\n",
      "138/138 [==============================] - 0s 1ms/step\n",
      "Epoch 1/300\n",
      "31/31 [==============================] - 1s 9ms/step - loss: 696.4787 - val_loss: 613.0561 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 542.0157 - val_loss: 440.1054 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 366.6500 - val_loss: 274.2626 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 219.1670 - val_loss: 155.9477 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 127.7502 - val_loss: 97.6776 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 90.5966 - val_loss: 80.7926 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 80.0247 - val_loss: 74.2888 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 73.0089 - val_loss: 66.8958 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 65.2816 - val_loss: 59.2187 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 56.9455 - val_loss: 51.2780 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 49.1981 - val_loss: 45.2674 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 43.8894 - val_loss: 41.6253 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 40.6791 - val_loss: 39.3833 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 38.6262 - val_loss: 37.8012 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 37.1270 - val_loss: 36.5793 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 35.8903 - val_loss: 35.5269 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 34.8686 - val_loss: 34.5966 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 33.9512 - val_loss: 33.8104 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 33.1399 - val_loss: 33.1149 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 32.3987 - val_loss: 32.3954 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 31.7181 - val_loss: 31.7248 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 31.0801 - val_loss: 31.1171 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 30.5431 - val_loss: 30.6035 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 30.0204 - val_loss: 30.1927 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 29.5619 - val_loss: 29.7495 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 29.1397 - val_loss: 29.3932 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 28.7541 - val_loss: 29.0079 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 28.3793 - val_loss: 28.6798 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 28.0439 - val_loss: 28.3730 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 27.7329 - val_loss: 28.1212 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 27.4160 - val_loss: 27.8430 - lr: 0.0010\n",
      "Epoch 32/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 27.1527 - val_loss: 27.5256 - lr: 0.0010\n",
      "Epoch 33/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.8825 - val_loss: 27.2850 - lr: 0.0010\n",
      "Epoch 34/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.6518 - val_loss: 27.1364 - lr: 0.0010\n",
      "Epoch 35/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.3771 - val_loss: 26.9106 - lr: 0.0010\n",
      "Epoch 36/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.1409 - val_loss: 26.6260 - lr: 0.0010\n",
      "Epoch 37/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.9064 - val_loss: 26.4173 - lr: 0.0010\n",
      "Epoch 38/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.6767 - val_loss: 26.2920 - lr: 0.0010\n",
      "Epoch 39/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.4768 - val_loss: 26.0684 - lr: 0.0010\n",
      "Epoch 40/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.2916 - val_loss: 25.8847 - lr: 0.0010\n",
      "Epoch 41/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 25.1825 - val_loss: 25.7875 - lr: 0.0010\n",
      "Epoch 42/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.9364 - val_loss: 25.6230 - lr: 0.0010\n",
      "Epoch 43/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.8150 - val_loss: 25.5290 - lr: 0.0010\n",
      "Epoch 44/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.5890 - val_loss: 25.2977 - lr: 0.0010\n",
      "Epoch 45/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.4102 - val_loss: 25.2310 - lr: 0.0010\n",
      "Epoch 46/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.2255 - val_loss: 24.9962 - lr: 0.0010\n",
      "Epoch 47/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.0717 - val_loss: 24.9020 - lr: 0.0010\n",
      "Epoch 48/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.9600 - val_loss: 24.7316 - lr: 0.0010\n",
      "Epoch 49/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 23.7797 - val_loss: 24.6292 - lr: 0.0010\n",
      "Epoch 50/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.6175 - val_loss: 24.4789 - lr: 0.0010\n",
      "Epoch 51/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.4717 - val_loss: 24.3689 - lr: 0.0010\n",
      "Epoch 52/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.3456 - val_loss: 24.2653 - lr: 0.0010\n",
      "Epoch 53/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.2381 - val_loss: 24.1043 - lr: 0.0010\n",
      "Epoch 54/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.0523 - val_loss: 23.9844 - lr: 0.0010\n",
      "Epoch 55/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 22.9828 - val_loss: 23.9046 - lr: 0.0010\n",
      "Epoch 56/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 22.8143 - val_loss: 23.7403 - lr: 0.0010\n",
      "Epoch 57/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.6383 - val_loss: 23.5924 - lr: 0.0010\n",
      "Epoch 58/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.5167 - val_loss: 23.4910 - lr: 0.0010\n",
      "Epoch 59/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.3371 - val_loss: 23.3175 - lr: 0.0010\n",
      "Epoch 60/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.2302 - val_loss: 23.1978 - lr: 0.0010\n",
      "Epoch 61/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 22.0916 - val_loss: 22.9823 - lr: 0.0010\n",
      "Epoch 62/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 21.9731 - val_loss: 22.8795 - lr: 0.0010\n",
      "Epoch 63/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.8180 - val_loss: 22.8084 - lr: 0.0010\n",
      "Epoch 64/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.7043 - val_loss: 22.6743 - lr: 0.0010\n",
      "Epoch 65/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.5721 - val_loss: 22.4512 - lr: 0.0010\n",
      "Epoch 66/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.4558 - val_loss: 22.3455 - lr: 0.0010\n",
      "Epoch 67/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.2526 - val_loss: 22.1791 - lr: 0.0010\n",
      "Epoch 68/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.1933 - val_loss: 22.0322 - lr: 0.0010\n",
      "Epoch 69/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.0210 - val_loss: 21.8988 - lr: 0.0010\n",
      "Epoch 70/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.8688 - val_loss: 21.7616 - lr: 0.0010\n",
      "Epoch 71/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.7500 - val_loss: 21.6587 - lr: 0.0010\n",
      "Epoch 72/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 20.6603 - val_loss: 21.5174 - lr: 0.0010\n",
      "Epoch 73/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.5511 - val_loss: 21.4191 - lr: 0.0010\n",
      "Epoch 74/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 20.3909 - val_loss: 21.2518 - lr: 0.0010\n",
      "Epoch 75/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.2566 - val_loss: 21.1211 - lr: 0.0010\n",
      "Epoch 76/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.1793 - val_loss: 21.0926 - lr: 0.0010\n",
      "Epoch 77/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.0242 - val_loss: 20.9619 - lr: 0.0010\n",
      "Epoch 78/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.9378 - val_loss: 20.7885 - lr: 0.0010\n",
      "Epoch 79/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.8352 - val_loss: 20.6703 - lr: 0.0010\n",
      "Epoch 80/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.7064 - val_loss: 20.5277 - lr: 0.0010\n",
      "Epoch 81/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.6263 - val_loss: 20.4480 - lr: 0.0010\n",
      "Epoch 82/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.5562 - val_loss: 20.4074 - lr: 0.0010\n",
      "Epoch 83/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.5333 - val_loss: 20.2476 - lr: 0.0010\n",
      "Epoch 84/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.3282 - val_loss: 20.1662 - lr: 0.0010\n",
      "Epoch 85/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.2318 - val_loss: 20.0125 - lr: 0.0010\n",
      "Epoch 86/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.1761 - val_loss: 19.9301 - lr: 0.0010\n",
      "Epoch 87/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 19.0099 - val_loss: 19.8781 - lr: 0.0010\n",
      "Epoch 88/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.9000 - val_loss: 19.8037 - lr: 0.0010\n",
      "Epoch 89/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.8105 - val_loss: 19.6742 - lr: 0.0010\n",
      "Epoch 90/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.7295 - val_loss: 19.5601 - lr: 0.0010\n",
      "Epoch 91/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.6571 - val_loss: 19.5379 - lr: 0.0010\n",
      "Epoch 92/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.5883 - val_loss: 19.4733 - lr: 0.0010\n",
      "Epoch 93/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.5214 - val_loss: 19.4930 - lr: 0.0010\n",
      "Epoch 94/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.4430 - val_loss: 19.3289 - lr: 0.0010\n",
      "Epoch 95/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.3179 - val_loss: 19.2965 - lr: 0.0010\n",
      "Epoch 96/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.2666 - val_loss: 19.1032 - lr: 0.0010\n",
      "Epoch 97/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.1760 - val_loss: 19.1056 - lr: 0.0010\n",
      "Epoch 98/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.0927 - val_loss: 18.9542 - lr: 0.0010\n",
      "Epoch 99/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 18.0013 - val_loss: 18.9344 - lr: 0.0010\n",
      "Epoch 100/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.9529 - val_loss: 18.9063 - lr: 0.0010\n",
      "Epoch 101/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.8831 - val_loss: 18.8205 - lr: 0.0010\n",
      "Epoch 102/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.8088 - val_loss: 18.7517 - lr: 0.0010\n",
      "Epoch 103/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.7337 - val_loss: 18.7071 - lr: 0.0010\n",
      "Epoch 104/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.6636 - val_loss: 18.6226 - lr: 0.0010\n",
      "Epoch 105/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 17.5801 - val_loss: 18.5941 - lr: 0.0010\n",
      "Epoch 106/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.5144 - val_loss: 18.4839 - lr: 0.0010\n",
      "Epoch 107/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.5117 - val_loss: 18.5037 - lr: 0.0010\n",
      "Epoch 108/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.4450 - val_loss: 18.4873 - lr: 0.0010\n",
      "Epoch 109/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.3569 - val_loss: 18.3969 - lr: 0.0010\n",
      "Epoch 110/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.2495 - val_loss: 18.3405 - lr: 0.0010\n",
      "Epoch 111/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.2117 - val_loss: 18.2471 - lr: 0.0010\n",
      "Epoch 112/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.1586 - val_loss: 18.2313 - lr: 0.0010\n",
      "Epoch 113/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.0874 - val_loss: 18.1822 - lr: 0.0010\n",
      "Epoch 114/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.9916 - val_loss: 18.0821 - lr: 0.0010\n",
      "Epoch 115/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.9667 - val_loss: 18.0615 - lr: 0.0010\n",
      "Epoch 116/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.9788 - val_loss: 18.0286 - lr: 0.0010\n",
      "Epoch 117/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.8390 - val_loss: 17.9598 - lr: 0.0010\n",
      "Epoch 118/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.8002 - val_loss: 17.9373 - lr: 0.0010\n",
      "Epoch 119/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.7248 - val_loss: 17.8391 - lr: 0.0010\n",
      "Epoch 120/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.6472 - val_loss: 17.7994 - lr: 0.0010\n",
      "Epoch 121/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.6307 - val_loss: 17.7874 - lr: 0.0010\n",
      "Epoch 122/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.5591 - val_loss: 17.7519 - lr: 0.0010\n",
      "Epoch 123/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 16.5026 - val_loss: 17.6755 - lr: 0.0010\n",
      "Epoch 124/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4623 - val_loss: 17.6725 - lr: 0.0010\n",
      "Epoch 125/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4309 - val_loss: 17.7304 - lr: 0.0010\n",
      "Epoch 126/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4207 - val_loss: 17.5417 - lr: 0.0010\n",
      "Epoch 127/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3403 - val_loss: 17.5160 - lr: 0.0010\n",
      "Epoch 128/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3141 - val_loss: 17.4993 - lr: 0.0010\n",
      "Epoch 129/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.2294 - val_loss: 17.4584 - lr: 0.0010\n",
      "Epoch 130/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.2523 - val_loss: 17.4360 - lr: 0.0010\n",
      "Epoch 131/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.1881 - val_loss: 17.4563 - lr: 0.0010\n",
      "Epoch 132/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.1429 - val_loss: 17.3276 - lr: 0.0010\n",
      "Epoch 133/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.0575 - val_loss: 17.5448 - lr: 0.0010\n",
      "Epoch 134/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.1446 - val_loss: 17.3619 - lr: 0.0010\n",
      "Epoch 135/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.0195 - val_loss: 17.3600 - lr: 0.0010\n",
      "Epoch 136/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8967 - val_loss: 17.3038 - lr: 1.0000e-04\n",
      "Epoch 137/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8595 - val_loss: 17.2806 - lr: 1.0000e-04\n",
      "Epoch 138/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8447 - val_loss: 17.2721 - lr: 1.0000e-04\n",
      "Epoch 139/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.8378 - val_loss: 17.2702 - lr: 1.0000e-04\n",
      "Epoch 140/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.8313 - val_loss: 17.2662 - lr: 1.0000e-04\n",
      "Epoch 141/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8287 - val_loss: 17.2673 - lr: 1.0000e-04\n",
      "Epoch 142/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.8232 - val_loss: 17.2592 - lr: 1.0000e-04\n",
      "Epoch 143/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8170 - val_loss: 17.2464 - lr: 1.0000e-04\n",
      "Epoch 144/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8117 - val_loss: 17.2369 - lr: 1.0000e-04\n",
      "Epoch 145/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8044 - val_loss: 17.2253 - lr: 1.0000e-04\n",
      "Epoch 146/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8033 - val_loss: 17.2219 - lr: 1.0000e-04\n",
      "Epoch 147/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7998 - val_loss: 17.2158 - lr: 1.0000e-04\n",
      "Epoch 148/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7967 - val_loss: 17.2140 - lr: 1.0000e-04\n",
      "Epoch 149/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7862 - val_loss: 17.2173 - lr: 1.0000e-04\n",
      "Epoch 150/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7824 - val_loss: 17.2080 - lr: 1.0000e-04\n",
      "Epoch 151/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7763 - val_loss: 17.2029 - lr: 1.0000e-04\n",
      "Epoch 152/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7723 - val_loss: 17.2033 - lr: 1.0000e-04\n",
      "Epoch 153/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7708 - val_loss: 17.2123 - lr: 1.0000e-04\n",
      "Epoch 154/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7612 - val_loss: 17.2071 - lr: 1.0000e-04\n",
      "Epoch 155/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7499 - val_loss: 17.2076 - lr: 1.0000e-05\n",
      "Epoch 156/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7496 - val_loss: 17.2080 - lr: 1.0000e-05\n",
      "Epoch 157/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7488 - val_loss: 17.2077 - lr: 1.0000e-05\n",
      "Epoch 158/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7476 - val_loss: 17.2062 - lr: 1.0000e-05\n",
      "Epoch 159/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7478 - val_loss: 17.2058 - lr: 1.0000e-05\n",
      "Epoch 160/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7472 - val_loss: 17.2044 - lr: 1.0000e-05\n",
      "Epoch 161/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7467 - val_loss: 17.2048 - lr: 1.0000e-05\n",
      "Epoch 162/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7459 - val_loss: 17.2060 - lr: 1.0000e-05\n",
      "Epoch 163/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7452 - val_loss: 17.2050 - lr: 1.0000e-05\n",
      "Epoch 164/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7453 - val_loss: 17.2036 - lr: 1.0000e-05\n",
      "Epoch 165/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7444 - val_loss: 17.2033 - lr: 1.0000e-05\n",
      "Epoch 166/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7444 - val_loss: 17.2026 - lr: 1.0000e-05\n",
      "Epoch 167/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7438 - val_loss: 17.2027 - lr: 1.0000e-05\n",
      "Epoch 168/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7435 - val_loss: 17.2020 - lr: 1.0000e-05\n",
      "Epoch 169/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7433 - val_loss: 17.2012 - lr: 1.0000e-05\n",
      "Epoch 170/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7426 - val_loss: 17.2002 - lr: 1.0000e-05\n",
      "Epoch 171/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7419 - val_loss: 17.2007 - lr: 1.0000e-05\n",
      "Epoch 172/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7414 - val_loss: 17.2015 - lr: 1.0000e-05\n",
      "Epoch 173/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7410 - val_loss: 17.2013 - lr: 1.0000e-05\n",
      "Epoch 174/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.7407 - val_loss: 17.2017 - lr: 1.0000e-05\n",
      "Epoch 175/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7402 - val_loss: 17.2013 - lr: 1.0000e-05\n",
      "Epoch 176/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7399 - val_loss: 17.2016 - lr: 1.0000e-05\n",
      "Epoch 177/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7392 - val_loss: 17.2009 - lr: 1.0000e-05\n",
      "Epoch 178/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.7382 - val_loss: 17.1995 - lr: 1.0000e-05\n",
      "Epoch 179/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7380 - val_loss: 17.1999 - lr: 1.0000e-05\n",
      "Epoch 180/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7374 - val_loss: 17.1994 - lr: 1.0000e-05\n",
      "Epoch 181/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7376 - val_loss: 17.1973 - lr: 1.0000e-05\n",
      "Epoch 182/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7371 - val_loss: 17.1980 - lr: 1.0000e-05\n",
      "Epoch 183/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7369 - val_loss: 17.1998 - lr: 1.0000e-05\n",
      "Epoch 184/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7359 - val_loss: 17.1977 - lr: 1.0000e-05\n",
      "Epoch 185/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7352 - val_loss: 17.1960 - lr: 1.0000e-05\n",
      "Epoch 186/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7348 - val_loss: 17.1955 - lr: 1.0000e-05\n",
      "Epoch 187/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7347 - val_loss: 17.1937 - lr: 1.0000e-05\n",
      "Epoch 188/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7344 - val_loss: 17.1943 - lr: 1.0000e-05\n",
      "Epoch 189/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7342 - val_loss: 17.1945 - lr: 1.0000e-05\n",
      "Epoch 190/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7339 - val_loss: 17.1946 - lr: 1.0000e-05\n",
      "Epoch 191/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7326 - val_loss: 17.1965 - lr: 1.0000e-05\n",
      "Epoch 192/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7322 - val_loss: 17.1958 - lr: 1.0000e-05\n",
      "Epoch 193/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7320 - val_loss: 17.1941 - lr: 1.0000e-05\n",
      "Epoch 194/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.7311 - val_loss: 17.1944 - lr: 1.0000e-05\n",
      "Epoch 195/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7308 - val_loss: 17.1945 - lr: 1.0000e-05\n",
      "Epoch 196/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7301 - val_loss: 17.1953 - lr: 1.0000e-05\n",
      "Epoch 197/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7296 - val_loss: 17.1947 - lr: 1.0000e-05\n",
      "Epoch 198/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7291 - val_loss: 17.1944 - lr: 1.0000e-05\n",
      "Epoch 199/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.7287 - val_loss: 17.1941 - lr: 1.0000e-05\n",
      "Epoch 200/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7284 - val_loss: 17.1947 - lr: 1.0000e-05\n",
      "Epoch 201/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7281 - val_loss: 17.1958 - lr: 1.0000e-05\n",
      "Epoch 202/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7277 - val_loss: 17.1950 - lr: 1.0000e-05\n",
      "Epoch 203/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7268 - val_loss: 17.1931 - lr: 1.0000e-05\n",
      "Epoch 204/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7268 - val_loss: 17.1917 - lr: 1.0000e-05\n",
      "Epoch 205/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.7260 - val_loss: 17.1912 - lr: 1.0000e-05\n",
      "Epoch 206/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7255 - val_loss: 17.1906 - lr: 1.0000e-05\n",
      "Epoch 207/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.7250 - val_loss: 17.1910 - lr: 1.0000e-05\n",
      "Epoch 208/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.7241 - val_loss: 17.1907 - lr: 1.0000e-05\n",
      "Epoch 209/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7241 - val_loss: 17.1902 - lr: 1.0000e-05\n",
      "Epoch 210/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7236 - val_loss: 17.1892 - lr: 1.0000e-05\n",
      "Epoch 211/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7235 - val_loss: 17.1879 - lr: 1.0000e-05\n",
      "Epoch 212/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7230 - val_loss: 17.1855 - lr: 1.0000e-05\n",
      "Epoch 213/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7225 - val_loss: 17.1856 - lr: 1.0000e-05\n",
      "Epoch 214/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.7220 - val_loss: 17.1863 - lr: 1.0000e-05\n",
      "Epoch 215/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7215 - val_loss: 17.1862 - lr: 1.0000e-05\n",
      "Epoch 216/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7214 - val_loss: 17.1873 - lr: 1.0000e-05\n",
      "Epoch 217/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7205 - val_loss: 17.1862 - lr: 1.0000e-05\n",
      "Epoch 218/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7202 - val_loss: 17.1860 - lr: 1.0000e-05\n",
      "Epoch 219/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7197 - val_loss: 17.1863 - lr: 1.0000e-05\n",
      "Epoch 220/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7191 - val_loss: 17.1862 - lr: 1.0000e-05\n",
      "Epoch 221/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7186 - val_loss: 17.1863 - lr: 1.0000e-05\n",
      "Epoch 222/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7187 - val_loss: 17.1858 - lr: 1.0000e-05\n",
      "Epoch 223/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7180 - val_loss: 17.1856 - lr: 1.0000e-05\n",
      "Epoch 224/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7171 - val_loss: 17.1833 - lr: 1.0000e-05\n",
      "Epoch 225/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7168 - val_loss: 17.1822 - lr: 1.0000e-05\n",
      "Epoch 226/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7166 - val_loss: 17.1843 - lr: 1.0000e-05\n",
      "Epoch 227/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7155 - val_loss: 17.1844 - lr: 1.0000e-05\n",
      "Epoch 228/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7151 - val_loss: 17.1838 - lr: 1.0000e-05\n",
      "Epoch 229/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7149 - val_loss: 17.1849 - lr: 1.0000e-05\n",
      "Epoch 230/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.7146 - val_loss: 17.1847 - lr: 1.0000e-05\n",
      "Epoch 231/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7147 - val_loss: 17.1831 - lr: 1.0000e-05\n",
      "Epoch 232/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.7136 - val_loss: 17.1837 - lr: 1.0000e-05\n",
      "Epoch 233/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7133 - val_loss: 17.1827 - lr: 1.0000e-05\n",
      "Epoch 234/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7127 - val_loss: 17.1829 - lr: 1.0000e-05\n",
      "Epoch 235/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7122 - val_loss: 17.1817 - lr: 1.0000e-05\n",
      "Epoch 236/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7116 - val_loss: 17.1812 - lr: 1.0000e-05\n",
      "Epoch 237/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.7112 - val_loss: 17.1806 - lr: 1.0000e-05\n",
      "Epoch 238/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.7104 - val_loss: 17.1805 - lr: 1.0000e-05\n",
      "Epoch 239/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7105 - val_loss: 17.1803 - lr: 1.0000e-05\n",
      "Epoch 240/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.7098 - val_loss: 17.1800 - lr: 1.0000e-05\n",
      "Epoch 241/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7093 - val_loss: 17.1796 - lr: 1.0000e-05\n",
      "Epoch 242/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7089 - val_loss: 17.1812 - lr: 1.0000e-05\n",
      "Epoch 243/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7080 - val_loss: 17.1801 - lr: 1.0000e-05\n",
      "Epoch 244/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7075 - val_loss: 17.1806 - lr: 1.0000e-05\n",
      "Epoch 245/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7073 - val_loss: 17.1783 - lr: 1.0000e-05\n",
      "Epoch 246/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7071 - val_loss: 17.1760 - lr: 1.0000e-05\n",
      "Epoch 247/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.7067 - val_loss: 17.1750 - lr: 1.0000e-05\n",
      "Epoch 248/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7059 - val_loss: 17.1752 - lr: 1.0000e-05\n",
      "Epoch 249/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7055 - val_loss: 17.1762 - lr: 1.0000e-05\n",
      "Epoch 250/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7047 - val_loss: 17.1765 - lr: 1.0000e-05\n",
      "Epoch 251/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.7040 - val_loss: 17.1777 - lr: 1.0000e-05\n",
      "Epoch 252/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7043 - val_loss: 17.1798 - lr: 1.0000e-05\n",
      "Epoch 253/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7038 - val_loss: 17.1788 - lr: 1.0000e-05\n",
      "Epoch 254/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7031 - val_loss: 17.1786 - lr: 1.0000e-05\n",
      "Epoch 255/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7022 - val_loss: 17.1768 - lr: 1.0000e-05\n",
      "Epoch 256/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7019 - val_loss: 17.1753 - lr: 1.0000e-05\n",
      "Epoch 257/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7017 - val_loss: 17.1752 - lr: 1.0000e-05\n",
      "Epoch 258/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7009 - val_loss: 17.1741 - lr: 1.0000e-05\n",
      "Epoch 259/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7010 - val_loss: 17.1730 - lr: 1.0000e-05\n",
      "Epoch 260/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7002 - val_loss: 17.1737 - lr: 1.0000e-05\n",
      "Epoch 261/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6997 - val_loss: 17.1759 - lr: 1.0000e-05\n",
      "Epoch 262/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.6994 - val_loss: 17.1756 - lr: 1.0000e-05\n",
      "Epoch 263/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6988 - val_loss: 17.1753 - lr: 1.0000e-05\n",
      "Epoch 264/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.6982 - val_loss: 17.1733 - lr: 1.0000e-05\n",
      "Epoch 265/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.6978 - val_loss: 17.1743 - lr: 1.0000e-05\n",
      "Epoch 266/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6973 - val_loss: 17.1727 - lr: 1.0000e-05\n",
      "Epoch 267/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6966 - val_loss: 17.1719 - lr: 1.0000e-05\n",
      "Epoch 268/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6962 - val_loss: 17.1721 - lr: 1.0000e-05\n",
      "Epoch 269/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.6960 - val_loss: 17.1723 - lr: 1.0000e-05\n",
      "Epoch 270/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6954 - val_loss: 17.1702 - lr: 1.0000e-05\n",
      "Epoch 271/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6955 - val_loss: 17.1687 - lr: 1.0000e-05\n",
      "Epoch 272/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.6944 - val_loss: 17.1698 - lr: 1.0000e-05\n",
      "Epoch 273/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6937 - val_loss: 17.1691 - lr: 1.0000e-05\n",
      "Epoch 274/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6936 - val_loss: 17.1682 - lr: 1.0000e-05\n",
      "Epoch 275/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6931 - val_loss: 17.1677 - lr: 1.0000e-05\n",
      "Epoch 276/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6924 - val_loss: 17.1677 - lr: 1.0000e-05\n",
      "Epoch 277/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6917 - val_loss: 17.1678 - lr: 1.0000e-05\n",
      "Epoch 278/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6920 - val_loss: 17.1656 - lr: 1.0000e-05\n",
      "Epoch 279/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.6913 - val_loss: 17.1671 - lr: 1.0000e-05\n",
      "Epoch 280/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.6913 - val_loss: 17.1667 - lr: 1.0000e-05\n",
      "Epoch 281/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6903 - val_loss: 17.1638 - lr: 1.0000e-05\n",
      "Epoch 282/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6898 - val_loss: 17.1645 - lr: 1.0000e-05\n",
      "Epoch 283/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.6892 - val_loss: 17.1646 - lr: 1.0000e-05\n",
      "Epoch 284/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.6885 - val_loss: 17.1653 - lr: 1.0000e-05\n",
      "Epoch 285/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6882 - val_loss: 17.1643 - lr: 1.0000e-05\n",
      "Epoch 286/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.6876 - val_loss: 17.1676 - lr: 1.0000e-05\n",
      "Epoch 287/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6871 - val_loss: 17.1677 - lr: 1.0000e-05\n",
      "Epoch 288/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6870 - val_loss: 17.1667 - lr: 1.0000e-05\n",
      "Epoch 289/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.6862 - val_loss: 17.1668 - lr: 1.0000e-05\n",
      "Epoch 290/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6859 - val_loss: 17.1658 - lr: 1.0000e-05\n",
      "Epoch 291/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6857 - val_loss: 17.1651 - lr: 1.0000e-05\n",
      "Epoch 292/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6851 - val_loss: 17.1648 - lr: 1.0000e-05\n",
      "Epoch 293/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6843 - val_loss: 17.1645 - lr: 1.0000e-05\n",
      "Epoch 294/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.6841 - val_loss: 17.1644 - lr: 1.0000e-05\n",
      "Epoch 295/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6837 - val_loss: 17.1634 - lr: 1.0000e-05\n",
      "Epoch 296/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.6831 - val_loss: 17.1630 - lr: 1.0000e-05\n",
      "Epoch 297/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6828 - val_loss: 17.1630 - lr: 1.0000e-05\n",
      "Epoch 298/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6823 - val_loss: 17.1632 - lr: 1.0000e-05\n",
      "Epoch 299/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6819 - val_loss: 17.1625 - lr: 1.0000e-05\n",
      "Epoch 300/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6812 - val_loss: 17.1626 - lr: 1.0000e-05\n",
      "138/138 [==============================] - 0s 2ms/step\n",
      "Epoch 1/300\n",
      "31/31 [==============================] - 1s 8ms/step - loss: 711.5402 - val_loss: 656.3323 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 592.4402 - val_loss: 528.5807 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 463.6458 - val_loss: 402.7307 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 347.4368 - val_loss: 296.7704 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 253.0679 - val_loss: 214.4744 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 182.4350 - val_loss: 155.0352 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 133.8681 - val_loss: 116.5983 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 104.6655 - val_loss: 95.7057 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 90.2380 - val_loss: 86.3405 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 83.6401 - val_loss: 80.5750 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 77.6551 - val_loss: 73.4656 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 70.4579 - val_loss: 66.1257 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 63.4387 - val_loss: 58.9903 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 56.4264 - val_loss: 52.0231 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 50.2703 - val_loss: 46.7018 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 45.9615 - val_loss: 43.1966 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 42.9737 - val_loss: 40.6326 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 40.7335 - val_loss: 38.7246 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 39.0032 - val_loss: 37.1976 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 37.5594 - val_loss: 35.9544 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 36.2755 - val_loss: 34.8412 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 35.1276 - val_loss: 33.8980 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 34.1141 - val_loss: 33.0575 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 33.2400 - val_loss: 32.3459 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 32.5233 - val_loss: 31.7147 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 31.8304 - val_loss: 31.2158 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 31.2393 - val_loss: 30.7058 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 30.7369 - val_loss: 30.1897 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 30.1836 - val_loss: 29.7444 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 29.7329 - val_loss: 29.4378 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 29.2263 - val_loss: 28.9198 - lr: 0.0010\n",
      "Epoch 32/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 28.8093 - val_loss: 28.4777 - lr: 0.0010\n",
      "Epoch 33/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 28.3172 - val_loss: 28.0764 - lr: 0.0010\n",
      "Epoch 34/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 27.8332 - val_loss: 27.7572 - lr: 0.0010\n",
      "Epoch 35/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 27.4634 - val_loss: 27.3037 - lr: 0.0010\n",
      "Epoch 36/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 27.0239 - val_loss: 26.9605 - lr: 0.0010\n",
      "Epoch 37/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.6335 - val_loss: 26.6094 - lr: 0.0010\n",
      "Epoch 38/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.2979 - val_loss: 26.3162 - lr: 0.0010\n",
      "Epoch 39/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 25.9781 - val_loss: 26.0760 - lr: 0.0010\n",
      "Epoch 40/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.7645 - val_loss: 25.8615 - lr: 0.0010\n",
      "Epoch 41/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.4176 - val_loss: 25.5208 - lr: 0.0010\n",
      "Epoch 42/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.1632 - val_loss: 25.2745 - lr: 0.0010\n",
      "Epoch 43/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.9039 - val_loss: 25.1047 - lr: 0.0010\n",
      "Epoch 44/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.7231 - val_loss: 24.9559 - lr: 0.0010\n",
      "Epoch 45/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.4928 - val_loss: 24.7323 - lr: 0.0010\n",
      "Epoch 46/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.3255 - val_loss: 24.5597 - lr: 0.0010\n",
      "Epoch 47/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.1188 - val_loss: 24.4495 - lr: 0.0010\n",
      "Epoch 48/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.9810 - val_loss: 24.3393 - lr: 0.0010\n",
      "Epoch 49/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.8237 - val_loss: 24.1916 - lr: 0.0010\n",
      "Epoch 50/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.6657 - val_loss: 24.0464 - lr: 0.0010\n",
      "Epoch 51/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.5563 - val_loss: 23.9544 - lr: 0.0010\n",
      "Epoch 52/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.5141 - val_loss: 23.8819 - lr: 0.0010\n",
      "Epoch 53/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.3138 - val_loss: 23.6842 - lr: 0.0010\n",
      "Epoch 54/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 23.2678 - val_loss: 23.6587 - lr: 0.0010\n",
      "Epoch 55/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.0730 - val_loss: 23.5540 - lr: 0.0010\n",
      "Epoch 56/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.9490 - val_loss: 23.4171 - lr: 0.0010\n",
      "Epoch 57/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.8845 - val_loss: 23.4731 - lr: 0.0010\n",
      "Epoch 58/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.9083 - val_loss: 23.2832 - lr: 0.0010\n",
      "Epoch 59/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.7493 - val_loss: 23.2764 - lr: 0.0010\n",
      "Epoch 60/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.5741 - val_loss: 23.0947 - lr: 0.0010\n",
      "Epoch 61/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.4667 - val_loss: 23.0157 - lr: 0.0010\n",
      "Epoch 62/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.3811 - val_loss: 22.9961 - lr: 0.0010\n",
      "Epoch 63/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.3152 - val_loss: 22.8576 - lr: 0.0010\n",
      "Epoch 64/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 22.1917 - val_loss: 22.8817 - lr: 0.0010\n",
      "Epoch 65/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.1169 - val_loss: 22.7529 - lr: 0.0010\n",
      "Epoch 66/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.0425 - val_loss: 22.6396 - lr: 0.0010\n",
      "Epoch 67/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.9530 - val_loss: 22.5825 - lr: 0.0010\n",
      "Epoch 68/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 21.8303 - val_loss: 22.4287 - lr: 0.0010\n",
      "Epoch 69/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.7678 - val_loss: 22.4598 - lr: 0.0010\n",
      "Epoch 70/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.6512 - val_loss: 22.3678 - lr: 0.0010\n",
      "Epoch 71/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.5986 - val_loss: 22.2738 - lr: 0.0010\n",
      "Epoch 72/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.4868 - val_loss: 22.1789 - lr: 0.0010\n",
      "Epoch 73/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 21.3758 - val_loss: 22.1635 - lr: 0.0010\n",
      "Epoch 74/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.3026 - val_loss: 22.0192 - lr: 0.0010\n",
      "Epoch 75/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.2254 - val_loss: 21.9455 - lr: 0.0010\n",
      "Epoch 76/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.1118 - val_loss: 21.8498 - lr: 0.0010\n",
      "Epoch 77/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.0266 - val_loss: 21.8694 - lr: 0.0010\n",
      "Epoch 78/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.9701 - val_loss: 21.7492 - lr: 0.0010\n",
      "Epoch 79/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.8549 - val_loss: 21.6707 - lr: 0.0010\n",
      "Epoch 80/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.7851 - val_loss: 21.6824 - lr: 0.0010\n",
      "Epoch 81/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.6867 - val_loss: 21.5250 - lr: 0.0010\n",
      "Epoch 82/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.6266 - val_loss: 21.4932 - lr: 0.0010\n",
      "Epoch 83/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 20.5161 - val_loss: 21.4173 - lr: 0.0010\n",
      "Epoch 84/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.4441 - val_loss: 21.3450 - lr: 0.0010\n",
      "Epoch 85/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.3967 - val_loss: 21.3132 - lr: 0.0010\n",
      "Epoch 86/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.2459 - val_loss: 21.2635 - lr: 0.0010\n",
      "Epoch 87/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 20.2411 - val_loss: 21.1377 - lr: 0.0010\n",
      "Epoch 88/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 20.1140 - val_loss: 21.1348 - lr: 0.0010\n",
      "Epoch 89/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.0440 - val_loss: 21.0593 - lr: 0.0010\n",
      "Epoch 90/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.9643 - val_loss: 20.9607 - lr: 0.0010\n",
      "Epoch 91/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.8842 - val_loss: 20.9179 - lr: 0.0010\n",
      "Epoch 92/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.8136 - val_loss: 20.8704 - lr: 0.0010\n",
      "Epoch 93/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.7193 - val_loss: 20.7708 - lr: 0.0010\n",
      "Epoch 94/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.7116 - val_loss: 20.7473 - lr: 0.0010\n",
      "Epoch 95/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.6026 - val_loss: 20.6339 - lr: 0.0010\n",
      "Epoch 96/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.5033 - val_loss: 20.7448 - lr: 0.0010\n",
      "Epoch 97/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 19.4940 - val_loss: 20.6510 - lr: 0.0010\n",
      "Epoch 98/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.3935 - val_loss: 20.6024 - lr: 0.0010\n",
      "Epoch 99/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.3249 - val_loss: 20.5253 - lr: 0.0010\n",
      "Epoch 100/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.1907 - val_loss: 20.3994 - lr: 0.0010\n",
      "Epoch 101/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.1395 - val_loss: 20.3724 - lr: 0.0010\n",
      "Epoch 102/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 19.1103 - val_loss: 20.3166 - lr: 0.0010\n",
      "Epoch 103/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 18.9962 - val_loss: 20.2233 - lr: 0.0010\n",
      "Epoch 104/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.9475 - val_loss: 20.2132 - lr: 0.0010\n",
      "Epoch 105/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.8713 - val_loss: 20.1749 - lr: 0.0010\n",
      "Epoch 106/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.8022 - val_loss: 20.0335 - lr: 0.0010\n",
      "Epoch 107/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 18.7332 - val_loss: 20.0483 - lr: 0.0010\n",
      "Epoch 108/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.6372 - val_loss: 19.9638 - lr: 0.0010\n",
      "Epoch 109/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.5939 - val_loss: 19.8560 - lr: 0.0010\n",
      "Epoch 110/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.5243 - val_loss: 19.8749 - lr: 0.0010\n",
      "Epoch 111/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.4586 - val_loss: 19.7885 - lr: 0.0010\n",
      "Epoch 112/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.3789 - val_loss: 19.6232 - lr: 0.0010\n",
      "Epoch 113/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.2868 - val_loss: 19.6516 - lr: 0.0010\n",
      "Epoch 114/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.2481 - val_loss: 19.6033 - lr: 0.0010\n",
      "Epoch 115/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.2049 - val_loss: 19.5751 - lr: 0.0010\n",
      "Epoch 116/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.1316 - val_loss: 19.5133 - lr: 0.0010\n",
      "Epoch 117/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 18.0774 - val_loss: 19.5101 - lr: 0.0010\n",
      "Epoch 118/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.9996 - val_loss: 19.3896 - lr: 0.0010\n",
      "Epoch 119/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 17.9208 - val_loss: 19.2943 - lr: 0.0010\n",
      "Epoch 120/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 17.8913 - val_loss: 19.3162 - lr: 0.0010\n",
      "Epoch 121/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.8291 - val_loss: 19.1908 - lr: 0.0010\n",
      "Epoch 122/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 17.7183 - val_loss: 19.0338 - lr: 0.0010\n",
      "Epoch 123/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.6544 - val_loss: 19.0604 - lr: 0.0010\n",
      "Epoch 124/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.5905 - val_loss: 18.9984 - lr: 0.0010\n",
      "Epoch 125/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.5256 - val_loss: 18.9758 - lr: 0.0010\n",
      "Epoch 126/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.4890 - val_loss: 18.8226 - lr: 0.0010\n",
      "Epoch 127/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 17.3804 - val_loss: 18.7987 - lr: 0.0010\n",
      "Epoch 128/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.3701 - val_loss: 18.7396 - lr: 0.0010\n",
      "Epoch 129/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.3083 - val_loss: 18.7314 - lr: 0.0010\n",
      "Epoch 130/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.2121 - val_loss: 18.7175 - lr: 0.0010\n",
      "Epoch 131/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 17.2287 - val_loss: 18.5988 - lr: 0.0010\n",
      "Epoch 132/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.0743 - val_loss: 18.5147 - lr: 0.0010\n",
      "Epoch 133/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.0441 - val_loss: 18.5002 - lr: 0.0010\n",
      "Epoch 134/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 16.9752 - val_loss: 18.3724 - lr: 0.0010\n",
      "Epoch 135/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.8599 - val_loss: 18.3668 - lr: 0.0010\n",
      "Epoch 136/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.8567 - val_loss: 18.2847 - lr: 0.0010\n",
      "Epoch 137/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.7570 - val_loss: 18.2464 - lr: 0.0010\n",
      "Epoch 138/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.7037 - val_loss: 18.1971 - lr: 0.0010\n",
      "Epoch 139/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.6658 - val_loss: 18.1789 - lr: 0.0010\n",
      "Epoch 140/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.6244 - val_loss: 18.0743 - lr: 0.0010\n",
      "Epoch 141/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.5706 - val_loss: 18.0401 - lr: 0.0010\n",
      "Epoch 142/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.5281 - val_loss: 17.9578 - lr: 0.0010\n",
      "Epoch 143/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 16.4202 - val_loss: 17.9269 - lr: 0.0010\n",
      "Epoch 144/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3791 - val_loss: 17.8086 - lr: 0.0010\n",
      "Epoch 145/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3167 - val_loss: 17.7823 - lr: 0.0010\n",
      "Epoch 146/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.2579 - val_loss: 17.8278 - lr: 0.0010\n",
      "Epoch 147/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.2146 - val_loss: 17.8498 - lr: 0.0010\n",
      "Epoch 148/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 16.3211 - val_loss: 17.6855 - lr: 0.0010\n",
      "Epoch 149/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.1054 - val_loss: 17.6391 - lr: 0.0010\n",
      "Epoch 150/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.0716 - val_loss: 17.5616 - lr: 0.0010\n",
      "Epoch 151/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 16.0240 - val_loss: 17.5286 - lr: 0.0010\n",
      "Epoch 152/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9576 - val_loss: 17.5587 - lr: 0.0010\n",
      "Epoch 153/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.9567 - val_loss: 17.4977 - lr: 0.0010\n",
      "Epoch 154/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.9055 - val_loss: 17.5169 - lr: 0.0010\n",
      "Epoch 155/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9094 - val_loss: 17.4445 - lr: 0.0010\n",
      "Epoch 156/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8514 - val_loss: 17.4330 - lr: 0.0010\n",
      "Epoch 157/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8203 - val_loss: 17.4192 - lr: 0.0010\n",
      "Epoch 158/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8085 - val_loss: 17.3143 - lr: 0.0010\n",
      "Epoch 159/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6810 - val_loss: 17.2806 - lr: 0.0010\n",
      "Epoch 160/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6504 - val_loss: 17.3207 - lr: 0.0010\n",
      "Epoch 161/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6723 - val_loss: 17.2542 - lr: 0.0010\n",
      "Epoch 162/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.5947 - val_loss: 17.2099 - lr: 0.0010\n",
      "Epoch 163/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.5532 - val_loss: 17.2099 - lr: 0.0010\n",
      "Epoch 164/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.5445 - val_loss: 17.1556 - lr: 0.0010\n",
      "Epoch 165/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.4988 - val_loss: 17.0925 - lr: 0.0010\n",
      "Epoch 166/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.4355 - val_loss: 17.0828 - lr: 0.0010\n",
      "Epoch 167/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.4652 - val_loss: 17.0781 - lr: 0.0010\n",
      "Epoch 168/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.4023 - val_loss: 16.9553 - lr: 0.0010\n",
      "Epoch 169/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.3479 - val_loss: 16.9207 - lr: 0.0010\n",
      "Epoch 170/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.3492 - val_loss: 17.0059 - lr: 0.0010\n",
      "Epoch 171/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.3164 - val_loss: 17.0186 - lr: 0.0010\n",
      "Epoch 172/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2968 - val_loss: 16.8710 - lr: 0.0010\n",
      "Epoch 173/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2878 - val_loss: 16.9984 - lr: 0.0010\n",
      "Epoch 174/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.3175 - val_loss: 16.8139 - lr: 0.0010\n",
      "Epoch 175/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1896 - val_loss: 16.8043 - lr: 0.0010\n",
      "Epoch 176/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1331 - val_loss: 16.7683 - lr: 0.0010\n",
      "Epoch 177/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1183 - val_loss: 16.7319 - lr: 0.0010\n",
      "Epoch 178/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.1612 - val_loss: 16.7494 - lr: 0.0010\n",
      "Epoch 179/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.0868 - val_loss: 16.7132 - lr: 0.0010\n",
      "Epoch 180/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.0444 - val_loss: 16.6693 - lr: 0.0010\n",
      "Epoch 181/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.0406 - val_loss: 16.6805 - lr: 0.0010\n",
      "Epoch 182/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.9955 - val_loss: 16.6206 - lr: 0.0010\n",
      "Epoch 183/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.9716 - val_loss: 16.5953 - lr: 0.0010\n",
      "Epoch 184/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.9597 - val_loss: 16.6003 - lr: 0.0010\n",
      "Epoch 185/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.9224 - val_loss: 16.5837 - lr: 0.0010\n",
      "Epoch 186/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8877 - val_loss: 16.5263 - lr: 0.0010\n",
      "Epoch 187/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.8565 - val_loss: 16.5121 - lr: 0.0010\n",
      "Epoch 188/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.9257 - val_loss: 16.5694 - lr: 0.0010\n",
      "Epoch 189/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8412 - val_loss: 16.4714 - lr: 0.0010\n",
      "Epoch 190/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8801 - val_loss: 16.4115 - lr: 0.0010\n",
      "Epoch 191/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7967 - val_loss: 16.4161 - lr: 0.0010\n",
      "Epoch 192/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7487 - val_loss: 16.4474 - lr: 0.0010\n",
      "Epoch 193/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7312 - val_loss: 16.4084 - lr: 0.0010\n",
      "Epoch 194/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7540 - val_loss: 16.4963 - lr: 0.0010\n",
      "Epoch 195/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7630 - val_loss: 16.3967 - lr: 0.0010\n",
      "Epoch 196/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6908 - val_loss: 16.3425 - lr: 0.0010\n",
      "Epoch 197/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7491 - val_loss: 16.3323 - lr: 0.0010\n",
      "Epoch 198/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6364 - val_loss: 16.3556 - lr: 0.0010\n",
      "Epoch 199/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6207 - val_loss: 16.3312 - lr: 0.0010\n",
      "Epoch 200/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6072 - val_loss: 16.2938 - lr: 0.0010\n",
      "Epoch 201/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5843 - val_loss: 16.2951 - lr: 0.0010\n",
      "Epoch 202/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5383 - val_loss: 16.2665 - lr: 0.0010\n",
      "Epoch 203/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5298 - val_loss: 16.2875 - lr: 0.0010\n",
      "Epoch 204/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5321 - val_loss: 16.2399 - lr: 0.0010\n",
      "Epoch 205/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.4755 - val_loss: 16.2386 - lr: 0.0010\n",
      "Epoch 206/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.4731 - val_loss: 16.2428 - lr: 0.0010\n",
      "Epoch 207/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5379 - val_loss: 16.2314 - lr: 0.0010\n",
      "Epoch 208/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.4642 - val_loss: 16.2356 - lr: 0.0010\n",
      "Epoch 209/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5229 - val_loss: 16.1750 - lr: 0.0010\n",
      "Epoch 210/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.4239 - val_loss: 16.1884 - lr: 0.0010\n",
      "Epoch 211/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.4007 - val_loss: 16.0864 - lr: 0.0010\n",
      "Epoch 212/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.3564 - val_loss: 16.2040 - lr: 0.0010\n",
      "Epoch 213/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.4103 - val_loss: 16.1362 - lr: 0.0010\n",
      "Epoch 214/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.3665 - val_loss: 16.0919 - lr: 0.0010\n",
      "Epoch 215/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.1967 - val_loss: 16.0841 - lr: 1.0000e-04\n",
      "Epoch 216/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.1813 - val_loss: 16.0791 - lr: 1.0000e-04\n",
      "Epoch 217/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.1796 - val_loss: 16.0732 - lr: 1.0000e-04\n",
      "Epoch 218/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.1696 - val_loss: 16.0701 - lr: 1.0000e-04\n",
      "Epoch 219/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.1681 - val_loss: 16.0765 - lr: 1.0000e-04\n",
      "Epoch 220/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.1640 - val_loss: 16.0847 - lr: 1.0000e-04\n",
      "Epoch 221/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.1593 - val_loss: 16.0918 - lr: 1.0000e-04\n",
      "Epoch 222/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.1495 - val_loss: 16.0899 - lr: 1.0000e-05\n",
      "Epoch 223/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.1462 - val_loss: 16.0863 - lr: 1.0000e-05\n",
      "Epoch 224/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.1449 - val_loss: 16.0857 - lr: 1.0000e-05\n",
      "Epoch 225/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.1444 - val_loss: 16.0846 - lr: 1.0000e-05\n",
      "Epoch 226/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.1438 - val_loss: 16.0851 - lr: 1.0000e-05\n",
      "Epoch 227/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.1434 - val_loss: 16.0859 - lr: 1.0000e-05\n",
      "Epoch 228/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.1429 - val_loss: 16.0843 - lr: 1.0000e-05\n",
      "Epoch 229/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.1423 - val_loss: 16.0823 - lr: 1.0000e-05\n",
      "Epoch 230/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.1420 - val_loss: 16.0820 - lr: 1.0000e-05\n",
      "Epoch 231/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.1415 - val_loss: 16.0800 - lr: 1.0000e-05\n",
      "Epoch 232/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.1409 - val_loss: 16.0792 - lr: 1.0000e-05\n",
      "Epoch 233/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.1407 - val_loss: 16.0791 - lr: 1.0000e-05\n",
      "Epoch 234/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.1404 - val_loss: 16.0769 - lr: 1.0000e-05\n",
      "Epoch 235/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.1401 - val_loss: 16.0778 - lr: 1.0000e-05\n",
      "Epoch 236/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.1393 - val_loss: 16.0777 - lr: 1.0000e-05\n",
      "Epoch 237/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.1394 - val_loss: 16.0773 - lr: 1.0000e-05\n",
      "Epoch 238/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.1389 - val_loss: 16.0766 - lr: 1.0000e-05\n",
      "138/138 [==============================] - 0s 2ms/step\n",
      "Epoch 1/300\n",
      "31/31 [==============================] - 1s 9ms/step - loss: 723.8277 - val_loss: 622.8126 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 536.7343 - val_loss: 428.5359 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 344.8770 - val_loss: 251.9383 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 197.0189 - val_loss: 138.4733 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 114.3336 - val_loss: 89.8958 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 86.2854 - val_loss: 78.1888 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 78.4559 - val_loss: 72.2045 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 71.8276 - val_loss: 65.7602 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 64.7526 - val_loss: 58.9653 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 57.5865 - val_loss: 52.2298 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 50.7837 - val_loss: 46.5211 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 45.5779 - val_loss: 42.7161 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 42.1568 - val_loss: 40.2056 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 39.9145 - val_loss: 38.5338 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 38.3220 - val_loss: 37.2726 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 37.1522 - val_loss: 36.3011 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 36.2603 - val_loss: 35.5412 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 35.5286 - val_loss: 34.8450 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 34.9150 - val_loss: 34.3145 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 34.3556 - val_loss: 33.7628 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 33.8632 - val_loss: 33.2645 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 33.3801 - val_loss: 32.7793 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 32.9110 - val_loss: 32.2863 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 32.4478 - val_loss: 31.8638 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 31.9571 - val_loss: 31.4149 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 31.4948 - val_loss: 31.0321 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 30.9823 - val_loss: 30.5333 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 30.4932 - val_loss: 30.0381 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 30.0204 - val_loss: 29.5764 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 29.5553 - val_loss: 29.1794 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 29.1222 - val_loss: 28.8005 - lr: 0.0010\n",
      "Epoch 32/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 28.6865 - val_loss: 28.4711 - lr: 0.0010\n",
      "Epoch 33/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 28.3273 - val_loss: 28.1617 - lr: 0.0010\n",
      "Epoch 34/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 27.8915 - val_loss: 27.8146 - lr: 0.0010\n",
      "Epoch 35/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 27.5543 - val_loss: 27.5771 - lr: 0.0010\n",
      "Epoch 36/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 27.2446 - val_loss: 27.3347 - lr: 0.0010\n",
      "Epoch 37/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 26.9609 - val_loss: 27.0662 - lr: 0.0010\n",
      "Epoch 38/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.7106 - val_loss: 26.9358 - lr: 0.0010\n",
      "Epoch 39/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.5033 - val_loss: 26.7520 - lr: 0.0010\n",
      "Epoch 40/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.2457 - val_loss: 26.4753 - lr: 0.0010\n",
      "Epoch 41/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.0500 - val_loss: 26.3298 - lr: 0.0010\n",
      "Epoch 42/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.8062 - val_loss: 26.1730 - lr: 0.0010\n",
      "Epoch 43/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.6112 - val_loss: 25.9723 - lr: 0.0010\n",
      "Epoch 44/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.4642 - val_loss: 25.8290 - lr: 0.0010\n",
      "Epoch 45/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.3165 - val_loss: 25.6619 - lr: 0.0010\n",
      "Epoch 46/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 25.0315 - val_loss: 25.3961 - lr: 0.0010\n",
      "Epoch 47/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.8444 - val_loss: 25.2192 - lr: 0.0010\n",
      "Epoch 48/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.6349 - val_loss: 24.9717 - lr: 0.0010\n",
      "Epoch 49/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.4414 - val_loss: 24.8662 - lr: 0.0010\n",
      "Epoch 50/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.3538 - val_loss: 24.6390 - lr: 0.0010\n",
      "Epoch 51/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.0819 - val_loss: 24.4599 - lr: 0.0010\n",
      "Epoch 52/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.8589 - val_loss: 24.3358 - lr: 0.0010\n",
      "Epoch 53/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.7478 - val_loss: 24.1894 - lr: 0.0010\n",
      "Epoch 54/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 23.5046 - val_loss: 24.0384 - lr: 0.0010\n",
      "Epoch 55/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.3571 - val_loss: 23.9153 - lr: 0.0010\n",
      "Epoch 56/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.1935 - val_loss: 23.7203 - lr: 0.0010\n",
      "Epoch 57/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.9960 - val_loss: 23.5656 - lr: 0.0010\n",
      "Epoch 58/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 22.8961 - val_loss: 23.4187 - lr: 0.0010\n",
      "Epoch 59/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.7225 - val_loss: 23.2653 - lr: 0.0010\n",
      "Epoch 60/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.5535 - val_loss: 23.1679 - lr: 0.0010\n",
      "Epoch 61/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.4235 - val_loss: 23.0788 - lr: 0.0010\n",
      "Epoch 62/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.2638 - val_loss: 22.9239 - lr: 0.0010\n",
      "Epoch 63/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.2099 - val_loss: 22.7716 - lr: 0.0010\n",
      "Epoch 64/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.9986 - val_loss: 22.7461 - lr: 0.0010\n",
      "Epoch 65/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.8821 - val_loss: 22.6321 - lr: 0.0010\n",
      "Epoch 66/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.7584 - val_loss: 22.4581 - lr: 0.0010\n",
      "Epoch 67/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.6535 - val_loss: 22.4316 - lr: 0.0010\n",
      "Epoch 68/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.5736 - val_loss: 22.3584 - lr: 0.0010\n",
      "Epoch 69/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.4336 - val_loss: 22.1953 - lr: 0.0010\n",
      "Epoch 70/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.3502 - val_loss: 22.1644 - lr: 0.0010\n",
      "Epoch 71/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 21.1947 - val_loss: 22.0393 - lr: 0.0010\n",
      "Epoch 72/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.0889 - val_loss: 21.9664 - lr: 0.0010\n",
      "Epoch 73/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.9954 - val_loss: 21.9209 - lr: 0.0010\n",
      "Epoch 74/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.8992 - val_loss: 21.8156 - lr: 0.0010\n",
      "Epoch 75/300\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 20.8100 - val_loss: 21.7266 - lr: 0.0010\n",
      "Epoch 76/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 20.7536 - val_loss: 21.6898 - lr: 0.0010\n",
      "Epoch 77/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.6538 - val_loss: 21.6559 - lr: 0.0010\n",
      "Epoch 78/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.5142 - val_loss: 21.5670 - lr: 0.0010\n",
      "Epoch 79/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 20.4865 - val_loss: 21.4487 - lr: 0.0010\n",
      "Epoch 80/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 20.3441 - val_loss: 21.3665 - lr: 0.0010\n",
      "Epoch 81/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.2691 - val_loss: 21.3263 - lr: 0.0010\n",
      "Epoch 82/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.1793 - val_loss: 21.2998 - lr: 0.0010\n",
      "Epoch 83/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.1516 - val_loss: 21.1779 - lr: 0.0010\n",
      "Epoch 84/300\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 20.0694 - val_loss: 21.1421 - lr: 0.0010\n",
      "Epoch 85/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.9890 - val_loss: 21.1612 - lr: 0.0010\n",
      "Epoch 86/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.9193 - val_loss: 21.0186 - lr: 0.0010\n",
      "Epoch 87/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.8430 - val_loss: 20.9286 - lr: 0.0010\n",
      "Epoch 88/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.7868 - val_loss: 20.9465 - lr: 0.0010\n",
      "Epoch 89/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.7334 - val_loss: 20.9462 - lr: 0.0010\n",
      "Epoch 90/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.6427 - val_loss: 20.7999 - lr: 0.0010\n",
      "Epoch 91/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.5877 - val_loss: 20.8267 - lr: 0.0010\n",
      "Epoch 92/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 19.5541 - val_loss: 20.7701 - lr: 0.0010\n",
      "Epoch 93/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.4557 - val_loss: 20.6860 - lr: 0.0010\n",
      "Epoch 94/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.4191 - val_loss: 20.6168 - lr: 0.0010\n",
      "Epoch 95/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.3111 - val_loss: 20.5731 - lr: 0.0010\n",
      "Epoch 96/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 19.3419 - val_loss: 20.5915 - lr: 0.0010\n",
      "Epoch 97/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.3143 - val_loss: 20.5930 - lr: 0.0010\n",
      "Epoch 98/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.2029 - val_loss: 20.4426 - lr: 0.0010\n",
      "Epoch 99/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.0945 - val_loss: 20.3811 - lr: 0.0010\n",
      "Epoch 100/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.0419 - val_loss: 20.4149 - lr: 0.0010\n",
      "Epoch 101/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 18.9984 - val_loss: 20.2884 - lr: 0.0010\n",
      "Epoch 102/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.9907 - val_loss: 20.2413 - lr: 0.0010\n",
      "Epoch 103/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.8435 - val_loss: 20.2389 - lr: 0.0010\n",
      "Epoch 104/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.8105 - val_loss: 20.1594 - lr: 0.0010\n",
      "Epoch 105/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 18.8455 - val_loss: 20.1694 - lr: 0.0010\n",
      "Epoch 106/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.7312 - val_loss: 20.0836 - lr: 0.0010\n",
      "Epoch 107/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.6513 - val_loss: 20.0122 - lr: 0.0010\n",
      "Epoch 108/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.6551 - val_loss: 19.9381 - lr: 0.0010\n",
      "Epoch 109/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 18.5724 - val_loss: 19.9813 - lr: 0.0010\n",
      "Epoch 110/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.5312 - val_loss: 19.8876 - lr: 0.0010\n",
      "Epoch 111/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.4623 - val_loss: 19.9194 - lr: 0.0010\n",
      "Epoch 112/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.5340 - val_loss: 19.9413 - lr: 0.0010\n",
      "Epoch 113/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.4094 - val_loss: 19.8363 - lr: 0.0010\n",
      "Epoch 114/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.3190 - val_loss: 19.7387 - lr: 0.0010\n",
      "Epoch 115/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 18.2592 - val_loss: 19.7295 - lr: 0.0010\n",
      "Epoch 116/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.2670 - val_loss: 19.6912 - lr: 0.0010\n",
      "Epoch 117/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.1448 - val_loss: 19.6198 - lr: 0.0010\n",
      "Epoch 118/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.1451 - val_loss: 19.6189 - lr: 0.0010\n",
      "Epoch 119/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.0665 - val_loss: 19.6158 - lr: 0.0010\n",
      "Epoch 120/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.0389 - val_loss: 19.6581 - lr: 0.0010\n",
      "Epoch 121/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.1475 - val_loss: 19.4269 - lr: 0.0010\n",
      "Epoch 122/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.9813 - val_loss: 19.3928 - lr: 0.0010\n",
      "Epoch 123/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.9135 - val_loss: 19.3725 - lr: 0.0010\n",
      "Epoch 124/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.8267 - val_loss: 19.3403 - lr: 0.0010\n",
      "Epoch 125/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.7744 - val_loss: 19.3307 - lr: 0.0010\n",
      "Epoch 126/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 17.7389 - val_loss: 19.2550 - lr: 0.0010\n",
      "Epoch 127/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.7008 - val_loss: 19.3338 - lr: 0.0010\n",
      "Epoch 128/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.6706 - val_loss: 19.2118 - lr: 0.0010\n",
      "Epoch 129/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.5823 - val_loss: 19.1866 - lr: 0.0010\n",
      "Epoch 130/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.5641 - val_loss: 19.1290 - lr: 0.0010\n",
      "Epoch 131/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.4884 - val_loss: 19.1205 - lr: 0.0010\n",
      "Epoch 132/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 17.4572 - val_loss: 19.0625 - lr: 0.0010\n",
      "Epoch 133/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.3959 - val_loss: 19.1415 - lr: 0.0010\n",
      "Epoch 134/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.3892 - val_loss: 19.0414 - lr: 0.0010\n",
      "Epoch 135/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.3429 - val_loss: 19.0141 - lr: 0.0010\n",
      "Epoch 136/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 17.2964 - val_loss: 18.8917 - lr: 0.0010\n",
      "Epoch 137/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.2298 - val_loss: 18.9003 - lr: 0.0010\n",
      "Epoch 138/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.1625 - val_loss: 18.9099 - lr: 0.0010\n",
      "Epoch 139/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.1262 - val_loss: 18.8272 - lr: 0.0010\n",
      "Epoch 140/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 17.1012 - val_loss: 18.8647 - lr: 0.0010\n",
      "Epoch 141/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.0852 - val_loss: 18.7324 - lr: 0.0010\n",
      "Epoch 142/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 17.0146 - val_loss: 18.7833 - lr: 0.0010\n",
      "Epoch 143/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.0702 - val_loss: 18.6715 - lr: 0.0010\n",
      "Epoch 144/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.9197 - val_loss: 18.6038 - lr: 0.0010\n",
      "Epoch 145/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.9028 - val_loss: 18.6304 - lr: 0.0010\n",
      "Epoch 146/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.9206 - val_loss: 18.6185 - lr: 0.0010\n",
      "Epoch 147/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.7607 - val_loss: 18.6377 - lr: 0.0010\n",
      "Epoch 148/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.6472 - val_loss: 18.5386 - lr: 1.0000e-04\n",
      "Epoch 149/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.5900 - val_loss: 18.5164 - lr: 1.0000e-04\n",
      "Epoch 150/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.5840 - val_loss: 18.5122 - lr: 1.0000e-04\n",
      "Epoch 151/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.5764 - val_loss: 18.5041 - lr: 1.0000e-04\n",
      "Epoch 152/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.5680 - val_loss: 18.5115 - lr: 1.0000e-04\n",
      "Epoch 153/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.5608 - val_loss: 18.5089 - lr: 1.0000e-04\n",
      "Epoch 154/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.5521 - val_loss: 18.5006 - lr: 1.0000e-04\n",
      "Epoch 155/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.5477 - val_loss: 18.4956 - lr: 1.0000e-04\n",
      "Epoch 156/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.5432 - val_loss: 18.4899 - lr: 1.0000e-04\n",
      "Epoch 157/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.5359 - val_loss: 18.4804 - lr: 1.0000e-04\n",
      "Epoch 158/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.5329 - val_loss: 18.4873 - lr: 1.0000e-04\n",
      "Epoch 159/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.5258 - val_loss: 18.4788 - lr: 1.0000e-04\n",
      "Epoch 160/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.5235 - val_loss: 18.4655 - lr: 1.0000e-04\n",
      "Epoch 161/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.5168 - val_loss: 18.4582 - lr: 1.0000e-04\n",
      "Epoch 162/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.5093 - val_loss: 18.4547 - lr: 1.0000e-04\n",
      "Epoch 163/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.5024 - val_loss: 18.4577 - lr: 1.0000e-04\n",
      "Epoch 164/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.5010 - val_loss: 18.4548 - lr: 1.0000e-04\n",
      "Epoch 165/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 16.4930 - val_loss: 18.4502 - lr: 1.0000e-04\n",
      "Epoch 166/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4896 - val_loss: 18.4498 - lr: 1.0000e-04\n",
      "Epoch 167/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4896 - val_loss: 18.4464 - lr: 1.0000e-04\n",
      "Epoch 168/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4822 - val_loss: 18.4387 - lr: 1.0000e-04\n",
      "Epoch 169/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4832 - val_loss: 18.4335 - lr: 1.0000e-04\n",
      "Epoch 170/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4670 - val_loss: 18.4386 - lr: 1.0000e-04\n",
      "Epoch 171/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4700 - val_loss: 18.4390 - lr: 1.0000e-04\n",
      "Epoch 172/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4660 - val_loss: 18.4410 - lr: 1.0000e-04\n",
      "Epoch 173/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4467 - val_loss: 18.4406 - lr: 1.0000e-05\n",
      "Epoch 174/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4459 - val_loss: 18.4391 - lr: 1.0000e-05\n",
      "Epoch 175/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4450 - val_loss: 18.4385 - lr: 1.0000e-05\n",
      "Epoch 176/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.4443 - val_loss: 18.4382 - lr: 1.0000e-05\n",
      "Epoch 177/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4439 - val_loss: 18.4390 - lr: 1.0000e-05\n",
      "Epoch 178/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4433 - val_loss: 18.4372 - lr: 1.0000e-05\n",
      "Epoch 179/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4428 - val_loss: 18.4369 - lr: 1.0000e-05\n",
      "Epoch 180/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.4419 - val_loss: 18.4362 - lr: 1.0000e-05\n",
      "Epoch 181/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4417 - val_loss: 18.4354 - lr: 1.0000e-05\n",
      "Epoch 182/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4407 - val_loss: 18.4361 - lr: 1.0000e-05\n",
      "Epoch 183/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4401 - val_loss: 18.4357 - lr: 1.0000e-05\n",
      "Epoch 184/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4397 - val_loss: 18.4351 - lr: 1.0000e-05\n",
      "Epoch 185/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4392 - val_loss: 18.4343 - lr: 1.0000e-05\n",
      "Epoch 186/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4383 - val_loss: 18.4332 - lr: 1.0000e-05\n",
      "Epoch 187/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4378 - val_loss: 18.4330 - lr: 1.0000e-05\n",
      "Epoch 188/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.4377 - val_loss: 18.4325 - lr: 1.0000e-05\n",
      "Epoch 189/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4373 - val_loss: 18.4315 - lr: 1.0000e-05\n",
      "Epoch 190/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4360 - val_loss: 18.4309 - lr: 1.0000e-05\n",
      "Epoch 191/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4357 - val_loss: 18.4288 - lr: 1.0000e-05\n",
      "Epoch 192/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.4358 - val_loss: 18.4279 - lr: 1.0000e-05\n",
      "Epoch 193/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4343 - val_loss: 18.4271 - lr: 1.0000e-05\n",
      "Epoch 194/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4338 - val_loss: 18.4272 - lr: 1.0000e-05\n",
      "Epoch 195/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4334 - val_loss: 18.4271 - lr: 1.0000e-05\n",
      "Epoch 196/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4332 - val_loss: 18.4278 - lr: 1.0000e-05\n",
      "Epoch 197/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4324 - val_loss: 18.4260 - lr: 1.0000e-05\n",
      "Epoch 198/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4318 - val_loss: 18.4257 - lr: 1.0000e-05\n",
      "Epoch 199/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4317 - val_loss: 18.4248 - lr: 1.0000e-05\n",
      "Epoch 200/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4309 - val_loss: 18.4255 - lr: 1.0000e-05\n",
      "Epoch 201/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4305 - val_loss: 18.4255 - lr: 1.0000e-05\n",
      "Epoch 202/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4297 - val_loss: 18.4252 - lr: 1.0000e-05\n",
      "Epoch 203/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4290 - val_loss: 18.4249 - lr: 1.0000e-05\n",
      "Epoch 204/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4286 - val_loss: 18.4244 - lr: 1.0000e-05\n",
      "Epoch 205/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4280 - val_loss: 18.4236 - lr: 1.0000e-05\n",
      "Epoch 206/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4274 - val_loss: 18.4203 - lr: 1.0000e-05\n",
      "Epoch 207/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4270 - val_loss: 18.4190 - lr: 1.0000e-05\n",
      "Epoch 208/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.4266 - val_loss: 18.4193 - lr: 1.0000e-05\n",
      "Epoch 209/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4256 - val_loss: 18.4184 - lr: 1.0000e-05\n",
      "Epoch 210/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4252 - val_loss: 18.4163 - lr: 1.0000e-05\n",
      "Epoch 211/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4247 - val_loss: 18.4160 - lr: 1.0000e-05\n",
      "Epoch 212/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4241 - val_loss: 18.4163 - lr: 1.0000e-05\n",
      "Epoch 213/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4238 - val_loss: 18.4153 - lr: 1.0000e-05\n",
      "Epoch 214/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4231 - val_loss: 18.4160 - lr: 1.0000e-05\n",
      "Epoch 215/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4226 - val_loss: 18.4162 - lr: 1.0000e-05\n",
      "Epoch 216/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.4218 - val_loss: 18.4154 - lr: 1.0000e-05\n",
      "Epoch 217/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4217 - val_loss: 18.4134 - lr: 1.0000e-05\n",
      "Epoch 218/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 16.4209 - val_loss: 18.4131 - lr: 1.0000e-05\n",
      "Epoch 219/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4203 - val_loss: 18.4133 - lr: 1.0000e-05\n",
      "Epoch 220/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4202 - val_loss: 18.4137 - lr: 1.0000e-05\n",
      "Epoch 221/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4197 - val_loss: 18.4127 - lr: 1.0000e-05\n",
      "Epoch 222/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4193 - val_loss: 18.4128 - lr: 1.0000e-05\n",
      "Epoch 223/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4182 - val_loss: 18.4131 - lr: 1.0000e-05\n",
      "Epoch 224/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.4182 - val_loss: 18.4124 - lr: 1.0000e-05\n",
      "Epoch 225/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 16.4176 - val_loss: 18.4117 - lr: 1.0000e-05\n",
      "Epoch 226/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4169 - val_loss: 18.4119 - lr: 1.0000e-05\n",
      "Epoch 227/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4167 - val_loss: 18.4115 - lr: 1.0000e-05\n",
      "Epoch 228/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4163 - val_loss: 18.4115 - lr: 1.0000e-05\n",
      "Epoch 229/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 16.4152 - val_loss: 18.4100 - lr: 1.0000e-05\n",
      "Epoch 230/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4150 - val_loss: 18.4106 - lr: 1.0000e-05\n",
      "Epoch 231/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4141 - val_loss: 18.4102 - lr: 1.0000e-05\n",
      "Epoch 232/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.4144 - val_loss: 18.4107 - lr: 1.0000e-05\n",
      "Epoch 233/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4132 - val_loss: 18.4087 - lr: 1.0000e-05\n",
      "Epoch 234/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4128 - val_loss: 18.4082 - lr: 1.0000e-05\n",
      "Epoch 235/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4123 - val_loss: 18.4064 - lr: 1.0000e-05\n",
      "Epoch 236/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4117 - val_loss: 18.4057 - lr: 1.0000e-05\n",
      "Epoch 237/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.4115 - val_loss: 18.4068 - lr: 1.0000e-05\n",
      "Epoch 238/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4114 - val_loss: 18.4066 - lr: 1.0000e-05\n",
      "Epoch 239/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4107 - val_loss: 18.4042 - lr: 1.0000e-05\n",
      "Epoch 240/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4099 - val_loss: 18.4046 - lr: 1.0000e-05\n",
      "Epoch 241/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4096 - val_loss: 18.4028 - lr: 1.0000e-05\n",
      "Epoch 242/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4084 - val_loss: 18.4029 - lr: 1.0000e-05\n",
      "Epoch 243/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4080 - val_loss: 18.4027 - lr: 1.0000e-05\n",
      "Epoch 244/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4073 - val_loss: 18.4018 - lr: 1.0000e-05\n",
      "Epoch 245/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.4069 - val_loss: 18.4003 - lr: 1.0000e-05\n",
      "Epoch 246/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 16.4063 - val_loss: 18.4001 - lr: 1.0000e-05\n",
      "Epoch 247/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4059 - val_loss: 18.3992 - lr: 1.0000e-05\n",
      "Epoch 248/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4056 - val_loss: 18.3980 - lr: 1.0000e-05\n",
      "Epoch 249/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4046 - val_loss: 18.3973 - lr: 1.0000e-05\n",
      "Epoch 250/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4051 - val_loss: 18.3972 - lr: 1.0000e-05\n",
      "Epoch 251/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4041 - val_loss: 18.3960 - lr: 1.0000e-05\n",
      "Epoch 252/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4033 - val_loss: 18.3959 - lr: 1.0000e-05\n",
      "Epoch 253/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4025 - val_loss: 18.3957 - lr: 1.0000e-05\n",
      "Epoch 254/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4024 - val_loss: 18.3956 - lr: 1.0000e-05\n",
      "Epoch 255/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4021 - val_loss: 18.3952 - lr: 1.0000e-05\n",
      "Epoch 256/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4020 - val_loss: 18.3945 - lr: 1.0000e-05\n",
      "Epoch 257/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4010 - val_loss: 18.3946 - lr: 1.0000e-05\n",
      "Epoch 258/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4003 - val_loss: 18.3933 - lr: 1.0000e-05\n",
      "Epoch 259/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3996 - val_loss: 18.3928 - lr: 1.0000e-05\n",
      "Epoch 260/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3991 - val_loss: 18.3932 - lr: 1.0000e-05\n",
      "Epoch 261/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3987 - val_loss: 18.3932 - lr: 1.0000e-05\n",
      "Epoch 262/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 16.3984 - val_loss: 18.3938 - lr: 1.0000e-05\n",
      "Epoch 263/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3978 - val_loss: 18.3928 - lr: 1.0000e-05\n",
      "Epoch 264/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3974 - val_loss: 18.3923 - lr: 1.0000e-05\n",
      "Epoch 265/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3966 - val_loss: 18.3926 - lr: 1.0000e-05\n",
      "Epoch 266/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 16.3962 - val_loss: 18.3924 - lr: 1.0000e-05\n",
      "Epoch 267/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3960 - val_loss: 18.3916 - lr: 1.0000e-05\n",
      "Epoch 268/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3952 - val_loss: 18.3915 - lr: 1.0000e-05\n",
      "Epoch 269/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.3947 - val_loss: 18.3909 - lr: 1.0000e-05\n",
      "Epoch 270/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3945 - val_loss: 18.3901 - lr: 1.0000e-05\n",
      "Epoch 271/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3932 - val_loss: 18.3903 - lr: 1.0000e-05\n",
      "Epoch 272/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3929 - val_loss: 18.3892 - lr: 1.0000e-05\n",
      "Epoch 273/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.3929 - val_loss: 18.3891 - lr: 1.0000e-05\n",
      "Epoch 274/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3919 - val_loss: 18.3874 - lr: 1.0000e-05\n",
      "Epoch 275/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3914 - val_loss: 18.3872 - lr: 1.0000e-05\n",
      "Epoch 276/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3915 - val_loss: 18.3865 - lr: 1.0000e-05\n",
      "Epoch 277/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3905 - val_loss: 18.3866 - lr: 1.0000e-05\n",
      "Epoch 278/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3901 - val_loss: 18.3863 - lr: 1.0000e-05\n",
      "Epoch 279/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3895 - val_loss: 18.3861 - lr: 1.0000e-05\n",
      "Epoch 280/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3887 - val_loss: 18.3859 - lr: 1.0000e-05\n",
      "Epoch 281/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.3884 - val_loss: 18.3850 - lr: 1.0000e-05\n",
      "Epoch 282/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3883 - val_loss: 18.3857 - lr: 1.0000e-05\n",
      "Epoch 283/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 16.3870 - val_loss: 18.3865 - lr: 1.0000e-05\n",
      "Epoch 284/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3867 - val_loss: 18.3868 - lr: 1.0000e-05\n",
      "Epoch 285/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3861 - val_loss: 18.3865 - lr: 1.0000e-05\n",
      "Epoch 286/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3858 - val_loss: 18.3864 - lr: 1.0000e-05\n",
      "Epoch 287/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 16.3857 - val_loss: 18.3855 - lr: 1.0000e-05\n",
      "Epoch 288/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3849 - val_loss: 18.3843 - lr: 1.0000e-05\n",
      "Epoch 289/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3841 - val_loss: 18.3842 - lr: 1.0000e-05\n",
      "Epoch 290/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3834 - val_loss: 18.3832 - lr: 1.0000e-05\n",
      "Epoch 291/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3831 - val_loss: 18.3841 - lr: 1.0000e-05\n",
      "Epoch 292/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3825 - val_loss: 18.3838 - lr: 1.0000e-05\n",
      "Epoch 293/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3821 - val_loss: 18.3842 - lr: 1.0000e-05\n",
      "Epoch 294/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3815 - val_loss: 18.3833 - lr: 1.0000e-05\n",
      "Epoch 295/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3813 - val_loss: 18.3832 - lr: 1.0000e-05\n",
      "Epoch 296/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3805 - val_loss: 18.3832 - lr: 1.0000e-05\n",
      "Epoch 297/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3800 - val_loss: 18.3820 - lr: 1.0000e-05\n",
      "Epoch 298/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3797 - val_loss: 18.3812 - lr: 1.0000e-05\n",
      "Epoch 299/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3791 - val_loss: 18.3801 - lr: 1.0000e-05\n",
      "Epoch 300/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3788 - val_loss: 18.3810 - lr: 1.0000e-05\n",
      "138/138 [==============================] - 0s 2ms/step\n",
      "Epoch 1/300\n",
      "31/31 [==============================] - 1s 10ms/step - loss: 759.4844 - val_loss: 696.0505 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 630.2300 - val_loss: 559.4118 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 490.8052 - val_loss: 420.3632 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 356.4890 - val_loss: 294.2428 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 244.4070 - val_loss: 200.2212 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 167.3949 - val_loss: 140.8428 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 121.4965 - val_loss: 108.4674 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 98.2463 - val_loss: 93.4566 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 87.7311 - val_loss: 86.5398 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 81.9525 - val_loss: 80.9514 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 76.0977 - val_loss: 74.6454 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 70.0889 - val_loss: 68.4330 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 64.1093 - val_loss: 62.1234 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 57.9603 - val_loss: 55.6911 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 52.3059 - val_loss: 50.5247 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 47.9765 - val_loss: 46.7010 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 44.6419 - val_loss: 43.6949 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 42.0735 - val_loss: 41.3400 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 40.0415 - val_loss: 39.5008 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 38.4203 - val_loss: 37.9818 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 37.0908 - val_loss: 36.6993 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 35.9292 - val_loss: 35.4957 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 34.8302 - val_loss: 34.3664 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 33.8555 - val_loss: 33.4246 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 33.0102 - val_loss: 32.6076 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 32.2042 - val_loss: 31.9258 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 31.5401 - val_loss: 31.2758 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 31.0303 - val_loss: 30.7746 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 30.5196 - val_loss: 30.3438 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 30.0773 - val_loss: 29.8978 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 29.6847 - val_loss: 29.5396 - lr: 0.0010\n",
      "Epoch 32/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 29.2984 - val_loss: 29.2047 - lr: 0.0010\n",
      "Epoch 33/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 28.9484 - val_loss: 28.8448 - lr: 0.0010\n",
      "Epoch 34/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 28.6248 - val_loss: 28.5366 - lr: 0.0010\n",
      "Epoch 35/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 28.3093 - val_loss: 28.2385 - lr: 0.0010\n",
      "Epoch 36/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 28.0033 - val_loss: 28.0136 - lr: 0.0010\n",
      "Epoch 37/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 27.7831 - val_loss: 27.7414 - lr: 0.0010\n",
      "Epoch 38/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 27.5042 - val_loss: 27.4145 - lr: 0.0010\n",
      "Epoch 39/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 27.2578 - val_loss: 27.2184 - lr: 0.0010\n",
      "Epoch 40/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.9825 - val_loss: 26.9589 - lr: 0.0010\n",
      "Epoch 41/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.8254 - val_loss: 26.7929 - lr: 0.0010\n",
      "Epoch 42/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.5105 - val_loss: 26.5207 - lr: 0.0010\n",
      "Epoch 43/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.3051 - val_loss: 26.2710 - lr: 0.0010\n",
      "Epoch 44/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 26.0749 - val_loss: 26.0133 - lr: 0.0010\n",
      "Epoch 45/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.8630 - val_loss: 25.8236 - lr: 0.0010\n",
      "Epoch 46/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.6278 - val_loss: 25.7155 - lr: 0.0010\n",
      "Epoch 47/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 25.3927 - val_loss: 25.3238 - lr: 0.0010\n",
      "Epoch 48/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 25.1839 - val_loss: 25.2044 - lr: 0.0010\n",
      "Epoch 49/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.9039 - val_loss: 24.9151 - lr: 0.0010\n",
      "Epoch 50/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.7785 - val_loss: 24.7211 - lr: 0.0010\n",
      "Epoch 51/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.3907 - val_loss: 24.4780 - lr: 0.0010\n",
      "Epoch 52/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 24.1693 - val_loss: 24.1615 - lr: 0.0010\n",
      "Epoch 53/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.9006 - val_loss: 23.9517 - lr: 0.0010\n",
      "Epoch 54/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.6984 - val_loss: 23.8212 - lr: 0.0010\n",
      "Epoch 55/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.4788 - val_loss: 23.6207 - lr: 0.0010\n",
      "Epoch 56/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.3072 - val_loss: 23.4057 - lr: 0.0010\n",
      "Epoch 57/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 23.2221 - val_loss: 23.3346 - lr: 0.0010\n",
      "Epoch 58/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.9936 - val_loss: 23.1992 - lr: 0.0010\n",
      "Epoch 59/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.8367 - val_loss: 23.0416 - lr: 0.0010\n",
      "Epoch 60/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 22.6770 - val_loss: 22.9607 - lr: 0.0010\n",
      "Epoch 61/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.5423 - val_loss: 22.7921 - lr: 0.0010\n",
      "Epoch 62/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.4044 - val_loss: 22.6896 - lr: 0.0010\n",
      "Epoch 63/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.2351 - val_loss: 22.6241 - lr: 0.0010\n",
      "Epoch 64/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 22.1290 - val_loss: 22.5847 - lr: 0.0010\n",
      "Epoch 65/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 22.0959 - val_loss: 22.4503 - lr: 0.0010\n",
      "Epoch 66/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.8330 - val_loss: 22.3813 - lr: 0.0010\n",
      "Epoch 67/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.7497 - val_loss: 22.2414 - lr: 0.0010\n",
      "Epoch 68/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 21.6041 - val_loss: 22.0984 - lr: 0.0010\n",
      "Epoch 69/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.4163 - val_loss: 21.9794 - lr: 0.0010\n",
      "Epoch 70/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.3002 - val_loss: 21.8523 - lr: 0.0010\n",
      "Epoch 71/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 21.1112 - val_loss: 21.7062 - lr: 0.0010\n",
      "Epoch 72/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 20.9906 - val_loss: 21.6068 - lr: 0.0010\n",
      "Epoch 73/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.8297 - val_loss: 21.5578 - lr: 0.0010\n",
      "Epoch 74/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.7339 - val_loss: 21.4627 - lr: 0.0010\n",
      "Epoch 75/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.5925 - val_loss: 21.3402 - lr: 0.0010\n",
      "Epoch 76/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.4808 - val_loss: 21.2465 - lr: 0.0010\n",
      "Epoch 77/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.3448 - val_loss: 21.2003 - lr: 0.0010\n",
      "Epoch 78/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.3262 - val_loss: 21.0341 - lr: 0.0010\n",
      "Epoch 79/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.2079 - val_loss: 21.0478 - lr: 0.0010\n",
      "Epoch 80/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 20.1262 - val_loss: 20.9508 - lr: 0.0010\n",
      "Epoch 81/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.9676 - val_loss: 20.9035 - lr: 0.0010\n",
      "Epoch 82/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.9260 - val_loss: 20.7416 - lr: 0.0010\n",
      "Epoch 83/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.7833 - val_loss: 20.7110 - lr: 0.0010\n",
      "Epoch 84/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.7016 - val_loss: 20.6341 - lr: 0.0010\n",
      "Epoch 85/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.6400 - val_loss: 20.5265 - lr: 0.0010\n",
      "Epoch 86/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.5357 - val_loss: 20.5180 - lr: 0.0010\n",
      "Epoch 87/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.4292 - val_loss: 20.3917 - lr: 0.0010\n",
      "Epoch 88/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.3559 - val_loss: 20.3475 - lr: 0.0010\n",
      "Epoch 89/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 19.3159 - val_loss: 20.3226 - lr: 0.0010\n",
      "Epoch 90/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.2207 - val_loss: 20.2542 - lr: 0.0010\n",
      "Epoch 91/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.1344 - val_loss: 20.2705 - lr: 0.0010\n",
      "Epoch 92/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 19.0689 - val_loss: 20.1332 - lr: 0.0010\n",
      "Epoch 93/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.9831 - val_loss: 20.0541 - lr: 0.0010\n",
      "Epoch 94/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.9411 - val_loss: 20.0860 - lr: 0.0010\n",
      "Epoch 95/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.9169 - val_loss: 20.0343 - lr: 0.0010\n",
      "Epoch 96/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.8212 - val_loss: 19.9617 - lr: 0.0010\n",
      "Epoch 97/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.7415 - val_loss: 19.9074 - lr: 0.0010\n",
      "Epoch 98/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.6821 - val_loss: 19.9107 - lr: 0.0010\n",
      "Epoch 99/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 18.6157 - val_loss: 19.8518 - lr: 0.0010\n",
      "Epoch 100/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.6094 - val_loss: 19.7944 - lr: 0.0010\n",
      "Epoch 101/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.5110 - val_loss: 19.7144 - lr: 0.0010\n",
      "Epoch 102/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.4708 - val_loss: 19.8560 - lr: 0.0010\n",
      "Epoch 103/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 18.4550 - val_loss: 19.6168 - lr: 0.0010\n",
      "Epoch 104/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.3648 - val_loss: 19.6085 - lr: 0.0010\n",
      "Epoch 105/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.2789 - val_loss: 19.5550 - lr: 0.0010\n",
      "Epoch 106/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.2310 - val_loss: 19.4933 - lr: 0.0010\n",
      "Epoch 107/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.1579 - val_loss: 19.5121 - lr: 0.0010\n",
      "Epoch 108/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.1271 - val_loss: 19.4418 - lr: 0.0010\n",
      "Epoch 109/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.0566 - val_loss: 19.3332 - lr: 0.0010\n",
      "Epoch 110/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.0005 - val_loss: 19.3401 - lr: 0.0010\n",
      "Epoch 111/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 18.0045 - val_loss: 19.3046 - lr: 0.0010\n",
      "Epoch 112/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.9185 - val_loss: 19.2206 - lr: 0.0010\n",
      "Epoch 113/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.8744 - val_loss: 19.2006 - lr: 0.0010\n",
      "Epoch 114/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 17.8185 - val_loss: 19.0354 - lr: 0.0010\n",
      "Epoch 115/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.7380 - val_loss: 19.1038 - lr: 0.0010\n",
      "Epoch 116/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.7177 - val_loss: 19.0127 - lr: 0.0010\n",
      "Epoch 117/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.6458 - val_loss: 18.9391 - lr: 0.0010\n",
      "Epoch 118/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 17.6107 - val_loss: 18.9029 - lr: 0.0010\n",
      "Epoch 119/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.5284 - val_loss: 18.8900 - lr: 0.0010\n",
      "Epoch 120/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.4619 - val_loss: 18.8944 - lr: 0.0010\n",
      "Epoch 121/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.4470 - val_loss: 18.7238 - lr: 0.0010\n",
      "Epoch 122/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 17.3580 - val_loss: 18.7209 - lr: 0.0010\n",
      "Epoch 123/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.2713 - val_loss: 18.6867 - lr: 0.0010\n",
      "Epoch 124/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.2967 - val_loss: 18.6578 - lr: 0.0010\n",
      "Epoch 125/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.2210 - val_loss: 18.5435 - lr: 0.0010\n",
      "Epoch 126/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 17.1686 - val_loss: 18.4544 - lr: 0.0010\n",
      "Epoch 127/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.0769 - val_loss: 18.5445 - lr: 0.0010\n",
      "Epoch 128/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 17.0661 - val_loss: 18.4109 - lr: 0.0010\n",
      "Epoch 129/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.9699 - val_loss: 18.4545 - lr: 0.0010\n",
      "Epoch 130/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.9610 - val_loss: 18.3954 - lr: 0.0010\n",
      "Epoch 131/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.8967 - val_loss: 18.3068 - lr: 0.0010\n",
      "Epoch 132/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.8181 - val_loss: 18.3400 - lr: 0.0010\n",
      "Epoch 133/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.8218 - val_loss: 18.1596 - lr: 0.0010\n",
      "Epoch 134/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.7110 - val_loss: 18.1744 - lr: 0.0010\n",
      "Epoch 135/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.6753 - val_loss: 18.0959 - lr: 0.0010\n",
      "Epoch 136/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.6263 - val_loss: 18.0558 - lr: 0.0010\n",
      "Epoch 137/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.5996 - val_loss: 18.0174 - lr: 0.0010\n",
      "Epoch 138/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.5352 - val_loss: 17.9916 - lr: 0.0010\n",
      "Epoch 139/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4744 - val_loss: 17.9057 - lr: 0.0010\n",
      "Epoch 140/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4233 - val_loss: 17.8233 - lr: 0.0010\n",
      "Epoch 141/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.3948 - val_loss: 17.8251 - lr: 0.0010\n",
      "Epoch 142/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 16.3745 - val_loss: 17.8244 - lr: 0.0010\n",
      "Epoch 143/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.4355 - val_loss: 17.6998 - lr: 0.0010\n",
      "Epoch 144/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.2753 - val_loss: 17.6482 - lr: 0.0010\n",
      "Epoch 145/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.2129 - val_loss: 17.6711 - lr: 0.0010\n",
      "Epoch 146/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.1935 - val_loss: 17.6037 - lr: 0.0010\n",
      "Epoch 147/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.1221 - val_loss: 17.5834 - lr: 0.0010\n",
      "Epoch 148/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.1806 - val_loss: 17.6111 - lr: 0.0010\n",
      "Epoch 149/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 16.0192 - val_loss: 17.4866 - lr: 0.0010\n",
      "Epoch 150/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9801 - val_loss: 17.4794 - lr: 0.0010\n",
      "Epoch 151/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.9233 - val_loss: 17.4226 - lr: 0.0010\n",
      "Epoch 152/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.8665 - val_loss: 17.4333 - lr: 0.0010\n",
      "Epoch 153/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8306 - val_loss: 17.3553 - lr: 0.0010\n",
      "Epoch 154/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.8464 - val_loss: 17.3756 - lr: 0.0010\n",
      "Epoch 155/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.7622 - val_loss: 17.3845 - lr: 0.0010\n",
      "Epoch 156/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7567 - val_loss: 17.3345 - lr: 0.0010\n",
      "Epoch 157/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.7379 - val_loss: 17.2487 - lr: 0.0010\n",
      "Epoch 158/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6518 - val_loss: 17.2752 - lr: 0.0010\n",
      "Epoch 159/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.6650 - val_loss: 17.1480 - lr: 0.0010\n",
      "Epoch 160/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6010 - val_loss: 17.1239 - lr: 0.0010\n",
      "Epoch 161/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.6238 - val_loss: 17.1569 - lr: 0.0010\n",
      "Epoch 162/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.5178 - val_loss: 17.0598 - lr: 0.0010\n",
      "Epoch 163/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.4800 - val_loss: 17.0666 - lr: 0.0010\n",
      "Epoch 164/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.4377 - val_loss: 17.0257 - lr: 0.0010\n",
      "Epoch 165/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.4111 - val_loss: 17.0191 - lr: 0.0010\n",
      "Epoch 166/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.3850 - val_loss: 16.9436 - lr: 0.0010\n",
      "Epoch 167/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.3840 - val_loss: 16.9843 - lr: 0.0010\n",
      "Epoch 168/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.3249 - val_loss: 16.9172 - lr: 0.0010\n",
      "Epoch 169/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2946 - val_loss: 16.8912 - lr: 0.0010\n",
      "Epoch 170/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2638 - val_loss: 16.8896 - lr: 0.0010\n",
      "Epoch 171/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2386 - val_loss: 16.8835 - lr: 0.0010\n",
      "Epoch 172/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.2214 - val_loss: 16.8932 - lr: 0.0010\n",
      "Epoch 173/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1783 - val_loss: 16.8304 - lr: 0.0010\n",
      "Epoch 174/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.1711 - val_loss: 16.8720 - lr: 0.0010\n",
      "Epoch 175/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1204 - val_loss: 16.8083 - lr: 0.0010\n",
      "Epoch 176/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 15.1517 - val_loss: 16.8957 - lr: 0.0010\n",
      "Epoch 177/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1102 - val_loss: 16.8290 - lr: 0.0010\n",
      "Epoch 178/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.1351 - val_loss: 16.7669 - lr: 0.0010\n",
      "Epoch 179/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.0444 - val_loss: 16.7570 - lr: 0.0010\n",
      "Epoch 180/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 15.0819 - val_loss: 16.7876 - lr: 0.0010\n",
      "Epoch 181/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 15.0476 - val_loss: 16.7076 - lr: 0.0010\n",
      "Epoch 182/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.9727 - val_loss: 16.6992 - lr: 0.0010\n",
      "Epoch 183/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.9418 - val_loss: 16.6971 - lr: 0.0010\n",
      "Epoch 184/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.9033 - val_loss: 16.6640 - lr: 0.0010\n",
      "Epoch 185/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.9311 - val_loss: 16.6673 - lr: 0.0010\n",
      "Epoch 186/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8430 - val_loss: 16.6005 - lr: 0.0010\n",
      "Epoch 187/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.8774 - val_loss: 16.6604 - lr: 0.0010\n",
      "Epoch 188/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.7975 - val_loss: 16.6517 - lr: 0.0010\n",
      "Epoch 189/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.7897 - val_loss: 16.7111 - lr: 0.0010\n",
      "Epoch 190/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6846 - val_loss: 16.6130 - lr: 1.0000e-04\n",
      "Epoch 191/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6487 - val_loss: 16.6013 - lr: 1.0000e-04\n",
      "Epoch 192/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6407 - val_loss: 16.6017 - lr: 1.0000e-04\n",
      "Epoch 193/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6264 - val_loss: 16.6007 - lr: 1.0000e-05\n",
      "Epoch 194/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6258 - val_loss: 16.6007 - lr: 1.0000e-05\n",
      "Epoch 195/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.6254 - val_loss: 16.5989 - lr: 1.0000e-05\n",
      "Epoch 196/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6246 - val_loss: 16.6007 - lr: 1.0000e-05\n",
      "Epoch 197/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6244 - val_loss: 16.6001 - lr: 1.0000e-05\n",
      "Epoch 198/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6240 - val_loss: 16.6001 - lr: 1.0000e-05\n",
      "Epoch 199/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.6231 - val_loss: 16.5987 - lr: 1.0000e-05\n",
      "Epoch 200/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6228 - val_loss: 16.5988 - lr: 1.0000e-05\n",
      "Epoch 201/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.6224 - val_loss: 16.5992 - lr: 1.0000e-05\n",
      "Epoch 202/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6221 - val_loss: 16.5991 - lr: 1.0000e-05\n",
      "Epoch 203/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6217 - val_loss: 16.5991 - lr: 1.0000e-05\n",
      "Epoch 204/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6211 - val_loss: 16.5966 - lr: 1.0000e-05\n",
      "Epoch 205/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6207 - val_loss: 16.5967 - lr: 1.0000e-05\n",
      "Epoch 206/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6201 - val_loss: 16.5978 - lr: 1.0000e-05\n",
      "Epoch 207/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6199 - val_loss: 16.5969 - lr: 1.0000e-05\n",
      "Epoch 208/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.6194 - val_loss: 16.5951 - lr: 1.0000e-05\n",
      "Epoch 209/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6188 - val_loss: 16.5942 - lr: 1.0000e-05\n",
      "Epoch 210/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6184 - val_loss: 16.5935 - lr: 1.0000e-05\n",
      "Epoch 211/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.6180 - val_loss: 16.5933 - lr: 1.0000e-05\n",
      "Epoch 212/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6176 - val_loss: 16.5924 - lr: 1.0000e-05\n",
      "Epoch 213/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6172 - val_loss: 16.5918 - lr: 1.0000e-05\n",
      "Epoch 214/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6172 - val_loss: 16.5878 - lr: 1.0000e-05\n",
      "Epoch 215/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6165 - val_loss: 16.5900 - lr: 1.0000e-05\n",
      "Epoch 216/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6160 - val_loss: 16.5892 - lr: 1.0000e-05\n",
      "Epoch 217/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6157 - val_loss: 16.5886 - lr: 1.0000e-05\n",
      "Epoch 218/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6154 - val_loss: 16.5911 - lr: 1.0000e-05\n",
      "Epoch 219/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.6147 - val_loss: 16.5920 - lr: 1.0000e-05\n",
      "Epoch 220/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6145 - val_loss: 16.5931 - lr: 1.0000e-05\n",
      "Epoch 221/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6138 - val_loss: 16.5921 - lr: 1.0000e-05\n",
      "Epoch 222/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6140 - val_loss: 16.5883 - lr: 1.0000e-05\n",
      "Epoch 223/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6128 - val_loss: 16.5909 - lr: 1.0000e-05\n",
      "Epoch 224/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6128 - val_loss: 16.5910 - lr: 1.0000e-05\n",
      "Epoch 225/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.6124 - val_loss: 16.5897 - lr: 1.0000e-05\n",
      "Epoch 226/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6118 - val_loss: 16.5880 - lr: 1.0000e-05\n",
      "Epoch 227/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6116 - val_loss: 16.5871 - lr: 1.0000e-05\n",
      "Epoch 228/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6112 - val_loss: 16.5904 - lr: 1.0000e-05\n",
      "Epoch 229/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.6108 - val_loss: 16.5870 - lr: 1.0000e-05\n",
      "Epoch 230/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6112 - val_loss: 16.5843 - lr: 1.0000e-05\n",
      "Epoch 231/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6101 - val_loss: 16.5858 - lr: 1.0000e-05\n",
      "Epoch 232/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6100 - val_loss: 16.5855 - lr: 1.0000e-05\n",
      "Epoch 233/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6094 - val_loss: 16.5858 - lr: 1.0000e-05\n",
      "Epoch 234/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6090 - val_loss: 16.5860 - lr: 1.0000e-05\n",
      "Epoch 235/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6086 - val_loss: 16.5839 - lr: 1.0000e-05\n",
      "Epoch 236/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6084 - val_loss: 16.5815 - lr: 1.0000e-05\n",
      "Epoch 237/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6079 - val_loss: 16.5811 - lr: 1.0000e-05\n",
      "Epoch 238/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6079 - val_loss: 16.5849 - lr: 1.0000e-05\n",
      "Epoch 239/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6075 - val_loss: 16.5851 - lr: 1.0000e-05\n",
      "Epoch 240/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6073 - val_loss: 16.5838 - lr: 1.0000e-05\n",
      "Epoch 241/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.6065 - val_loss: 16.5846 - lr: 1.0000e-05\n",
      "Epoch 242/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.6063 - val_loss: 16.5830 - lr: 1.0000e-05\n",
      "Epoch 243/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6059 - val_loss: 16.5796 - lr: 1.0000e-05\n",
      "Epoch 244/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6056 - val_loss: 16.5774 - lr: 1.0000e-05\n",
      "Epoch 245/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6057 - val_loss: 16.5792 - lr: 1.0000e-05\n",
      "Epoch 246/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6049 - val_loss: 16.5781 - lr: 1.0000e-05\n",
      "Epoch 247/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6046 - val_loss: 16.5760 - lr: 1.0000e-05\n",
      "Epoch 248/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6044 - val_loss: 16.5760 - lr: 1.0000e-05\n",
      "Epoch 249/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6039 - val_loss: 16.5760 - lr: 1.0000e-05\n",
      "Epoch 250/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6034 - val_loss: 16.5780 - lr: 1.0000e-05\n",
      "Epoch 251/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6032 - val_loss: 16.5789 - lr: 1.0000e-05\n",
      "Epoch 252/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.6026 - val_loss: 16.5773 - lr: 1.0000e-05\n",
      "Epoch 253/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6024 - val_loss: 16.5759 - lr: 1.0000e-05\n",
      "Epoch 254/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6025 - val_loss: 16.5765 - lr: 1.0000e-05\n",
      "Epoch 255/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6022 - val_loss: 16.5774 - lr: 1.0000e-05\n",
      "Epoch 256/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6018 - val_loss: 16.5790 - lr: 1.0000e-05\n",
      "Epoch 257/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6013 - val_loss: 16.5789 - lr: 1.0000e-05\n",
      "Epoch 258/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6006 - val_loss: 16.5780 - lr: 1.0000e-05\n",
      "Epoch 259/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6005 - val_loss: 16.5820 - lr: 1.0000e-05\n",
      "Epoch 260/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.6000 - val_loss: 16.5805 - lr: 1.0000e-05\n",
      "Epoch 261/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5999 - val_loss: 16.5800 - lr: 1.0000e-05\n",
      "Epoch 262/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5997 - val_loss: 16.5794 - lr: 1.0000e-05\n",
      "Epoch 263/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.5991 - val_loss: 16.5773 - lr: 1.0000e-05\n",
      "Epoch 264/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5988 - val_loss: 16.5766 - lr: 1.0000e-05\n",
      "Epoch 265/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.5987 - val_loss: 16.5760 - lr: 1.0000e-05\n",
      "Epoch 266/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5982 - val_loss: 16.5748 - lr: 1.0000e-05\n",
      "Epoch 267/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5981 - val_loss: 16.5780 - lr: 1.0000e-05\n",
      "Epoch 268/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5978 - val_loss: 16.5761 - lr: 1.0000e-05\n",
      "Epoch 269/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5977 - val_loss: 16.5759 - lr: 1.0000e-05\n",
      "Epoch 270/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5968 - val_loss: 16.5755 - lr: 1.0000e-05\n",
      "Epoch 271/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5966 - val_loss: 16.5745 - lr: 1.0000e-05\n",
      "Epoch 272/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5963 - val_loss: 16.5736 - lr: 1.0000e-05\n",
      "Epoch 273/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5960 - val_loss: 16.5732 - lr: 1.0000e-05\n",
      "Epoch 274/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5955 - val_loss: 16.5724 - lr: 1.0000e-05\n",
      "Epoch 275/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5954 - val_loss: 16.5732 - lr: 1.0000e-05\n",
      "Epoch 276/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5953 - val_loss: 16.5771 - lr: 1.0000e-05\n",
      "Epoch 277/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5948 - val_loss: 16.5779 - lr: 1.0000e-05\n",
      "Epoch 278/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5946 - val_loss: 16.5770 - lr: 1.0000e-05\n",
      "Epoch 279/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5943 - val_loss: 16.5781 - lr: 1.0000e-05\n",
      "Epoch 280/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5938 - val_loss: 16.5768 - lr: 1.0000e-05\n",
      "Epoch 281/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5936 - val_loss: 16.5761 - lr: 1.0000e-05\n",
      "Epoch 282/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5931 - val_loss: 16.5743 - lr: 1.0000e-05\n",
      "Epoch 283/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5934 - val_loss: 16.5766 - lr: 1.0000e-05\n",
      "Epoch 284/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5927 - val_loss: 16.5746 - lr: 1.0000e-05\n",
      "Epoch 285/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5924 - val_loss: 16.5723 - lr: 1.0000e-05\n",
      "Epoch 286/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5927 - val_loss: 16.5682 - lr: 1.0000e-05\n",
      "Epoch 287/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5918 - val_loss: 16.5705 - lr: 1.0000e-05\n",
      "Epoch 288/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.5913 - val_loss: 16.5691 - lr: 1.0000e-05\n",
      "Epoch 289/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5908 - val_loss: 16.5700 - lr: 1.0000e-05\n",
      "Epoch 290/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5911 - val_loss: 16.5685 - lr: 1.0000e-05\n",
      "Epoch 291/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.5905 - val_loss: 16.5699 - lr: 1.0000e-05\n",
      "Epoch 292/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.5899 - val_loss: 16.5698 - lr: 1.0000e-05\n",
      "Epoch 293/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.5898 - val_loss: 16.5691 - lr: 1.0000e-05\n",
      "Epoch 294/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5897 - val_loss: 16.5675 - lr: 1.0000e-05\n",
      "Epoch 295/300\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 14.5895 - val_loss: 16.5681 - lr: 1.0000e-05\n",
      "Epoch 296/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5890 - val_loss: 16.5704 - lr: 1.0000e-05\n",
      "Epoch 297/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5888 - val_loss: 16.5692 - lr: 1.0000e-05\n",
      "Epoch 298/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5885 - val_loss: 16.5707 - lr: 1.0000e-05\n",
      "Epoch 299/300\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 14.5885 - val_loss: 16.5706 - lr: 1.0000e-05\n",
      "Epoch 300/300\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 14.5874 - val_loss: 16.5717 - lr: 1.0000e-05\n",
      "138/138 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "X, y = X_numeric, merged_df[target_column]\n",
    "\n",
    "input_size = X.shape[1]\n",
    "\n",
    "input_shape = (input_size,)  # Replace input_size with the actual size of your input features\n",
    "hidden_layer_sizes = [64, 32, 16]  # Example: Two hidden layers with 64 and 32 units\n",
    "\n",
    "activation_functions = ['relu', 'sigmoid', 'relu']\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=8, shuffle=True, random_state=39)\n",
    "    \n",
    "scores_per_fold = []\n",
    "for train_indices, test_indices in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
    "    y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    neural_network_dev = create_neural_network(input_shape, hidden_layer_sizes, activation_functions)\n",
    "    neural_network_dev.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "    early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "    reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-5)\n",
    "    neural_network_dev.fit(\n",
    "        X_train_scaled, y_train, \n",
    "        epochs=300, batch_size=1024, \n",
    "        validation_data=(X_test_scaled, y_test),\n",
    "        callbacks=[reduce_lr, early_stopping]\n",
    "    )\n",
    "        \n",
    "    scores_per_fold.append(mean_squared_error(y_test, neural_network_dev.predict(X_test_scaled)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE: 16.92298600444407\n",
      "MSE Standard Deviation: 0.7097153407729242\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average MSE: {np.mean(scores_per_fold)}\")\n",
    "print(f\"MSE Standard Deviation: {np.std(scores_per_fold)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neumre_projekt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
